experiment_name: img2img/shinytubes-spikes7b-mamba-${matrix_slug}

matrix:
  bs: [64]
  opt: ["AdamW"]
  lr: [.0005]
  rnd: [True]
  l:
    - 4
  hid:
    - 16


trainer: experiments.img2img.trainer.TrainImg2Img
# histogram_loss_weight: 100.
# image_loss_margin: 2
resize_log_images: 3.

train_set: |
  ImageSourceTargetCropDataset("datasets/shiny-tubes3/train", SHAPE[-2:], target_first=True, num_crops=5000, random=${rnd})

validation_set: |
  ImageSourceTargetCropDataset("datasets/shiny-tubes3/validation", SHAPE[-2:], target_first=True, num_crops=2000, random=False)

batch_size: ${bs}
learnrate: ${lr}
optimizer: ${opt}
scheduler: CosineAnnealingWarmupLR
loss_function: l1
max_inputs: 1_000_000
num_inputs_between_validations: 100_000
# freeze_validation_set: True


globals:
  SHAPE: (3, 32, 32)

model: |
    from src.models.mamba.mamba import Mamba, ModelArgs
    
    class VisionMamba(nn.Module):
  
        def __init__(
                self,
                shape: Tuple[int, int, int],
                n_layer: int = 4,
                d_state: int = 16,
                expand: int = 2,
        ):
            super().__init__()
            self.layers = Mamba(ModelArgs(
                d_model=shape[-1] * shape[-2],
                n_layer=n_layer,
                d_state=d_state,
                expand=expand,
                vocab_size=1,
            )).layers
    
        def forward(self, x: torch.Tensor) -> torch.Tensor:
            x_shape = x.shape
            x = x.flatten(-2)
            for layer in self.layers:
                x = layer(x)
            return x.view(x_shape)
        
    VisionMamba(
        shape=SHAPE,
        n_layer=${l},
        d_state=${hid},
    )