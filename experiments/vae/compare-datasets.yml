trainer: src.train.TrainAutoencoder

matrix:
  ds:
    - "mnist"
    - "fmnist"
    - "rpg"
  aa:
    - "True"
    - "False"
  res:
    - 20
    - 28
    - 32
  lr:
    - 0.0003
    - 0.001

experiment_name: vae-test/vae_${matrix_slug}

train_set: | 
  {
      "mnist": mnist_dataset(train=True, shape=SHAPE, interpolation=${aa}),
      "fmnist": fmnist_dataset(train=True, shape=SHAPE, interpolation=${aa}),
      "rpg": rpg_tile_dataset_3x32x32(validation=False, shape=SHAPE, interpolation=${aa}) 
  }["${ds}"]

validation_set: |
  {
      "mnist": mnist_dataset(train=False, shape=SHAPE, interpolation=${aa}),
      "fmnist": fmnist_dataset(train=False, shape=SHAPE, interpolation=${aa}),
      "rpg": rpg_tile_dataset_3x32x32(validation=True, shape=SHAPE, interpolation=${aa})
  }["${ds}"]

batch_size: 64
learnrate: ${lr}
optimizer: Adam
scheduler: CosineAnnealingLR
max_inputs: 1_000_000

globals:
  SHAPE: (1, ${res}, ${res})
  CODE_SIZE: 128

model: |
  encoder = EncoderConv2d(SHAPE, code_size=CODE_SIZE, channels=(16, 24, 32), kernel_size=3)
  decoder = DecoderConv2d(SHAPE, code_size=CODE_SIZE, channels=(32, 24, 16), kernel_size=3)
  
  VariationalAutoencoder(
      encoder = VariationalEncoder(
          encoder, CODE_SIZE, CODE_SIZE
      ),
      decoder = decoder,
      reconstruction_loss = "l1",
      reconstruction_loss_weight = 1.,
      kl_loss_weight = 1.,
  )
