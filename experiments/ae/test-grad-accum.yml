matrix:
  bs:
    - 64
    #- 256
  ga:
    - 1
    - 4
    #- 6
    #- 8
  bn:
    - True
    - False
  lr:
    - 0.0003
    #- 0.0012

experiment_name: grad-accum/gatest3-${matrix_slug}

trainer: experiments.ae.trainer.TrainAutoencoderSpecial

train_set: |
  rpg_tile_dataset_3x32x32(SHAPE, validation=False)

validation_set: |
  rpg_tile_dataset_3x32x32(SHAPE, validation=True)

batch_size: ${bs}
gradient_accumulation: ${ga}

learnrate: 0.0003
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: l1
max_inputs: 1_000_000

globals:
  SHAPE: (3, 32, 32)
  CODE_SIZE: 128

model: |
  encoder = EncoderConv2d(SHAPE, code_size=CODE_SIZE, channels=(24, 32, 48), kernel_size=5, batch_norm=${bn})

  encoded_shape = encoder.convolution.get_output_shape(SHAPE)
  decoder = nn.Sequential(
      nn.Linear(CODE_SIZE, math.prod(encoded_shape)),
      Reshape(encoded_shape),
      encoder.convolution.create_transposed(act_last_layer=False),
  )

  EncoderDecoder(encoder, decoder)
