experiment_name: ae/kanpoly1l_${matrix_slug}

matrix:
  trial: [1]
  bs:
    - 64
#    - 256
  lr:
    - 0.0003
#    - 0.0001
  opt:
    - "AdamW"
    - "Adam"
#    - "RMSprop"
  ds:
    - ["mnist", [1, 28, 28]]
  ch:
    - [16]
  order:
    - 3
  eact:
#    - ["relu"]
    - ["none"]
  dact:
    - ["sigmoid"]
  percept_ch:
    - 0
    #- 128
  $filter: |
    len(${eact}) == len(${dact}) and len(${eact}) == len(${ch})
    and (isinstance(${order}, int) or len(${order}) == len(${ch}))

trainer: experiments.ae.trainer.TrainAutoencoderSpecial
seed: |
  2023 + ${trial}
feature_loss_weight: 0.

perceptual_model: |
  if ${percept_ch} == 0:
      model = None
  else:
      model = nn.Sequential(
          nn.Conv2d(${ds}[1], ${percept_ch}, kernel_size=3, padding=1),
      )
  model

train_set: |
  dataset_name, shape = ${ds}
  globals()[f"{dataset_name}_dataset"](shape=shape, train=True)

validation_set: |
  globals()[f"{dataset_name}_dataset"](shape=shape, train=False)

batch_size: ${bs}
learnrate: ${lr}
optimizer: ${opt}
scheduler: CosineAnnealingWarmupLR
loss_function: l2
max_inputs: 600_000

model: |
  from experiments.ae.kan.kanpolyae import KANPolyAE
  
  shape = ${ds}[1]
  
  model = KANPolyAE(
      shape=shape,
      channels=${ch}, 
      order=${order}, 
      encoder_activation=${eact},
      decoder_activation=${dact},
  )
  
  with torch.no_grad():
      print(model)
      inp = torch.ones(1, *shape)
      outp = dump_module_stacktrace(model.encoder, inp)
      print(inp.shape[1:], "->", outp.shape[1:])
      print("RATIO:", math.prod(inp.shape) / math.prod(outp.shape))
      print(f"params: {num_module_parameters(model):,}")
  
      recon = dump_module_stacktrace(model.decoder, outp)
  
  model
