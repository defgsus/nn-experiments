$extends: baseline.yml
# baseline was compression-ratio 24:1

matrix:
  model:
    - 1  # good one
  lr:
    #- 9.375e-7  # original
    - 9.375e-5
    # - 9.375e-4  # not working

experiment_name: ae/dcae5-${matrix_slug}

globals:
  SHAPE: (3, 32, 32)

learnrate: ${lr}

batch_size: 32
max_inputs: 5_000_000
#max_epoch:

train_set: |
  InterleaveIterableDataset(
    [
      rpg_tile_dataset_3x32x32(SHAPE, validation=False),
      TensorDataset(torch.load("./datasets/diverse-32x32-aug32.pt")),
      TensorDataset(torch.load("./datasets/photos-32x32-std01.pt")),
      #PixilartPatchDataset().resize(SHAPE[-2:]),
    ],
  )
validation_set: |
  rpg_tile_dataset_3x32x32((SHAPE[0], 32, 32), validation=True)

#num_inputs_between_validations: 1000

model: |
    from omegaconf import OmegaConf
    from src.models.efficientvit.dc_ae import DCAE, DCAEConfig
    
    CFG_STRINGS = [
        # 81M x48 lr=9.375e-5 ve=0.0414 
        (
            "latent_channels=64 "
            "encoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] "
            "encoder.width_list=[64,128,256,256,512,512] encoder.depth_list=[0,4,8,2,2,2] "
            "decoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] "
            "decoder.width_list=[64,128,256,256,512,512] decoder.depth_list=[0,5,10,2,2,2] "
            "decoder.norm=[bn2d,bn2d,bn2d,trms2d,trms2d,trms2d] decoder.act=[relu,relu,relu,silu,silu,silu]"
        ),
    ]
    cfg = OmegaConf.from_dotlist(CFG_STRINGS[${model}-1].split(" "))
    cfg: DCAEConfig = OmegaConf.to_object(OmegaConf.merge(OmegaConf.structured(DCAEConfig), cfg))
    DCAE(cfg)
