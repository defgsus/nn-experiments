matrix:
  opt: ["Adam"]
  lr: [0.001]
  patch: [4, 8, 16]
  #stride: [2, 4, 8, 16]
  #$filter: {stride} <= ${patch}
  l: [2]
  head: [8]
  hid: [256]

#experiment_name: mnist/trF_${matrix_id}_${matrix_slug}
experiment_name: mnist/trF_${matrix_slug}

trainer: TrainAutoencoder

globals:
  SHAPE: (1, 32, 32)
  CODE_SIZE: 32 * 32 // 10

train_set: |
  from experiments.datasets import rpg_tile_dataset 
  rpg_tile_dataset(SHAPE, validation=False, shuffle=True, random_shift=4, random_flip=True)
  #import experiments.datasets.classic
  #experiments.datasets.classic.fmnist_dataset(train=True, shape=SHAPE)

validation_set: |
  from experiments.datasets import rpg_tile_dataset 
  rpg_tile_dataset(SHAPE, validation=True, shuffle=True, limit=500)
  #import experiments.datasets.classic
  #experiments.datasets.classic.fmnist_dataset(train=False, shape=SHAPE)

batch_size: 64
learnrate: ${lr}
optimizer: ${opt}
scheduler: CosineAnnealingLR
loss_function: l1
max_inputs: 1_000_000

model: |
  from experiments.ae.transformer import *
  
  TransformerAutoencoder(
      shape=SHAPE, code_size=CODE_SIZE,
      patch_size=${patch},
      stride=${patch},
      num_layers=${l},
      num_hidden=${hid},
      num_heads=${head},
  )
