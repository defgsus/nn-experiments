experiment_name: textmask/convtext-code_${matrix_slug}

matrix:
  bs: [64]
  opt: ["AdamW"]
  lr: [.0005]
  size:
    - 160
  mask:
    - 30
  maskt:
    - "block"
  l:
    - 5
    #- 12
  ch:
    - 64
  #    - 128
  ks:
    - 9
    #- 11
    #- 13
  dil:
    - [2, 3, 4, 5, 1]
    - [1, 2, 3, 4, 5, 1]
    - [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1]
    - [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 1]
  $filter: isinstance(${dil}, int) or len(${dil}) == ${l}
  attn:
    - [0, 0, 4, 4, 0]  # +2.5
  act:
    - "gelu"


trainer: experiments.textmask.texttrainer.TextMaskTrainer
mask_size: ${mask}
mask_type: "${maskt}"

train_set: |
  ds = FileTextSegmentIterableDataset(
    FilenameDataset(
        "~/prog/python/github",
        include="*.py",
        exclude=["*/env/*", "*/node_modules/*", "*/site-packages/*"],
        recursive=True,
    ),
    size=${size}, stride="random",
  ).shuffle(10000)

validation_set: |
  ds = FileTextSegmentIterableDataset(
    FilenameDataset(
        #"~/prog/python/github",
        "/home/bergi/prog/python/botgard/BotGard3/",
        include="*.py",
        exclude=["*/env/*", "*/node_modules/*", "*/site-packages/*"],
        recursive=True,
    ),
    size=${size}, stride=5,
  ).shuffle(1000, seed=23).limit(5000)

batch_size: ${bs}
learnrate: ${lr}
optimizer: ${opt}
scheduler: CosineAnnealingWarmupLR
loss_function: l1
max_inputs: 4_000_000
#num_epochs_between_validations: 1
num_inputs_between_validations: 50_000
freeze_validation_set: True


model: |
  from experiments.textmask.textmodel import ConvTextModel
  
  ConvTextModel(
      vocab_size=256,
      num_layers=${l},
      num_channels=${ch},
      kernel_size=${ks},
      dilation=${dil},
      activation="${act}",
      num_attention_heads=${attn},
  )
