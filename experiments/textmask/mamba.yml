experiment_name: textmask/mamba-alice-${matrix_slug}

matrix:
  bs: [64]
  opt: ["AdamW"]
  lr: [.0005]
  size:
    - 40
  mask:
    - 5
  l:
    - 2
  d_model:
    - 32
  d_state:
    - 16
  exp:
    - 2


trainer: experiments.textmask.texttrainer.TextMaskTrainer
mask_size: ${mask}

train_set: |
  ds = TextSegmentIterableDataset(
    #Path("/home/bergi/text/der_bandwurm.txt").read_text(),
    Path("${PATH}/datasets/alice.txt").read_text(),
    size=${size}, stride=1,
  ).repeat(20).shuffle(1000)

validation_set: |
  ds = TextSegmentIterableDataset(
    Path("/home/bergi/text/der_bandwurm.txt").read_text(),
    Path("${PATH}/datasets/alice.txt").read_text(),
    size=${size}, stride=5,
  ).shuffle(1000, seed=23).limit(5000)

batch_size: ${bs}
learnrate: ${lr}
optimizer: ${opt}
scheduler: CosineAnnealingWarmupLR
loss_function: l1
max_inputs: 10_000_000
#num_epochs_between_validations: 1
num_inputs_between_validations: 50_000
freeze_validation_set: True


model: |
  from src.models.mamba.mamba import Mamba, ModelArgs
  
  # nn.Embedding(256, 256) # makes 16K steps/sec
  
  Mamba(ModelArgs(
      d_model=${d_model},
      n_layer=${l},
      d_state=${d_state},
      expand=${exp},
      vocab_size=256,
  ))
  
