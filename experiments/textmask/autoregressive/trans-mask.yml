experiment_name: textmask/trans-mask_${matrix_slug}

matrix:
  trial: [1] #, 2, 3, 4, 5]
  bs:
    - 64
    #- 256
  opt: ["AdamW"]
  lr:
    - .0005
    #- .002
  ds:
    - "alice"
    #- "kama"
    #- "zoo"
  size:
    #- 40
    #- [15, 500]
    - [20, 250]
  mask:
    - 1
  maskt:
    #- "block"
    - "end"
    #- "single"
  l:
    #- 3
    - 4
    #- 6
  h:
    - 8
  ch:
    #- 64
    - 128
    #- 256
    #- 512
  ch2:
    - 128
  act:
    - "relu"
  semb:
    - False
    #- True

trainer: experiments.textmask.texttrainer.TextMaskTrainer
# mask_is_arg: 1
mask_size: ${mask}
mask_type: ${maskt}

train_set: |
  FILE = Path({
    "alice": "${PATH}/datasets/text/en/alice-in-wonderland.txt",
    "kama": "${PATH}/datasets/text/en/kama-sutra.txt",
    "zoo": "${PATH}/datasets/text/en/zoology.txt",
  }["${ds}"]).read_text()
  
  TextSegmentIterableDataset(
    FILE,
    size=${size}, stride=1,
    batch_size=${bs},
  ).shuffle(100_000)

validation_set: |
  TextSegmentIterableDataset(
    FILE,
    size=${size}, stride=5,
    batch_size=${bs}, seed=42,
  ).shuffle(100_000, seed=23).limit(5000).freeze()

batch_size: ${bs}
learnrate: ${lr}
optimizer: ${opt}
scheduler: CosineAnnealingWarmupLR
#loss_function: l1
max_inputs: 50_000_000
num_epochs_between_validations: 999999
num_inputs_between_validations: 100_000
#freeze_validation_set: True


model: |
  from experiments.textmask.texttransformer import TextTransformer
  
  TextTransformer(
      vocab_size=256,
      num_layers=${l},
      num_channels=${ch},
      num_channels_mlp=${ch2},
      num_heads=${h},
      activation="${act}",
      diagonal_embedding=True,
      symmetric_embedding=${semb},
  )
