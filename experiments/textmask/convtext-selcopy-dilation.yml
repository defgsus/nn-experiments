experiment_name: textmask/convtext-selcopy_dilat_${matrix_slug}

matrix:
  bs: [64]
  opt: ["AdamW"]
  lr: [.0005]
  nitem:
    - 10
  area:
    - 40
  l:
    #- 4
    - 6
    #- 8
    #- 10
    #- 12
  ch:
    - 64
  ks:
    - 9
    #- 11
    #- 13
  dil:
    - 2
    - [2, 2, 2, 1, 1, 1]
    - [2, 2, 2, 2, 1, 1]
    - [2, 2, 2, 2, 2, 1]
    - [3, 3, 3, 1, 1, 1]
    - [4, 4, 4, 1, 1, 1]
    - [5, 5, 5, 1, 1, 1]
    - [6, 6, 6, 1, 1, 1]
    - [5, 4, 3, 2, 1, 1]
    - [2, 3, 4, 5, 1, 1]
    - [2, 3, 4, 5, 6, 1]  # best so far
    - [1, 2, 3, 4, 5, 1]
    - [3, 5, 7, 9, 11, 1]

    - [2, 6, 4, 5, 3, 1]
    - [2, 4, 6, 3, 5, 1]
  norm:
    - None
  act:
    - "gelu"


trainer: experiments.textmask.texttrainer.TextMaskTrainer
mask_is_arg: 1

train_set: |
  validation_set = TextSelectiveCopyingIterableDataset(
    count=10000,
    num_items=${nitem},
    area=${area},
    seed=23,
    with_masked=True,
  )
  TextSelectiveCopyingIterableDataset(
    count=100000,
    num_items=${nitem},
    area=${area},
    with_masked=True,
    exclude=list(i[0] for i in validation_set),
  )

validation_set: |
  validation_set

batch_size: ${bs}
learnrate: ${lr}
optimizer: ${opt}
scheduler: CosineAnnealingWarmupLR
loss_function: l1
max_inputs: 1_000_000
num_epochs_between_validations: 1
#num_inputs_between_validations: 50_000
freeze_validation_set: True


model: |
  from experiments.textmask.textmodel import ConvTextModel
  
  ConvTextModel(
      vocab_size=256,
      num_layers=${l},
      num_channels=${ch},
      kernel_size=${ks},
      dilation=${dil},
      norm=${norm},
      activation="${act}",
      residual=True,
      # residual_map={2: [4], 3: [5]},  # good one for 6 layers, but needs gradient-clipping at 0.01
  )
