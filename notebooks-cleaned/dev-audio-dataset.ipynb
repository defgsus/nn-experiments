{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1845bb39-6321-49fa-a467-da6a469f3ba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union, Dict\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset, RandomSampler\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display, Audio\n",
    "import torchaudio\n",
    "from torchaudio.io import StreamReader\n",
    "\n",
    "from src.datasets import *\n",
    "from src.algo import GreedyLibrary\n",
    "from src.util.image import *\n",
    "from src.util import to_torch_device\n",
    "from src.patchdb import PatchDB, PatchDBIndex\n",
    "from src.models.encoder import *\n",
    "from src.util.audio import *\n",
    "from src.util.files import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74428d0-e626-4fe6-918b-4a36cc740639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"/home/bergi/Music/BR80-backup/ROLAND/LIVEREC/LIVE0033-2023-09-10-poesnek.WAV\"\n",
    "filename = \"/home/bergi/Music/Aphex Twin/Acoustica Alarm Will Sound Performs Aphex Twin/01 Cock_Ver 10.mp3\"\n",
    "\n",
    "stream = StreamReader(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821bbe14-a7d7-402b-aec6-3bd6a490c749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while stream.num_out_streams:\n",
    "    stream.remove_stream(0)\n",
    "stream.add_basic_audio_stream(44_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5a70f-6fbf-45e6-ae7a-63d3d5f45c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for chunks in stream.stream():\n",
    "    wave = chunks[0]\n",
    "    break\n",
    "wave.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeced07-6ac8-4f51-a9fc-ee8ff520a6c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wave._elem.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b759bd66-1e7f-4efb-b5cd-9d03937967f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Audio(.1 * np.random.randn(20_000), rate=44100, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80792e-7fd1-4711-ad94-4de629125ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Audio(wave._elem.permute(1, 0).numpy(), rate=44000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7d22b-e4a6-473a-878a-8879f5221b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_audio(wave[-256:].permute(1, 0), (200, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f810d23-c88b-442a-8360-7de1cd5424d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = AudioSliceIterableDataset(filename, slice_size=1000, sample_rate=22050, mono=True)\n",
    "print(next(iter(ds)).shape)\n",
    "print(next(iter(DataLoader(ds, batch_size=3))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d55f4d-83f0-4f48-b0c5-da1133065188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "            \n",
    "ds = AudioSliceIterableDataset(filename, 22_050, 1000)\n",
    "waves = []\n",
    "for wave in ds:\n",
    "    waves.append(wave[:, 0])\n",
    "    if len(waves) > 14:\n",
    "        break\n",
    "waves = torch.concat([w.unsqueeze(0) for w in waves][9:]) \n",
    "plot_audio(waves, (300, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b525e90-5e17-41a4-b94a-db9e907c0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_audio_LOCAL(\n",
    "        waves: torch.Tensor, \n",
    "        shape: Tuple[int, int],\n",
    "        colors: Optional[Iterable[Tuple[int, int, int]]] = None,\n",
    ") -> PIL.Image.Image:\n",
    "    image = PIL.Image.new(\"RGB\", (shape[-1], shape[-2]))\n",
    "    draw = PIL.ImageDraw.ImageDraw(image)\n",
    "    \n",
    "    draw.line(\n",
    "        ((0, shape[-2] / 2), (shape[-1], shape[-2] / 2)),\n",
    "        fill=(128, 128, 128),\n",
    "        width=1,\n",
    "    )\n",
    "    \n",
    "    if waves.ndim == 1:\n",
    "        waves = waves.unsqueeze(0)\n",
    "        \n",
    "    if colors is None:\n",
    "        colors = (\n",
    "            (255, 255, 255),\n",
    "            (255, 128, 128),\n",
    "            (128, 255, 128),\n",
    "            (128, 128, 255),\n",
    "            (255, 255, 128),\n",
    "            (255, 128, 255),\n",
    "            (128, 255, 255),\n",
    "        )\n",
    "    else:\n",
    "        colors = tuple(colors)\n",
    "    \n",
    "    for i, wave in enumerate(waves):\n",
    "        x = torch.linspace(0, shape[-1] - 1, len(wave))\n",
    "        y = (1. - wave) * (shape[-2] / 2. - 1)\n",
    "        segments = torch.cat([x.unsqueeze(0), y.unsqueeze(0)]).permute(1, 0)\n",
    "        segments = tuple(tuple(s) for s in segments)\n",
    "        draw.line(segments, width=1, fill=colors[i % len(colors)])\n",
    "    return image\n",
    "\n",
    "#plot_audio(wave[:1280, 0].view(-1, 128), (128, 256))\n",
    "plot_audio(-torch.ones(128), (128, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41370684-37ab-46cb-8262-dbf090d3a07f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PIL.ImageDraw.ImageDraw.line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c1514-a602-463a-89ce-f4fb1376c6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.train_vae_audio import VAEAudioLinear\n",
    "m = VAEAudioLinear(1000, 100)\n",
    "m.forward(torch.randn(10, 1, 1000)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0edfb9a-d3d1-49ea-8030-0122c5e45dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec698809-5ad2-42ff-8803-5825d6ea5ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5fc0c-a788-40df-a990-c3ab0e3e6400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchaudio.utils.ffmpeg_utils import get_audio_decoders, get_input_protocols\n",
    "#get_audio_decoders()\n",
    "get_input_protocols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad1bb9-67a0-4d22-bed2-a96cc60b2e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
