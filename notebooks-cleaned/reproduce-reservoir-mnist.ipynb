{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35719274-c4c2-45f6-8f6a-a3cfab885c40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union, Dict\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display, HTML, Audio\n",
    "import plotly\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "from src.datasets import *\n",
    "from src.util.image import *\n",
    "from src.util import *\n",
    "from src.util.files import *\n",
    "from src.util.embedding import *\n",
    "from src.algo import *\n",
    "from src.models.encoder import *\n",
    "from src.models.decoder import *\n",
    "from src.models.util import *\n",
    "from src.models.reservoir import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8942b4-3566-413b-87d4-d614618aca53",
   "metadata": {},
   "source": [
    "# reproducing https://arxiv.org/pdf/2309.06815.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed5b932-9187-4a29-a64c-9cfa007bb509",
   "metadata": {},
   "source": [
    "## make small MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac14812-686c-404a-a439-af9ae2835bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_train_test_data(\n",
    "        num_train_samples_per_class: int = 660,\n",
    "        num_test_samples_per_class: int = 330,\n",
    "        seed: int = 23,\n",
    "):\n",
    "    from torchvision.datasets import MNIST\n",
    "    org_mnist = MNIST(\"~/prog/data/datasets\")\n",
    "\n",
    "    train_images = []\n",
    "    train_targets = []\n",
    "    test_images = []\n",
    "    test_targets = []\n",
    "    \n",
    "    train_counts = {}\n",
    "    test_counts = {}\n",
    "\n",
    "    for image, label in zip(org_mnist.data, org_mnist.targets):\n",
    "        label = int(label)\n",
    "        \n",
    "        target = [0] * 10\n",
    "        target[label] = 1\n",
    "        target = torch.Tensor(target).unsqueeze(0)\n",
    "        \n",
    "        #image = VF.hflip(image.permute(1, 0))\n",
    "        image = VF.crop(image, 3, 6, 22, 16)\n",
    "        image = image.unsqueeze(0).float() / 255.\n",
    "        \n",
    "        if train_counts.get(label, 0) < num_train_samples_per_class:\n",
    "            train_counts[label] = train_counts.get(label, 0) + 1\n",
    "            train_images.append(image)\n",
    "            train_targets.append(target)\n",
    "            \n",
    "        elif test_counts.get(label, 0) < num_test_samples_per_class:\n",
    "            test_counts[label] = test_counts.get(label, 0) + 1\n",
    "            test_images.append(image)\n",
    "            test_targets.append(target)\n",
    "    \n",
    "    gen = torch.Generator().manual_seed(seed)\n",
    "    train_permute = torch.randperm(len(train_images), generator=gen)\n",
    "    test_permute = torch.randperm(len(test_images), generator=gen)\n",
    "    \n",
    "    return (\n",
    "        torch.concat(train_images)[train_permute],\n",
    "        torch.concat(train_targets)[train_permute],\n",
    "        torch.concat(test_images)[test_permute],\n",
    "        torch.concat(test_targets)[test_permute],\n",
    "    )\n",
    "\n",
    "train_images, train_targets, test_images, test_targets = get_train_test_data()\n",
    "display(VF.to_pil_image(make_grid(train_images[:20, None, :, :], nrow=20)))\n",
    "display(VF.to_pil_image(make_grid(test_images[:20, None, :, :], nrow=20)))\n",
    "train_images.shape, train_targets.shape, test_images.shape, test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9726f6b-1570-4498-a592-665d8b598b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_time(series, steps: int = 3):\n",
    "    return torch.repeat_interleave(series, steps, dim=1)\n",
    "\n",
    "display(VF.to_pil_image(make_grid(expand_time(train_images)[:20, None, :, :], nrow=20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d7ea35-694d-497a-945e-a61b7611ad39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## baseline with linear regression only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e209278-d1f3-4762-a51f-e9f7f107ef7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "\n",
    "def dump_error(label: str, targets, prediction, ret: bool = False):\n",
    "    #error_l1 = (targets - prediction).abs().mean()\n",
    "    error_l1 = F.l1_loss(prediction, targets)\n",
    "    error_l2 = F.mse_loss(prediction, targets)\n",
    "    #error_l2 = (((targets - prediction) ** 2).sum(dim=-1)).sqrt().mean() / targets.shape[-1]\n",
    "    accuracy = (targets.argmax(dim=-1) == prediction.argmax(dim=-1)).float().mean()\n",
    "    if ret:\n",
    "        return float(error_l1), float(error_l2), float(accuracy)\n",
    "    print(f\"{label} error l1={error_l1:.3f}, l2={error_l2:.3f}, accuracy={accuracy:.3f}\")\n",
    "    # print( == prediction.argmax(dim=-1))\n",
    "    x = prediction.argmax(dim=-1)\n",
    "    y = targets.argmax(dim=-1)\n",
    "    fig = matplotlib.pyplot.figure(figsize=(2, 2))\n",
    "    hist = np.histogram2d(x.numpy(), y.numpy())[0]\n",
    "    matplotlib.pyplot.imshow(np.power(hist / hist.max(), .5))\n",
    "    #display(px.imshow(hist, title=\"confusion matrix\"))\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(train_images.flatten(1).numpy(), train_targets.numpy())\n",
    "\n",
    "dump_error(\"train\", train_targets, torch.Tensor(ridge.predict(train_images.flatten(1).numpy())))\n",
    "dump_error(\"test \", test_targets, torch.Tensor(ridge.predict(test_images.flatten(1).numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c558f-ba99-46ee-a560-133ef57289d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## reservoir / echo state network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b77c7-5181-4de2-8d52-6f9f1cd0558b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _act(x):\n",
    "    return torch.sin(x * 5.)\n",
    "\n",
    "esn = ReservoirReadout(\n",
    "    Reservoir(\n",
    "        16, 100, activation=\"sigmoid\", rec_prob=.1, rec_std=1.5, leak_rate=.1, input_prob=0.5, input_std=1.5,\n",
    "        #16, 1000, activation=\"sigmoid\", rec_prob=0.1, rec_std=1.0, leak_rate=.5, input_prob=0.5, input_std=1.5,\n",
    "    ),\n",
    ")\n",
    "\n",
    "def _trans_images(images):\n",
    "    #images = expand_time(images, 3)\n",
    "    #images = F.pad(images, (0, 0, 0, 20))\n",
    "    return images\n",
    "\n",
    "def _trans_state(state, reshape: bool = True):\n",
    "    # state = state[:, state.shape[1] // 2:, :]\n",
    "    # state = state[:, :, -100:]\n",
    "    state = torch.sin(state * 6.)\n",
    "    if reshape:\n",
    "        state = state.view(state.shape[0], -1)\n",
    "    return state\n",
    "\n",
    "train_state = esn.run_reservoir(_trans_images(train_images))\n",
    "print(f\"trans_state.shape = {train_state.shape}\")\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(_trans_state(train_state).numpy(), train_targets.numpy())\n",
    "\n",
    "test_state = esn.run_reservoir(_trans_images(test_images))\n",
    "\n",
    "dump_error(\"train\", train_targets, torch.Tensor(ridge.predict(_trans_state(train_state).numpy())))\n",
    "dump_error(\"test \", test_targets, torch.Tensor(ridge.predict(_trans_state(test_state).numpy())))\n",
    "\n",
    "display(px.imshow(_trans_state(train_state, reshape=False)[0].T, aspect=False, title=\"example reservoir state\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ce636-12ce-40f8-8ae3-8631c7cbe2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c3272cd-0540-4d1d-859a-79c0b1e20b2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# train neural linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057285e-c390-44a4-b8f5-f01c68953321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a3ab3-47ba-4e32-9f51-5b098abbdb15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_STEPS = 30_000\n",
    "\n",
    "model = nn.Linear(math.prod(train_state.shape[-2:]), 10)\n",
    "with torch.no_grad():\n",
    "    model.weight[:] = torch.Tensor(ridge.coef_)\n",
    "    model.bias[:] = torch.Tensor(ridge.intercept_)\n",
    "\n",
    "# model = nn.Sequential(nn.Linear(math.prod(train_state.shape[-2:]), 300), nn.Linear(300, 10))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=.001, weight_decay=.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, NUM_STEPS)\n",
    "\n",
    "model.cuda()\n",
    "train_state_trans = _trans_state(train_state).cuda()\n",
    "train_targets_cuda = train_targets.cuda()\n",
    "losses = []\n",
    "try:\n",
    "    for epoch in tqdm(range(NUM_STEPS)):\n",
    "        prediction = model(\n",
    "            train_state_trans \n",
    "            #+ 0.01 * torch.randn_like(train_state_trans)\n",
    "        )\n",
    "        loss = F.mse_loss(prediction, train_targets_cuda)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        losses.append(float(loss))\n",
    "        if epoch % 500 == 0:\n",
    "            print(min(losses[-500:]), max(losses[-500:]))\n",
    "                  \n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "model.cpu()\n",
    "\n",
    "display(px.line(losses, title=\"training loss\"))\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_prediction = model(_trans_state(train_state))\n",
    "    test_prediction = model(_trans_state(test_state))\n",
    "    \n",
    "dump_error(\"train\", train_targets, train_prediction)\n",
    "dump_error(\"test \", test_targets, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ed951-e2a0-46fa-aef2-98a0c8fa5d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(px.line(pd.DataFrame({\n",
    "    \"ridge_bias\": ridge.intercept_.flatten(),\n",
    "    \"nn_bias\": model.bias.detach().flatten(0),\n",
    "})))\n",
    "px.line(pd.DataFrame({\n",
    "    \"ridge_weight\": ridge.coef_.flatten(),\n",
    "    \"nn_weight\": model.weight.detach().flatten(0),\n",
    "    \"diff\": torch.Tensor(ridge.coef_.flatten()) - model.weight.detach().flatten(0),\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea7ac7-9b40-4ff2-a8ea-318f8478a178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    activation,\n",
    "    rec_prob,\n",
    "    rec_std,\n",
    "    leak_rate,\n",
    "):\n",
    "    esn = ReservoirReadout(\n",
    "        Reservoir(16, 1000, activation=activation, rec_prob=rec_prob, rec_std=rec_std, leak_rate=leak_rate),\n",
    "    )\n",
    "\n",
    "    train_state = esn.run_reservoir(expand_time(train_images, 1))\n",
    "\n",
    "    ridge = Ridge()\n",
    "    ridge.fit(train_state.view(train_state.shape[0], -1).numpy(), train_targets.numpy())\n",
    "\n",
    "    test_state = esn.run_reservoir(expand_time(test_images, 1))\n",
    "    \n",
    "    train_errors = dump_error(\"train\", train_targets, torch.Tensor(ridge.predict(train_state.view(train_state.shape[0], -1).numpy())), ret=True)\n",
    "    test_errors = dump_error(\"test \", test_targets, torch.Tensor(ridge.predict(test_state.view(test_state.shape[0], -1).numpy())), ret=True)\n",
    "    return {\n",
    "        \"train_error_l1\": train_errors[0],\n",
    "        \"train_error_l2\": train_errors[1],\n",
    "        \"train_accuracy\": train_errors[2],\n",
    "        \"test_error_l1\": test_errors[0],\n",
    "        \"test_error_l2\": test_errors[1],\n",
    "        \"test_accuracy\": test_errors[2],\n",
    "    }\n",
    "\n",
    "matrix = {\n",
    "    \"activation\": [\"sigmoid\", \"tanh\"],\n",
    "    \"rec_prob\": [0.1, .5, 1.],\n",
    "    \"rec_std\": [.5, 1., 1.5, 2.],\n",
    "    \"leak_rate\": [0.1, .5, .9, (.1, .9)],\n",
    "}\n",
    "rows = []\n",
    "try:\n",
    "    for params in tqdm(list(iter_parameter_permutations(matrix))):\n",
    "        for _ in range(5):\n",
    "            results = run_experiment(**params)\n",
    "            rows.append({\n",
    "                \"id\": \" \".join(f\"{key}={value}\" for key, value in params.items()),\n",
    "                #**{f\"param_{key}\": val for key, val in params.items()},\n",
    "                **results,\n",
    "            })\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.groupby(\"id\").mean(numeric_only=True).sort_values(\"test_accuracy\", ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf4f24-26c0-4ab3-b447-6198f8431514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66468e-f9a2-465d-a554-b6f48e988373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df.groupby(\"id\").mean(numeric_only=True).sort_values(\"test_accuracy\", ascending=False)\n",
    "df2#df2[\"param_activation\"] = df[\"param_activation\"]#.#.reset_index().drop(\"id\", axis=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02e9a8-e6a6-45be-bc0f-2ccd12e846f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c2e91-14e4-487f-bf4e-8af634e09adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f50d04d-acc6-47ca-9b83-28af620f4370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for klass in range(3):\n",
    "    idx = int(torch.argwhere(train_targets.argmax(dim=-1) == klass)[0][0])\n",
    "    h = train_state.shape[-1]\n",
    "    \n",
    "    images = [\n",
    "        train_images[idx].unsqueeze(0),\n",
    "        train_state[idx].T.unsqueeze(0),\n",
    "    ]\n",
    "    # print([i.shape for i in images])\n",
    "    display(VF.to_pil_image(torch.concat([\n",
    "        VF.resize(img, (h, int(h / img.shape[-2] * img.shape[-1])), VF.InterpolationMode.NEAREST, antialias=False)\n",
    "        for img in images\n",
    "    ], dim=-1)))\n",
    "#ridge.predict(train_state[:1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157dfd8-3d18-4d98-a3e7-336aac1097c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "activation_to_callable(\"gelu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
