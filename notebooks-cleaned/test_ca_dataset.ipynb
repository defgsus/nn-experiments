{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896580de-dfbd-4fec-9480-fcc6b6ff9d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from src.datasets.ca import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3b9d5b-3d87-40f7-a7a3-4860d59255db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = TotalCADataset(\n",
    "    (64, 64), \n",
    "    seed=23,\n",
    "    #num_repetitions=8,\n",
    "    #num_iterations=[1, 20],\n",
    "    #init_prob=[0, 1],\n",
    "    #rules=[\"3-23\", \"124-45\"],\n",
    "    dtype=torch.uint8,\n",
    ")\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c590a-d3a1-45d3-811b-f07d51b16dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_images(iterable, num: int = 8, nrow: int = 8):\n",
    "    images = []\n",
    "    for image in iterable:\n",
    "        if isinstance(image, (list, tuple)):\n",
    "            image = image[0]\n",
    "        images.append(image * 200)\n",
    "        if len(images) >= num:\n",
    "            break\n",
    "    return VF.to_pil_image(make_grid(images, nrow=nrow))\n",
    "\n",
    "dl = DataLoader(ds)\n",
    "plot_images(dl, 256, nrow=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb676d70-d945-4791-8a8a-62c795e7154e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9dc65-2b11-4877-9a7b-02b2a6b78b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = TensorDataset(torch.load(\"../datasets/ca-64x64-i10-p05.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93901049-9032-46d0-886a-8476ad52403e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CropDataset(Dataset):\n",
    "    def __init__(self, dataset: Dataset, shape: Tuple[int, int]):\n",
    "        self.dataset = dataset\n",
    "        self.shape = shape\n",
    "        self.cropper = VT.RandomCrop(self.shape)\n",
    "        \n",
    "    def __len(self): return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        item = self.dataset[item]\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            return [self.cropper(item[0]).unsqueeze(0), *item[1:]]\n",
    "        return self.cropper(item).unsqueeze(0)\n",
    "        \n",
    "ds3 = CropDataset(ds2, (32, 32))\n",
    "plot_images(ds3, 256, nrow=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f513c-ab1c-42b2-828e-bc24339b7b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00123fd9-31b3-4579-9437-6ba408afb32f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _trans(x):\n",
    "    f = fft.fft2(x)#[...,:4,:4])\n",
    "    return (f.real-f.imag) * .01 + .5\n",
    "    #return VF.resize(f.real, (64, 64)) * .1 + .3# * f.imag)\n",
    "images = [ds[i][0].unsqueeze(0) for i in range(8)]\n",
    "images += [_trans(i) for i in images]\n",
    "VF.to_pil_image(make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8f6a1-89af-412b-bc02-927cda476077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = fft.fft2(torch.Tensor([[0, 1, 1, 0], [1, 0, 1, 0]]))\n",
    "f = fft.fft2(torch.Tensor(torch.randn(10, 10)))\n",
    "f.shape\n",
    "#torch.cat([f.real, f.imag])#to(torch.float)#imag.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
