{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41ac48-a41e-4552-9fc9-97c2a6162edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *\n",
    "from multiprocessing import Pool\n",
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b7d9f-4081-41e6-beb5-b549e4cb1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imagenet1kIterableDataset(BaseIterableDataset):\n",
    "    _NUM_IMAGES = {\n",
    "        \"train\": 1281167,\n",
    "        \"validation\": 50000,\n",
    "        \"test\": 100000,\n",
    "    }\n",
    "    def __init__(\n",
    "            self,\n",
    "            type: str = \"train\",  # \"train\", \"validation\", \"test\" \n",
    "            image_type: str = \"pil\",\n",
    "            with_label: bool = False,\n",
    "            repo_path: Union[str, Path] = config.BIG_DATASETS_PATH / \"hug\" / \"imagenet-1k\",\n",
    "    ):\n",
    "        if type not in self._NUM_IMAGES:\n",
    "            raise ValueError(f\"'type' needs to be one of {', '.join(self._NUM_IMAGES)}, got '{type}'\")\n",
    "        super().__init__()\n",
    "        self._type = type\n",
    "        self._image_type = image_type\n",
    "        self._with_label = with_label\n",
    "        self._repo_path = Path(repo_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._NUM_IMAGES[self._type]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        files = sorted((self._repo_path / \"data\").glob(f\"{self._type}-*-of-*.parquet\"))\n",
    "        for file in files:\n",
    "            for batch in pq.ParquetFile(file).iter_batches(batch_size=10):\n",
    "                images = batch[\"image\"]\n",
    "                labels = batch[\"label\"]\n",
    "                for image, label in zip(images, labels):\n",
    "                    buffer = io.BytesIO(image[\"bytes\"].as_buffer())\n",
    "                    image = PIL.Image.open(buffer)\n",
    "                    if self._image_type == \"tensor\":\n",
    "                        image = VF.to_tensor(image.convert(\"RGB\"))\n",
    "                    if self._with_label:\n",
    "                        yield image, label\n",
    "                    else:\n",
    "                        yield image\n",
    "\n",
    "\n",
    "image_ds = Imagenet1kIterableDataset()\n",
    "size_map = {}\n",
    "try:\n",
    "    with tqdm(image_ds) as iterable:\n",
    "        for i, image in enumerate(iterable):\n",
    "            size_map[image.size] = size_map.get(image.size, 0) + 1\n",
    "            iterable.set_postfix({\"num_res\": len(size_map)})\n",
    "            #if i % 2000 == 0:\n",
    "            #    print(size_map)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73771c2c-82a6-4751-a988-0a0ccf8e6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(size_map)\n",
    "df = pd.DataFrame(size_map.values(), index=list(size_map), columns=[\"count\"]).sort_index().sort_values(\"count\")\n",
    "df.index = df.index.map(lambda x: str(tuple(x)))\n",
    "df[\"%\"] = (df[\"count\"] / df[\"count\"].sum() * 100).round(2)\n",
    "df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ac145-9d75-4966-871c-fc03914c19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"count\"] > 100].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4ead8-6475-4150-ab69-7648fdac6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = []\n",
    "for image in tqdm(image_ds.limit(5000)):\n",
    "    grid.append(image_resize_crop(image, (16, 16)))\n",
    "display(VF.to_pil_image(make_grid(grid, nrow=50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc8ffc-d858-4db5-879d-96b6360489d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm() as progress:\n",
    "    for batch in tqdm(DataLoader(image_ds, batch_size=1, num_workers=4)):\n",
    "        progress.update(batch.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253620f0-3df8-4160-82e4-7578f86d2bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7718b-c562-41cb-a397-a5153014b6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7952afbb-d02d-49cb-b838-90eda845b34c",
   "metadata": {},
   "source": [
    "# extract fixed sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b174da-ac9a-469c-ac67-9038d6a055a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[-20:].map(lambda x: (3, eval(x)[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15819a-8723-4a99-bf0b-4fdb167fbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util.tensor_storage import TensorStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12c771-1285-4ed8-9534-ba2414130850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shapes(shapes: List[Tuple[int, int, int]]):\n",
    "    shape_storage = {\n",
    "        shape: TensorStorage(\n",
    "            filename_part=config.BIG_DATASETS_PATH / \"imagenet1k-uint8-by-shape\" / \"x\".join(str(s) for s in shape) / \"batch\",\n",
    "            max_bytes=250 * 1024**2,\n",
    "        )\n",
    "        for shape in shapes\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        for image, label in tqdm(Imagenet1kIterableDataset(with_label=True)):\n",
    "            shape = (3, image.height, image.width)\n",
    "            if shape in shape_storage:\n",
    "                t = (VF.to_tensor(image.convert(\"RGB\")) * 255).to(torch.uint8)\n",
    "                shape_storage[shape].add(t)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    for storage in shape_storage.values():\n",
    "        storage.store_buffer()\n",
    "\n",
    "extract_shapes([\n",
    "    (3, 375, 500),\n",
    "    (3, 333, 500),\n",
    "    (3, 500, 375),\n",
    "    (3, 334, 500),\n",
    "    (3, 500, 333),\n",
    "    (3, 500, 500),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf40ab0-82e8-4688-a703-0ef8a5005175",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.load(config.BIG_DATASETS_PATH / \"imagenet1k-uint8-by-shape\" / \"3x375x500\" / \"batch-000001.pt\")\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6d55d-d710-4591-abdb-f72619b37834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d678a6-af6e-4941-a0d7-2b886109684a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
