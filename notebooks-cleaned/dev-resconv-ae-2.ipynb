{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654dd98-a179-423f-98ad-6f8ee48da92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17995dc-dcc7-4f1f-8bd3-b3606b7bfb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 16, 5, padding=2)\n",
    "print(\"W:\", conv.weight.shape)\n",
    "inp = torch.ones(1, 3, 32, 32)\n",
    "outp = conv(inp)\n",
    "print(inp.shape, \"->\", outp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2d340-b5c4-4c18-ae08-bc61eb106e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(4, 16, 5, padding=2, groups=4)\n",
    "print(\"W:\", conv.weight.shape)\n",
    "inp = torch.ones(1, 4, 32, 32)\n",
    "outp = conv(inp)\n",
    "print(inp.shape, \"->\", outp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d85e6a-19a8-4162-8120-94add2e58a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(4, 16, 5, padding=2)\n",
    "print(\"W:\", conv.weight.shape)\n",
    "inp = torch.ones(1, 4, 32, 32)\n",
    "outp = conv(inp)\n",
    "print(inp.shape, \"->\", outp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32610255-8503-4ba1-83d7-ba663c75343c",
   "metadata": {},
   "source": [
    "- more channels at shallow layers\n",
    "- small kernel size in shallow layers and larger kernel size in deeper layers\n",
    "- batch-norm before conv, or after conv, not after activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c66920-0a6e-464a-8948-c8f091eba139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RescaleConv(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            factor: int,\n",
    "            channels: int,\n",
    "            kernel_size: int = 3,\n",
    "            padding: int = 1,\n",
    "            activation: Union[None, str, Callable] = None,\n",
    "            batch_norm: bool = False,\n",
    "            transpose: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._transpose = transpose\n",
    "        chan_mult = factor ** 2\n",
    "        if not transpose:\n",
    "            self.unshuffle = nn.PixelUnshuffle(factor)\n",
    "            self.conv = nn.Conv2d(channels * chan_mult, channels, kernel_size, padding=padding)\n",
    "        else:\n",
    "            self.conv = nn.ConvTranspose2d(channels, channels * chan_mult, kernel_size, padding=padding)\n",
    "            self.shuffle = nn.PixelShuffle(factor)\n",
    "            \n",
    "        self.act = activation_to_module(activation)\n",
    "                \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self._transpose:\n",
    "            x = self.unshuffle(x)\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = self.conv(x)\n",
    "            x = self.shuffle(x)\n",
    "        if self.act is not None:\n",
    "            x = self.act(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"transpose={self._transpose}\"\n",
    "        \n",
    "m = RescaleConv(2, 16)\n",
    "mt = RescaleConv(2, 16, transpose=True)\n",
    "print(f\"params: {num_module_parameters(m):,} {num_module_parameters(mt):,}\")\n",
    "for size in (32, 64, 128):\n",
    "    inp = torch.ones(1, 16, size, size)\n",
    "    outp = m(inp)\n",
    "    print(inp.shape, \"->\", outp.shape, \"ratio:\", math.prod(inp.shape) / math.prod(outp.shape))\n",
    "    recon = mt(outp)\n",
    "    assert inp.shape == recon.shape, f\"{inp.shape} != {recon.shape}\"\n",
    "display(m)\n",
    "display(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaca081-127f-4777-8e01-b460a7e05cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConvStack(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels: Tuple[int, ...],\n",
    "            kernel_size: Union[int, Tuple[int, ...]] = 3,\n",
    "            padding: Union[int, Tuple[int, ...]] = 1,\n",
    "            activation: Union[Union[None, str, Callable], Tuple[Union[None, str, Callable], ...]] = None,\n",
    "            batch_norm: Union[bool, Tuple[bool, ...]] = False,\n",
    "            depth: Union[int, Tuple[int, ...]] = 0,\n",
    "            scale: Union[int, Tuple[int, ...]] = 1,\n",
    "            transpose: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._channels = tuple(channels)\n",
    "        assert len(self._channels) >= 2, f\"Got {len(self._channels)}\"\n",
    "        num_layers = len(self._channels) - 1\n",
    "        self._kernel_size = param_make_tuple(kernel_size, num_layers)\n",
    "        self._padding = param_make_tuple(padding, num_layers)\n",
    "        self._activation = param_make_tuple(activation, num_layers)\n",
    "        self._batch_norm = param_make_tuple(batch_norm, num_layers)\n",
    "        self._depth = param_make_tuple(depth, num_layers)\n",
    "        self._scale = param_make_tuple(scale, num_layers)\n",
    "        self._transpose = transpose\n",
    "        \n",
    "        self.layers = nn.Sequential()\n",
    "        chan_mult = 1\n",
    "        for idx in range(num_layers):\n",
    "            ch1 = self._channels[idx]\n",
    "            ch2 = self._channels[idx + 1]\n",
    "\n",
    "            if self._batch_norm[idx]:\n",
    "                self.layers.add_module(f\"layer_{idx+1}_norm\", nn.BatchNorm2d(ch1))\n",
    "            if self._scale[idx] > 1:\n",
    "                self.layers.add_module(\n",
    "                    f\"layer_{idx+1}_scale\",\n",
    "                    RescaleConv(self._scale[idx], ch1, transpose=transpose)\n",
    "                )\n",
    "            self.layers.add_module(\n",
    "                f\"layer_{idx+1}_conv\", \n",
    "                (nn.ConvTranspose2d if transpose else nn.Conv2d)(\n",
    "                    ch1, ch2, self._kernel_size[idx], padding=self._padding[idx]\n",
    "                )\n",
    "            )\n",
    "            if self._activation[idx] is not None:\n",
    "                self.layers.add_module(f\"layer_{idx+1}_act\", activation_to_module(self._activation[idx]))\n",
    "            for i in range(self._depth[idx]):\n",
    "                self.layers.add_module(\n",
    "                    f\"layer_{idx+1}_res_{i+1}\",\n",
    "                    ResidualAdd(\n",
    "                        nn.Conv2d(ch2, ch2, self._kernel_size[idx], padding=int(math.floor(self._kernel_size[idx] / 2)))\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return (\n",
    "            f\"channels={self._channels}, depth={self._depth}, scale={self._scale}, kernel_size={self._kernel_size}\"\n",
    "            f\",\\nbatch_norm={self._batch_norm}, activation={self._activation}, \"\n",
    "        )\n",
    "\n",
    "m = ResConvStack(\n",
    "    channels=(3, 64, 48, 32, 16, 3), \n",
    "    kernel_size=3, #(3, 5, 9, 9, 9),\n",
    "    padding=1,\n",
    "    scale=(1, 2, 2, 2, 1),\n",
    "    batch_norm=True, activation=\"gelu\", depth=2\n",
    ")\n",
    "mt = ResConvStack(\n",
    "    channels=(3, 64, 48, 32, 16, 3), \n",
    "    scale=(1, 2, 2, 2, 1),\n",
    "    transpose=True,\n",
    ")\n",
    "#mt.register_forward_pre_hook(lambda model, x: print(\"X\", x[0].shape))\n",
    "print(f\"params: {num_module_parameters(m):,} {num_module_parameters(mt):,}\")\n",
    "for size in (32, 64, 128):\n",
    "    inp = torch.ones(1, 3, size, size)\n",
    "    outp = m(inp)\n",
    "    print(inp.shape, \"->\", outp.shape, \"ratio:\", math.prod(inp.shape) / math.prod(outp.shape))\n",
    "    recon = mt(outp)\n",
    "    assert inp.shape == recon.shape, f\"{inp.shape} != {recon.shape}\"\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9c47f-f9d9-40e4-9bf9-3f52350042b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ResConvStack(\n",
    "    channels=(3, 64, 48, 32, 16, 3), \n",
    "    kernel_size=3, #(3, 5, 9, 9, 9),\n",
    "    padding=1,\n",
    "    scale=(1, 2, 2, 2, 1),\n",
    "    batch_norm=True, activation=\"gelu\", depth=2\n",
    ")\n",
    "mt = ResConvStack(\n",
    "    channels=(3, 64, 48, 32, 16, 3), \n",
    "    scale=(1, 2, 2, 2, 1),\n",
    "    transpose=True,\n",
    ")\n",
    "#mt.register_forward_pre_hook(lambda model, x: print(\"X\", x[0].shape))\n",
    "print(f\"params: {num_module_parameters(m):,} {num_module_parameters(mt):,}\")\n",
    "for size in (32, 64, 128):\n",
    "    inp = torch.ones(1, 3, size, size)\n",
    "    outp = m(inp)\n",
    "    print(inp.shape, \"->\", outp.shape, \"ratio:\", math.prod(inp.shape) / math.prod(outp.shape))\n",
    "    recon = mt(outp)\n",
    "    assert inp.shape == recon.shape, f\"{inp.shape} != {recon.shape}\"\n",
    "display(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
