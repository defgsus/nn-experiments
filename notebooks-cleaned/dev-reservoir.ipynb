{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e849d524-4fc7-47f4-ad13-1157631d285d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union, Dict\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display, HTML, Audio\n",
    "import plotly\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "from src.datasets import *\n",
    "from src.util.image import *\n",
    "from src.util import *\n",
    "from src.util.files import *\n",
    "from src.util.embedding import *\n",
    "from src.algo import *\n",
    "from src.models.encoder import *\n",
    "from src.models.decoder import *\n",
    "from src.models.util import *\n",
    "from src.util.text_encoder import TextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c24e5-b0d8-480a-aab3-3075cd6c98c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Reservoir(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_inputs: int,\n",
    "        num_cells: int,\n",
    "        leak_rate: Union[float, Tuple[float, float]] = .5,\n",
    "        rec_std: float = 1.,\n",
    "        rec_prob: float = .5,\n",
    "        input_std: float = 1.,\n",
    "        input_prob: float = .5,\n",
    "        activation: Union[str, Callable] = \"tanh\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_cells = self.num_outputs = num_cells\n",
    "        if isinstance(leak_rate, (int, float)):\n",
    "            self.leak_rate = leak_rate\n",
    "        else:\n",
    "            self.leak_rate = nn.Parameter(torch.rand(self.num_cells) * (leak_rate[1] - leak_rate[0]) + leak_rate[0])\n",
    "            \n",
    "        self.activation = activation_to_callable(activation)\n",
    "        self.bias_recurrent = nn.Parameter(torch.randn(self.num_cells))\n",
    "        self.weight_recurrent = nn.Parameter(\n",
    "            torch.randn(self.num_cells, self.num_cells) * (torch.rand(self.num_cells, self.num_cells) < rec_prob) * rec_std\n",
    "        )\n",
    "        self.weight_input = nn.Parameter(\n",
    "            torch.randn(self.num_inputs, self.num_cells) * (torch.rand(self.num_inputs, self.num_cells) < input_prob) * input_std\n",
    "        )\n",
    "        \n",
    "    def forward(self, state: torch.Tensor, input: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        assert state.ndim == 2, state.shape\n",
    "        assert state.shape[-1] == self.num_cells, state.shape        \n",
    "        \n",
    "        rec_state = (state + self.bias_recurrent) @ self.weight_recurrent\n",
    "        rec_state = self.activation(rec_state)\n",
    "        \n",
    "        if input is not None:\n",
    "            assert input.ndim == 2, input.shape\n",
    "            assert input.shape[-1] == self.num_inputs, input.shape\n",
    "            \n",
    "            in_state = input @ self.weight_input\n",
    "            rec_state = rec_state + self.activation(in_state)\n",
    "            \n",
    "        next_state = state * (1. - self.leak_rate) + rec_state * self.leak_rate\n",
    "        return next_state\n",
    "    \n",
    "    def run(self, input: torch.Tensor, state: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        if state is None:\n",
    "            state = torch.zeros(input.shape[0], self.num_cells)\n",
    "        states = []\n",
    "        for i in range(input.shape[-2]):\n",
    "            state = self(state, input[:, i])\n",
    "            states.append(state)\n",
    "        \n",
    "        return torch.concat([s.unsqueeze(1) for s in states], dim=1)\n",
    "    \n",
    "res = Reservoir(2, 40, rec_std=.5, leak_rate=(.1, .2), activation=\"sin\")\n",
    "with torch.no_grad():\n",
    "    state = res.run(torch.ones(3, 1000, 2))\n",
    "    \n",
    "print(state.shape)\n",
    "px.imshow(state[0].T, aspect=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96171eba-3fa1-40a4-ba0a-0553362016f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    series = torch.ones(1, 44100, res.num_inputs)\n",
    "    state = res.run(series)\n",
    "\n",
    "for i in range(min(10, state.shape[-1])):\n",
    "    display(Audio(state[0, :, i], rate=44100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3470f1-2fc2-4f25-a59a-bb498f5dd3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e6ee0a-5936-4c1f-8961-dd4b2919e08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    series = torch.zeros(1, 300, 2)\n",
    "    series[:, 10:20] = -1\n",
    "    series[:, 110:120] = -1\n",
    "    state = res.run(series)\n",
    "px.imshow(state[0].T, aspect=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b8359d-0782-4ff6-af97-68af223c2bd9",
   "metadata": {},
   "source": [
    "# compare speed with reservoirpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a69b3-a6dc-4cf2-8137-b3ecee615c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_INPUTS = 2\n",
    "NUM_CELLS = 1000\n",
    "NUM_BATCHES = 30\n",
    "NUM_TIMESTEPS = 1000\n",
    "\n",
    "start_time = time.time()\n",
    "res = Reservior(NUM_INPUTS, NUM_CELLS, rec_std=.5, leak_rate=(.1, .5), act=\"sin\")\n",
    "with torch.no_grad():\n",
    "    state = res.run(torch.ones(NUM_BATCHES, NUM_TIMESTEPS, NUM_INPUTS))\n",
    "print(f\"{time.time() - start_time:,.3f}sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d0cb16-93f2-4981-aa12-cb4995850332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import reservoirpy\n",
    "from reservoirpy import nodes\n",
    "reservoirpy.verbosity(0)\n",
    "\n",
    "start_time = time.time()\n",
    "ens = nodes.Input() >> nodes.Reservoir(NUM_CELLS)\n",
    "ens.run(np.ones((NUM_BATCHES, NUM_TIMESTEPS, NUM_INPUTS)))\n",
    "print(f\"{time.time() - start_time:,.3f}sec \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026edc8f-dd40-432a-836f-b79e929bc73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "class ReservoirReadout:\n",
    "    def __init__(\n",
    "            self,\n",
    "            reservoir: nn.Module,\n",
    "            verbose: bool = True,\n",
    "    ):\n",
    "        assert hasattr(reservoir, \"num_inputs\"), \"reservoir needs `num_inputs` attribute\"\n",
    "        assert hasattr(reservoir, \"num_outputs\"), \"reservoir needs `num_outputs` attribute\"\n",
    "        self.reservoir = reservoir\n",
    "        self.verbose = verbose\n",
    "        self.ridge = None\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def run_reservoir(\n",
    "            self, \n",
    "            input: Optional[torch.Tensor] = None, \n",
    "            state: Optional[torch.Tensor] = None,\n",
    "            steps: Optional[int] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        if input is not None:\n",
    "            assert input.ndim == 3, f\"Expecting `input` of shape (B, T, N), got {input.shape}\"\n",
    "            assert input.shape[-1] == self.reservoir.num_inputs, \\\n",
    "                f\"Expecting final dimension of `input` to match `reservior.num_inputs` {self.reservoir.num_inputs}, got {input.shape}\"\n",
    "            batch_size = input.shape[0]\n",
    "            if steps is None:\n",
    "                steps = input.shape[1]\n",
    "        else:\n",
    "            batch_size = 1\n",
    "            \n",
    "        if state is not None:\n",
    "            assert state.ndim == 2, f\"Expecting `state` of shape (B, C), got {state.shape}\"\n",
    "            assert state.shape[-1] == self.reservoir.num_cells, \\\n",
    "                f\"Expecting last `state` dimension to match reservoir size {self.reservoir.num_cells}, got {state.shape}\"\n",
    "            assert state.shape[0] == batch_size, \\\n",
    "                f\"Expecting first `state` dimension to match batch size {batch_size}, got {state.shape}\"\n",
    "        else:\n",
    "            state = torch.zeros(batch_size, self.reservoir.num_cells)\n",
    "        \n",
    "        if steps is None:\n",
    "            steps = 1\n",
    "            \n",
    "        states = []\n",
    "        for i in tqdm(range(steps), desc=\"running reservoir\", disable=not self.verbose):\n",
    "            state = self.reservoir(state, input[:, i] if input is not None and i < input.shape[1] else None)\n",
    "            states.append(state)\n",
    "        \n",
    "        return torch.concat([s.unsqueeze(1) for s in states], dim=1)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def fit(self, input: torch.Tensor, target: torch.Tensor, alpha: float = 1.) -> Tuple[float, float]:\n",
    "        assert input.ndim == 3, f\"Expecting input of shape (B, T, N), got {input.shape}\"\n",
    "        assert input.shape[-1] == self.reservoir.num_inputs, \\\n",
    "                f\"Expecting final dimension of `input` to match `reservior.num_inputs` {self.reservoir.num_inputs}, got {input.shape}\"\n",
    "        assert target.ndim == 3, f\"Expecting target of shape (B, T, N), got {target.shape}\"\n",
    "        assert input.shape[:2] == target.shape[:2], \\\n",
    "            f\"Expecting first 2 dimensions of `target` to be equal to `input` {input.shape[:2]}, got {target.shape[:2]}\"\n",
    "        \n",
    "        batch_size, time_steps = input.shape[:2]\n",
    "        \n",
    "        state = self.run_reservoir(input=input)\n",
    "        \n",
    "        state = state.reshape(batch_size * time_steps, -1)\n",
    "        target = target.reshape(batch_size * time_steps, -1)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"fitting output...\")\n",
    "        self.ridge = Ridge(alpha=alpha)\n",
    "        self.ridge.fit(state.numpy(), target.numpy())\n",
    "        \n",
    "        prediction = torch.Tensor(self.ridge.predict(state))\n",
    "\n",
    "        error_l1 = (target - prediction).abs().mean()\n",
    "        error_l2 = torch.sqrt(((target - prediction) ** 2).sum())\n",
    "        return float(error_l1), float(error_l2)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(\n",
    "            self, \n",
    "            input: Optional[torch.Tensor] = None, \n",
    "            state: Optional[torch.Tensor] = None,\n",
    "            steps: Optional[int] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        assert self.ridge is not None, \"Must call `fit` before `predict`\"\n",
    "        \n",
    "        state = self.run_reservoir(input=input, state=state, steps=steps)\n",
    "  \n",
    "        batch_size, time_steps = state.shape[:2]\n",
    "        \n",
    "        state = state.reshape(batch_size * time_steps, -1)\n",
    "        \n",
    "        prediction = torch.Tensor(self.ridge.predict(state))\n",
    "        \n",
    "        return prediction.view(batch_size, time_steps, -1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "            self, \n",
    "            steps: int,\n",
    "            input: Optional[torch.Tensor] = None, \n",
    "            state: Optional[torch.Tensor] = None,\n",
    "            adjust_prediction: Optional[Callable] = None,\n",
    "            lookahead: int = 1,\n",
    "    ) -> torch.Tensor:\n",
    "        state = self.run_reservoir(input=input, state=state)\n",
    "  \n",
    "        batch_size, time_steps = state.shape[:2]\n",
    "        \n",
    "        prediction = torch.Tensor(self.ridge.predict(state.reshape(batch_size * time_steps, -1)))\n",
    "        prediction = prediction.view(batch_size, time_steps, -1)\n",
    "        \n",
    "        state_slice = state[:, -lookahead]\n",
    "        # input_slice = prediction[:, -1, :]\n",
    "        future_predictions = [prediction]\n",
    "        input_slices = [prediction[:, -i, :] for i in range(lookahead-1, -1, -1)]\n",
    "        if adjust_prediction is not None:\n",
    "            input_slices = [adjust_prediction(s) for s in input_slices]\n",
    "            \n",
    "        for i in tqdm(range(steps), desc=\"generating\", disable=not self.verbose):\n",
    "            state_slice = self.reservoir(state_slice, input_slices.pop(0)) \n",
    "            predicted_slice = torch.Tensor(self.ridge.predict(state_slice))\n",
    "            if adjust_prediction is not None:\n",
    "                predicted_slice = adjust_prediction(predicted_slice)\n",
    "            future_predictions.append(predicted_slice[:, None, :])\n",
    "            input_slices.append(predicted_slice)\n",
    "        \n",
    "        return torch.concat(future_predictions, dim=-2)\n",
    "    \n",
    "esn = ReservoirReadout(Reservior(1, 1000))\n",
    "t = torch.linspace(0, 8*torch.pi, 400)\n",
    "curve = torch.sin(t) #+ torch.sin(t * 3) + torch.sin(t * 7)\n",
    "lookahead = 10\n",
    "input = curve[:-lookahead].view(1, -1, 1)\n",
    "target = curve[lookahead:].view(1, -1, 1)\n",
    "# display(px.imshow(esn.run_reservoir(input=inp)[0].T))\n",
    "print(esn.fit(input, target))\n",
    "prediction = esn.predict(input)\n",
    "display(px.line(pd.DataFrame({\n",
    "    \"target\": target[0, :, 0],\n",
    "    \"prediction\": prediction[0, :, 0],\n",
    "    \"error\": (target - prediction)[0, :, 0],\n",
    "})))\n",
    "prediction = esn.generate(1000, input, lookahead=lookahead)\n",
    "display(px.line(prediction[0, :1000, 0], title=\"generate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0328aa6-8588-4b34-b57d-f47ed72785e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = esn.generate(50_000, input, lookahead=lookahead)\n",
    "display(Audio(prediction[0, :, 0], rate=44100))\n",
    "display(px.line(prediction[0, 20000:23000, 0], title=\"generate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a60a6-27b4-44fc-9fd6-bd927bf04f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1edf00ad-df76-48e7-b278-dcab2b2f7de6",
   "metadata": {},
   "source": [
    "# class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa85c29-e72e-421b-9abf-6e0a973877c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_sequence(sequence, num_classes: int):\n",
    "    output = torch.zeros((len(sequence), num_classes))\n",
    "    for i, s in enumerate(sequence):\n",
    "        output[i, s] = 1.\n",
    "    return output\n",
    "\n",
    "CHAR_MAPPING = {}\n",
    "for c in \" ,.:/[]|&;0123456789\":\n",
    "    CHAR_MAPPING[c] = len(CHAR_MAPPING)\n",
    "for c in range(ord('a'), ord('z') + 1):\n",
    "    CHAR_MAPPING[chr(c)] = len(CHAR_MAPPING)\n",
    "CODE_MAPPING = {\n",
    "    v: k \n",
    "    for k, v in CHAR_MAPPING.items()\n",
    "}\n",
    "def encode_text(text: str) -> np.ndarray:\n",
    "    classes = [\n",
    "        CHAR_MAPPING[c]\n",
    "        for c in text.lower()\n",
    "        if c in CHAR_MAPPING\n",
    "    ]\n",
    "    return encode_sequence(classes, num_classes=len(CHAR_MAPPING))\n",
    "\n",
    "def decode_text(code: torch.Tensor) -> str:\n",
    "    text = []\n",
    "    for classes in code:\n",
    "        c = torch.argmax(classes)\n",
    "        text.append(CODE_MAPPING.get(int(c), \"?\"))\n",
    "    return \"\".join(text)\n",
    "    \n",
    "#encode_sequence([0, 1, 2, 3, 2, 1, 0], 4)\n",
    "code = encode_text(\"abc defz\")\n",
    "#print(code)\n",
    "decode_text(code)\n",
    "#CHAR_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cd9a5-262f-45a5-b899-fde28ebf5279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchtext.datasets\n",
    "ds = torchtext.datasets.EnWik9()\n",
    "wiki_texts = []\n",
    "for line, _ in zip(ds, range(1000)):\n",
    "    if len(line) > 300:\n",
    "        wiki_texts.append(line[:3000])\n",
    "# display(wiki_texts[:10])\n",
    "display([decode_text(encode_text(t))[:100] for t in wiki_texts[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974fa59-f27e-43f6-8c48-64c7a77e4230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_text(*text, max_length: int = 700, num_cells: int = 1000, alpha: float = 1., act=\"sin\", lookahead: int = 1):\n",
    "    input_series = [\n",
    "        encode_text(t)[None, :max_length, :]\n",
    "        for t in text\n",
    "    ]\n",
    "    max_len = max(code.shape[1] for code in input_series)\n",
    "    input_series = torch.concat([\n",
    "        F.pad(s, (0, 0, 0, max_len - s.shape[1]))\n",
    "        for s in input_series\n",
    "    ])\n",
    "    target_series = input_series[:, lookahead:,  :]\n",
    "    input_series =  input_series[:, :-lookahead, :]\n",
    "    \n",
    "    esn = ReservoirReadout(\n",
    "        Reservoir(\n",
    "            input_series.shape[-1], num_cells, \n",
    "            leak_rate=(.1, .9),\n",
    "            activation=act,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    error_l1, error_l2 = esn.fit(input_series, target_series, alpha=alpha)\n",
    "        \n",
    "    print(f\"error l1 {error_l1:.3f}, l2 {error_l2:.3f}\")\n",
    "    \n",
    "    #display(px.imshow(target_series[0].T, aspect=False, title=\"targets\"))\n",
    "    #display(px.imshow(prediction[0].T, aspect=False, title=f\"prediction\"))\n",
    "    #display(px.imshow(-(target_series[0] - prediction[0]).T, aspect=False, title=f\"error l1 {error_l1:.3f}, l2 {error_l2:.3f}\"))\n",
    "    \n",
    "    def _adjust_prediction(p):\n",
    "        p_mask = p.max(dim=-1, keepdim=True)[0] == p\n",
    "        new_p = torch.zeros_like(p)\n",
    "        new_p[p_mask] = 1\n",
    "        return new_p\n",
    "    \n",
    "    input_len = input_series.shape[1] // 2\n",
    "    generated = esn.generate(\n",
    "        300, input_series[:, :input_len, :],\n",
    "        adjust_prediction=_adjust_prediction,\n",
    "        lookahead=lookahead,\n",
    "    )\n",
    "    \n",
    "    for gen in generated:\n",
    "        text = decode_text(gen)\n",
    "        print(repr(text[:input_len]), \"REPR:\", repr(text[input_len:]))\n",
    "    #print(generated.shape)\n",
    "        \n",
    "        \n",
    "predict_text(\n",
    "    *wiki_texts[:1],\n",
    "    #\"a simple text to learn to predict the next character. this is usually done with recurrent networks\"\n",
    "    #\" which are kind of hard to train. in reservoir computing we only train the readout module\"\n",
    "    #\" and let the reservoir rnn simply do its magic without intereferring\",\n",
    "    #\"a second text that has nothing to do with the first except that it uses the same characters\"\n",
    "    #\" and the same language.\",\n",
    "    alpha=1.,\n",
    "    num_cells=1000,\n",
    "    max_length=200,\n",
    "    act=\"tanh\",\n",
    "    lookahead=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
