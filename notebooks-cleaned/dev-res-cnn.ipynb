{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b5fce6-a006-4ff7-87c8-9978a006c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union, Type\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset, RandomSampler\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display\n",
    "\n",
    "from src.util.image import *\n",
    "from src.util import *\n",
    "from src.algo import ca1\n",
    "from src.models.util import *\n",
    "\n",
    "def resize(img, scale: float, mode: VF.InterpolationMode = VF.InterpolationMode.NEAREST):\n",
    "    return VF.resize(img, [max(1, int(s * scale)) for s in img.shape[-2:]], mode, antialias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24479d60-91db-4441-bd59-2f659f639d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlmostResidual2d(nn.Module):\n",
    "    def __init__(self, kernel_size: int, transpose: bool = False):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.transpose = transpose\n",
    "        \n",
    "        if self.kernel_size:\n",
    "            num_missing = self.kernel_size // 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.kernel_size <= 1:\n",
    "            return x\n",
    "\n",
    "        num = self.kernel_size // 2\n",
    "        if not self.transpose:\n",
    "            return x[..., num:-num, num:-num]\n",
    "            \n",
    "        else:\n",
    "            return F.pad(x, (num, num, num, num))\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"kernel_size={self.kernel_size}, transpose={self.transpose}\"\n",
    "\n",
    "AlmostResidual2d(3, transpose=True)(torch.rand(1, 3, 10, 12)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65262af5-2a16-4b5b-bc3a-8b592b3a7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels_in: int,\n",
    "            channels_hidden: int,\n",
    "            channels_out: int,\n",
    "            kernel_size: int = 3,\n",
    "            stride: int = 1,\n",
    "            groups: int = 1,\n",
    "            activation: Union[None, str, Callable, nn.Module, Type[nn.Module]] = \"relu\",\n",
    "            batch_norm: bool = True,\n",
    "            residual: Union[bool, str] = \"add\",\n",
    "            transpose: bool = False,\n",
    "    ):\n",
    "        assert residual in (False, True, \"add\", \"concat\"), f\"Got: {residual}\"\n",
    "        if residual is True:\n",
    "            residual = \"add\"\n",
    "        if residual == \"add\" and channels_in != channels_out:\n",
    "            raise ValueError(\n",
    "                f\"channels_in/_out must be equal for residual='add' mode\"\n",
    "            )\n",
    "            \n",
    "        super().__init__()\n",
    "\n",
    "        conv_class = nn.Conv2d if not transpose else nn.ConvTranspose2d\n",
    "\n",
    "        self.residual = residual\n",
    "        self.res_layers = nn.Sequential()\n",
    "        if residual:\n",
    "            if kernel_size > 1:\n",
    "                self.res_layers.add_module(\n",
    "                    f\"pool{kernel_size}x{kernel_size}\", \n",
    "                    #nn.AvgPool2d(kernel_size=kernel_size, stride=1)\n",
    "                    AlmostResidual2d(kernel_size=kernel_size, transpose=transpose)\n",
    "                )\n",
    "\n",
    "        self.layers = nn.Sequential()\n",
    "        self.layers.add_module(\"c1x1_1\", conv_class(channels_in, channels_hidden, kernel_size=1, groups=groups))\n",
    "        if batch_norm:\n",
    "            self.layers.add_module(\"bn_1\", nn.BatchNorm2d(channels_hidden))\n",
    "        if activation is not None:\n",
    "            self.layers.add_module(\"act_1\", activation_to_module(activation))\n",
    "\n",
    "        self.layers.add_module(f\"c{kernel_size}x{kernel_size}\", conv_class(channels_hidden, channels_hidden, kernel_size=kernel_size, groups=groups))        \n",
    "        if batch_norm:\n",
    "            self.layers.add_module(\"bn_2\", nn.BatchNorm2d(channels_hidden))\n",
    "        if activation is not None:\n",
    "            self.layers.add_module(\"act_2\", activation_to_module(activation))\n",
    "        self.layers.add_module(\"c1x1_2\", conv_class(channels_hidden, channels_out, kernel_size=1, groups=groups))\n",
    "        if batch_norm:\n",
    "            self.layers.add_module(\"bn_3\", nn.BatchNorm2d(channels_out))\n",
    "            \n",
    "        if activation is not None:\n",
    "            self.act_3 = activation_to_module(activation)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.layers(x)\n",
    "\n",
    "        x_res = self.res_layers(x)\n",
    "        #print(\"y:\", y.shape, \"x_res:\", x_res.shape)\n",
    "        \n",
    "        if self.residual == \"add\":\n",
    "            y = x_res + y\n",
    "        elif self.residual == \"concat\":\n",
    "            # print(x_res.shape, y.shape)\n",
    "            y = torch.concat([x_res, y], dim=-3)\n",
    "        return y\n",
    "    \n",
    "\n",
    "print( ResConvBlock(3, 7, 3, kernel_size=1)(torch.randn(1, 3, 10, 12)).shape )\n",
    "print( ResConvBlock(3, 7, 3)(torch.randn(1, 3, 10, 12)).shape )\n",
    "print( ResConvBlock(3, 7, 5, residual=\"concat\")(torch.randn(1, 3, 10, 12)).shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1a50a-8d78-4973-8c8d-d36fa9813465",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( ResConvBlock(3, 7, 3, kernel_size=1, transpose=True)(torch.randn(1, 3, 10, 12)).shape )\n",
    "print( ResConvBlock(3, 7, 3, transpose=True)(torch.randn(1, 3, 10, 12)).shape )\n",
    "print( ResConvBlock(3, 7, 5, transpose=True, residual=\"concat\")(torch.randn(1, 3, 10, 12)).shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ce77d-5bec-46a6-a2e2-bd4166276d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResConvBlock(3, 7, 5, transpose=True, residual=\"concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc91432-ab54-4256-bc2b-c556a849cff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64049fe0-caa9-4950-b9ae-29b216b51a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nn.Conv2d(4, 8, 1, groups=4)\n",
    "print(c.weight.shape)\n",
    "c(torch.rand(1, 4, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59edab4c-c2a8-4188-8c97-f34f87d0503a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb774bb-4a7d-42f4-abc3-c2167051953f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64edf0b-ebfb-43a8-90fa-1859cf0cbe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConv2dDecoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            shape: Tuple[int, int, int],\n",
    "            code_size: int,\n",
    "            kernel_size: Union[int, Iterable[int]] = 3,\n",
    "            stride: int = 1,\n",
    "            groups: int = 1,\n",
    "            channels: Iterable[int] = (384, 384, 256, 256, 128, 128, 64, 64, 32, 32, 3),\n",
    "            activation: Union[None, str, Callable, nn.Module, Type[nn.Module]] = \"relu\",\n",
    "            activation_last_layer: Union[None, bool, str, Callable, nn.Module, Type[nn.Module]] = None,\n",
    "            space_to_depth: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = tuple(channels)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.shape = shape\n",
    "        self.code_size = code_size\n",
    "        #act_fn = activation_to_module(activation)\n",
    "\n",
    "        conv = nn.Sequential()\n",
    "        ch_add = 0\n",
    "        for i, (ch, ch_next) in enumerate(zip(self.channels, self.channels[1:])):\n",
    "            is_last_layer = i + 2 == len(self.channels)\n",
    "            conv.add_module(\n",
    "                f\"block{i+1}\", \n",
    "                ResConvBlock(\n",
    "                    channels_in=ch + ch_add,\n",
    "                    channels_hidden=ch * 2,\n",
    "                    channels_out=ch_next,\n",
    "                    kernel_size=kernel_size,\n",
    "                    groups=1 if is_last_layer else groups,\n",
    "                    transpose=True,\n",
    "                    activation=activation,\n",
    "                    residual=False if is_last_layer else \"concat\",\n",
    "                )\n",
    "            )\n",
    "            ch_add += ch\n",
    "\n",
    "        self.conv_shape = (channels[0], 24, 24)\n",
    "        \n",
    "        self.linear = nn.Linear(code_size, math.prod(self.conv_shape))\n",
    "        self.conv = conv\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        y = self.linear(x).view(bs, *self.conv_shape)\n",
    "        return self.conv(y)\n",
    "        \n",
    "decoder = ResConv2dDecoder((3, 32, 32), 100, groups=8, kernel_size=5)\n",
    "print(f\"params: {num_module_parameters(decoder):,}\")\n",
    "output = decoder(torch.rand(10, 100))\n",
    "print( output.shape )\n",
    "display(VF.to_pil_image(resize(make_grid(output), 3)))\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902eed1c-84cb-4a47-9963-6649f12a1412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import shufflenetv2\n",
    "shufflenetv2.shufflenet_v2_x2_0(weights=shufflenetv2.ShuffleNet_V2_X2_0_Weights.DEFAULT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
