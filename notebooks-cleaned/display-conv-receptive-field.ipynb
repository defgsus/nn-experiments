{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6415c53-4ef1-4f81-8cb5-3c6e35b831fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b50d9-41fa-48af-96d1-fed059cdb91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_conv(\n",
    "        size: int, \n",
    "        kernel_size: int, \n",
    "        dilation: Union[int, Iterable[int]], \n",
    "        layers: int = 6, \n",
    "        zoom: int = 5,\n",
    "        middle: bool = False,\n",
    "):    \n",
    "    inp = torch.zeros(1, 3, size)\n",
    "    inp[..., size//2 if middle else 0] = 1\n",
    "    \n",
    "    grid = []\n",
    "    def add_pic(state):\n",
    "        img = state.permute(1, 0, 2)  # take the one batch dimension as height\n",
    "        #img = (img.abs() / img.max()).pow(.3)\n",
    "        grid.append(resize(img.abs().clamp(0, 1), zoom))\n",
    "        \n",
    "    add_pic(inp)\n",
    "    for i, dil in enumerate(param_make_list(dilation, layers, \"dilation\")):\n",
    "        padding = int(math.floor(kernel_size / 2)) * dil\n",
    "        conv = nn.Conv1d(3, 3, kernel_size, padding=padding, dilation=dil, bias=False)\n",
    "        conv.weight[:] = .5 * torch.rand(conv.weight.shape, generator=torch.Generator().manual_seed(23))\n",
    "        #conv.bias[:] = 0.\n",
    "        inp = conv(inp)\n",
    "        #print(inp)\n",
    "        #inp = F.gelu(inp)\n",
    "        add_pic(inp)\n",
    "        \n",
    "    display(VF.to_pil_image(make_grid(grid, nrow=1, pad_value=.3)))\n",
    "    if not middle:\n",
    "        print(\"receptive field radius:\", inp[0, 0].argwhere().flatten(0)[-1].item())\n",
    "        \n",
    "plot_conv(\n",
    "    250, \n",
    "    #layers=3, dilation=[3, 5, 1],\n",
    "    #kernel_size=13, layers=4, dilation=[3, 5, 7, 1],\n",
    "    #kernel_size=7, layers=3, dilation=[1, 1, 1],\n",
    "    #kernel_size=13, layers=3, dilation=[5, 7, 1],\n",
    "    kernel_size=13, layers=6, dilation=[2, 3, 5, 7, 9, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d040a0-5b51-4873-8b2e-6a19172d36d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d5331-2b6d-44c7-aa9c-6658f50ac815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc7c36-6ef1-4639-8d9f-20f487be0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock1d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        padding: Union[int, str] = \"same\",\n",
    "        dilation: int = 1,\n",
    "        bias: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth_conv = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=in_channels,\n",
    "            bias=bias,\n",
    "        )\n",
    "        self.point_conv = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=1,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.depth_conv.weight\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.depth_conv(x)\n",
    "        x = self.point_conv(x)\n",
    "        return x\n",
    "\n",
    "m = DepthConv1d(1, 3, dilation=3)\n",
    "print(f\"params: {num_module_parameters(m):,}\")\n",
    "\n",
    "inp = torch.ones(1, 1, 10)\n",
    "outp = m(inp)\n",
    "print(inp.shape, \"->\", outp.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
