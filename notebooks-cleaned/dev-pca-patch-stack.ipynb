{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22924707-ea3d-44a9-b4a6-863db2562d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a2400-9518-41e3-96a9-08c523b657af",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ds = Imagenet1kIterableDataset(\n",
    "    size_filter=[\n",
    "        (500, 375)\n",
    "        #(375, 500),\n",
    "        #(500, 500),\n",
    "        #(500, 400),\n",
    "    ],\n",
    ")\n",
    "grid = []\n",
    "for image in tqdm(image_ds.limit(64)):\n",
    "    #grid.append(image_resize_crop(image, (64, 64)))\n",
    "    grid.append(resize(image, 1/4))\n",
    "display(VF.to_pil_image(make_grid(grid, nrow=8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c4bfc-a491-4f9a-8402-39cc3129095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = []\n",
    "for image in tqdm(image_ds.shuffle(1000).limit(2000)):\n",
    "    #grid.append(image_resize_crop(image, (64, 64)))\n",
    "    grid.append(resize(image, 1/16))\n",
    "display(VF.to_pil_image(make_grid(grid, nrow=32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc27c5f-c5b4-45e8-9d25-0061b10adf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ds = ImageFolderIterableDataset(\n",
    "    \"~/Pictures/__diverse\",\n",
    "    recursive=True,\n",
    "    force_channels=3,\n",
    ")\n",
    "for image in image_ds.limit(2)\n",
    "    display(VF.to_pil_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d21794-de92-46d7-aae9-21edae4eb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 31\n",
    "\n",
    "patch_ds = ImagePatchIterableDataset(\n",
    "    image_ds.shuffle(1000),\n",
    "    shape=PATCH_SIZE,\n",
    "    stride=PATCH_SIZE // 2,\n",
    "    interleave_images=64,\n",
    ")\n",
    "VF.to_pil_image(make_grid(list(patch_ds.limit(64**2)), nrow=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54261efe-3111-48e4-82b1-3857b9d1de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "NUM_PATCHES = 128\n",
    "pca = IncrementalPCA(NUM_PATCHES)\n",
    "\n",
    "try:\n",
    "    for batch in tqdm(DataLoader(patch_ds, batch_size=1024)):\n",
    "        pca.partial_fit(batch.numpy().reshape(batch.shape[0], 3 * PATCH_SIZE**2))\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4283e-1090-4886-b9f6-bee71ca06c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = torch.from_numpy(pca.components_).reshape(NUM_PATCHES, 3, PATCH_SIZE, PATCH_SIZE)\n",
    "print(patches.min(), patches.max(), patches.mean())\n",
    "def normalize(patch: torch.Tensor):\n",
    "    patch = patch - patch.min()\n",
    "    patch = patch / patch.max()\n",
    "    #patch += .5\n",
    "    return patch.clamp(0, 1)\n",
    "VF.to_pil_image(resize(\n",
    "    #signed_to_image(make_grid(patches.unsqueeze(1), nrow=16))\n",
    "    make_grid([normalize(p) for p in patches], nrow=16)\n",
    "    , 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec0031-e389-44bf-97dc-0baf4b0f907c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2b2d9-0fd2-4192-8a15-6a1786afaa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = Path(\"data\")\n",
    "os.makedirs(FILEPATH, exist_ok=True)\n",
    "PATCHES_FILENAME = FILEPATH / f\"pca-patches-{NUM_PATCHES}-{PATCH_SIZE}x{PATCH_SIZE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458feb2-9b5b-4637-97ec-09d27c6e5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(patches, PATCHES_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d464c-d00e-44ef-a14a-c03f4cf752f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7fb352-b3df-47b8-87b1-801723ec9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = next(iter(image_ds.skip(0)))#[..., :512, :512]\n",
    "conv = nn.Conv2d(3, NUM_PATCHES, PATCH_SIZE, bias=False, stride=PATCH_SIZE // 2)\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3cf32b-acbc-4304-bf1d-41d26291bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat1 = conv(image)\n",
    "print(feat1.shape)\n",
    "VF.to_pil_image(resize(make_grid(\n",
    "    [(signed_to_image(i)*3).clamp(0, 1) for i in feat1]\n",
    "    #[normalize(i) for i in feat1]\n",
    "    #normalize(feat1[3:6])\n",
    "    , nrow=2), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133970e-fc9e-4bbc-8a37-e389fb8f32e5",
   "metadata": {},
   "source": [
    "# stage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d514efc-27f4-450f-9d64-df67796fabbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PATCHES2 = NUM_PATCHES\n",
    "pca2 = IncrementalPCA(NUM_PATCHES2)\n",
    "\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for image in tqdm(image_ds):\n",
    "            features = conv(image)\n",
    "            for batch in iter_image_patches(features, shape=PATCH_SIZE, stride=PATCH_SIZE//2, batch_size=1024):\n",
    "                #print(batch.shape)\n",
    "                pca2.partial_fit(batch.numpy().reshape(batch.shape[0], -1))\n",
    "        #\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ec035-ecc8-4b12-835f-c265b8b2fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches2 = torch.from_numpy(pca2.components_).reshape(NUM_PATCHES2, NUM_PATCHES, PATCH_SIZE, PATCH_SIZE)\n",
    "print(patches2.shape, patches2.min(), patches2.max(), patches2.mean())\n",
    "VF.to_pil_image(resize(\n",
    "    make_grid([normalize(p[o:o+1]) for p in patches2 for o in range(16)], nrow=16)\n",
    "    , 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b8075-39a7-4e99-bde2-134f678609a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805714f-3e61-46ca-9ba8-7b3a51a48731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe0507-44ab-4213-a6c2-27026b3d5cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37912ed1-71b2-48b5-b1be-1807d16c6c7d",
   "metadata": {},
   "source": [
    "# dataset from .pt files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c89df2a-15a5-4187-bed8-7f487b2c004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorFilesIterableDataset(BaseIterableDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            path: Union[str, Path],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._path = Path(path)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file in sorted(self._path.glob(\"*.pt\")):\n",
    "            tensor = torch.load(file)\n",
    "            for t in tensor:\n",
    "                yield t\n",
    "\n",
    "tensor_ds = TensorFilesIterableDataset(\n",
    "    config.BIG_DATASETS_PATH / \"imagenet1k-uint8-by-shape\" / \"3x375x500\"\n",
    ")\n",
    "for image in tqdm(tensor_ds):\n",
    "    pass\n",
    "    #grid.append(image_resize_crop(image, (128, 128)))\n",
    "#display(VF.to_pil_image(make_grid(grid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1f7f7-7767-42e4-bff7-fc3911eb3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "96/2**3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
