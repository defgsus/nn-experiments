{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d9249-e9ca-4efe-81af-dbf534c86518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union, Dict\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset, RandomSampler\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display\n",
    "\n",
    "from src.datasets import *\n",
    "from src.algo import GreedyLibrary\n",
    "from src.util.image import *\n",
    "from src.util import to_torch_device\n",
    "from src.patchdb import PatchDB\n",
    "from src.models.encoder import *\n",
    "from scripts import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417e63d-de1b-4986-9c62-a0a5f3d91ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_samples(ds, count=30*30, nrow=30, batch_size=10, skip: int = 0):\n",
    "    cur_count = 0\n",
    "    batches = []\n",
    "    try:\n",
    "        for batch in DataLoader(ds, batch_size=batch_size):\n",
    "            if isinstance(batch, (list, tuple)):\n",
    "                batch = batch[0]\n",
    "            if cur_count > skip:\n",
    "                batches.append(batch)\n",
    "            \n",
    "            cur_count += batch.shape[0]\n",
    "            if cur_count - skip >= count:\n",
    "                break\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    if not batches:\n",
    "        return \"nothin'\"\n",
    "    batch = torch.concat(batches)[:count]\n",
    "        \n",
    "    return VF.to_pil_image(make_grid(batch, nrow=nrow))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1cb0b7-8703-4dfe-9520-8a51f75608be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_samples(datasets.all_patch_datasets((1, 32, 32)))\n",
    "#plot_samples(datasets.photo_patch_dataset((1, 32, 32), \"/home/bergi/Pictures/photos\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b4225-e755-454b-91a0-308fdaf1a6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SHAPE = [1, 32, 32]\n",
    "\n",
    "def _scales(shape: Tuple[int, int]):\n",
    "    size = min(shape)\n",
    "    shape_size = min(SHAPE[-2:])\n",
    "    scales = []\n",
    "    for s in [\n",
    "        #2.,\n",
    "        1., \n",
    "        1./2., \n",
    "        1./5, \n",
    "        1./10, 1./20., 1./30.\n",
    "    ]:\n",
    "        if s * size >= shape_size and s * size < 10_000:\n",
    "            scales.append(s)\n",
    "    return scales\n",
    "        \n",
    "def _stride(shape: Tuple[int, int]):\n",
    "    # print(shape)\n",
    "    size = min(shape)\n",
    "    shape_size = min(SHAPE[-2:])\n",
    "    return max(1, min(shape_size, int(size / 10000)))\n",
    "    #if size <= 512:\n",
    "    #    return tuple(max(1, s // 5) for s in SHAPE[-2:])\n",
    "    #return SHAPE[-2:]\n",
    "\n",
    "ds_crop = make_image_patch_dataset(\n",
    "    verbose_image=True,\n",
    "    #path=\"~/Pictures/photos\", \n",
    "    #path=\"../db/images/kali\", \n",
    "    \n",
    "    #path=\"../db/images/textures/topping.png\", \n",
    "    \n",
    "    #path=\"/home/bergi/Pictures/__diverse/bob-dobbs_raster_trans.png\", \n",
    "    #path=\"/home/bergi/Pictures/__diverse/100_1600.jpg\",\n",
    "    #path=\"/home/bergi/Pictures/__diverse/100_1600.jpg\",\n",
    "    #path=\"/home/bergi/Pictures/__diverse/Pollock1.jpg\",\n",
    "    #path=\"/home/bergi/Pictures/hyperbolic_helicopter.jpg\",\n",
    "    #path=\"/home/bergi/Pictures/diffusion/cells-07.jpeg\",\n",
    "    path=\"/home/bergi/prog/python/github/magic-pen/results/pattern/3/organic-structures-fantasies-of-friendship-be-0000.jpg\",\n",
    "    \n",
    "    recursive=True,\n",
    "    shape=SHAPE,\n",
    "    #max_images=1,\n",
    "    max_image_bytes=1024 * 1024 * 1024 * 1,\n",
    "    #scales=[1./12., 1./6, 1./3, 1.],\n",
    "    #scales=[1./70., 1./40, 1./20, 1./10, 1./5, 1./3],\n",
    "    scales=_scales,\n",
    "    stride=5,#_stride,\n",
    "    #interleave_images=4,\n",
    "    #image_shuffle=5,\n",
    "    #transforms=[lambda x: VF.resize(x, tuple(s // 6 for s in x.shape[-2:]))], stride=5,\n",
    "    with_pos=True,\n",
    "    with_filename=True,\n",
    "    with_scale=True,\n",
    ")\n",
    "if 1:\n",
    "    ds_unique = ImageFilterIterableDataset(ds_crop, ImageFilter(\n",
    "        #min_std=0.03\n",
    "        #max_std=.3,\n",
    "        #min_compression_ratio=.8,\n",
    "        #max_compression_ratio=.95,\n",
    "    )) \n",
    "    ds_unique = DissimilarImageIterableDataset(\n",
    "        ds_unique, verbose=True,\n",
    "        max_similarity=.99, max_age=10_000, \n",
    "    )\n",
    "    #ds_unique = DissimilarImageIterableDataset(\n",
    "    #    ds_unique, verbose=True,\n",
    "    #    max_similarity=0.6, max_age=10_000, \n",
    "    #    encoder=\"encoderconv:../models/encoderconv/encoder-1x32x32-128-photo-5.pt\",\n",
    "    #)\n",
    "\n",
    "plot_samples(IterableShuffle(ds_unique, max_shuffle=0_000), count=30*30, skip=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6301f3-99e4-40c3-8d30-f20d76cb1519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "560118c5-753f-45a3-98fe-0728a2c65176",
   "metadata": {},
   "source": [
    "# build PatchDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700be17a-d510-457c-84ab-4d43cd2be52d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls ../models/encoder2d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68dd18-d68e-4d67-8fac-8f7150c9b96d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = EncoderConv2d.from_torch(\"../models/encoder2d/conv-1x32x32-128-all1.pt\", device=\"cpu\")\n",
    "#encoder = BoltzmanEncoder2d.from_torch(\"../models/encoder2d/boltzman-1x32x32-128-photo-300M.pt\", device=\"cpu\")\n",
    "encoder.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec66863c-8624-48da-a5f1-eb386486569e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls ../db/*.patchdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684cb4df-e6eb-4b1f-904b-ad89a04233ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = PatchDB(\"../db/sand-1x32x32-convall1.patchdb\", writeable=True)\n",
    "\n",
    "db.clear()\n",
    "\n",
    "count = 0\n",
    "last_count = 0\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        with db:\n",
    "            for patches, positions, scales, filenames in DataLoader(ds_unique, batch_size=64):\n",
    "                embeddings = encoder(patches)\n",
    "                embeddings = embeddings / embeddings.norm(dim=1, keepdim=True)\n",
    "                # embeddings = torch.round(embeddings, decimals=5)\n",
    "                #display(VF.to_pil_image(make_grid(patches)))\n",
    "                for embedding, pos, scale, filename in zip(embeddings, positions, scales, filenames):\n",
    "                    rect = pos.tolist() + list(patches[0].shape[-2:])\n",
    "                    rect = [int(r / scale) for r in rect]\n",
    "                    db.add_patch(filename, rect, embedding)\n",
    "                    count += 1\n",
    "\n",
    "                if count - last_count > 50_000:\n",
    "                    last_count = count\n",
    "                    db.flush()\n",
    "                    print(f\"{db.size_bytes():,} bytes\")\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "f\"{db.size_bytes():,} bytes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a085b-1a81-4f56-9f53-220c29ee93a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5c4fb-ab65-4c16-90a8-da2a24f853bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720dc696-968e-4078-8a49-4bd1edc62dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a8bf0-cab1-4a76-8945-6c300a725acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2ab2c4-7446-4f83-a488-fead09666889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a49957-640e-4361-a908-2dc1ff057304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbf09b-ac37-473f-bd25-90f9fdae5f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b684d-901a-4612-a1cf-cbbcb85ba1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "with gzip.open(db.filename, \"rt\") as fp:\n",
    "    print(fp.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51383e5-2e33-4d2c-896f-f2675591708c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "math.prod(embedding.shape) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5a7b7-3b53-43fb-8d32-3e5840f4ac2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "a = embedding.detach().numpy()\n",
    "print(len(base64.b64encode(a.data)))\n",
    "len(json.dumps(a.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33591e5d-d8ea-4134-a057-3aef0e343af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e2c6b-bde9-45ae-a959-e5d71aca36e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_unique = ds_crop#DissimilarImageIterableDataset(ds_crop, max_similarity=.99, max_age=200_000, verbose=False)\n",
    "ds_unique = DissimilarImageIterableDataset(ds_unique, max_similarity=.4, max_age=200_000, verbose=True, \n",
    "                                           encoder=\"encoderconv:../models/encoderconv/encoder-1x32x32-128-small-photo-3.pt\")\n",
    "plot_samples(ds_unique, count=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510e4a2-6ffa-4cf0-8607-a6859f3b994f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "32*32\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
