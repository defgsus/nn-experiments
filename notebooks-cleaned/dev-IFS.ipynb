{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d82c9a-daae-4a20-9236-ade1313a72a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.datasets import *\n",
    "from src.util.image import * \n",
    "from src.util import ImageFilter\n",
    "from src.algo import Space2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22f157-1eab-402a-bd73-2d8d28474056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IFS_Torch:\n",
    "    \n",
    "    def __init__(self, seed: Optional[int] = None, num_parameters: int = 5):\n",
    "        self.rng = torch.Generator().manual_seed(seed if seed is not None else int(time.time() * 1000))\n",
    "        self.parameters = torch.rand((num_parameters, 6), generator=self.rng) * 2. - 1.\n",
    "        self.probabilities = torch.rand((num_parameters, ), generator=self.rng)\n",
    "        \n",
    "    def iter_coordinates(self, num_iterations: int) -> Generator[Tuple[float, float], None, None]:\n",
    "        x, y = 0., 0.\n",
    "        for iteration in range(num_iterations):\n",
    "            param_index = None\n",
    "            while param_index is None:\n",
    "                idx = torch.randint(0, self.parameters.shape[0], (1,), generator=self.rng).item()\n",
    "                if torch.rand(1, generator=self.rng).item() < self.probabilities[idx]:\n",
    "                    param_index = idx\n",
    "            \n",
    "            a, b, c, d, e, f = self.parameters[param_index]\n",
    "            \n",
    "            x, y = (\n",
    "                x * a + y * b + e,\n",
    "                x * c + y * d + f\n",
    "            )\n",
    "            \n",
    "            yield x, y\n",
    "\n",
    "    def render_coordinates(self, shape: Tuple[int, int], num_iterations: int, padding: int = 2) -> torch.Tensor:\n",
    "        coords = torch.Tensor(list(ifs.iter_coordinates(num_iterations)))\n",
    "        min_x, max_x = coords[:, 0].min(), coords[:, 0].max()\n",
    "        min_y, max_y = coords[:, 1].min(), coords[:, 1].max()\n",
    "        coords[:, 0] = (coords[:, 0] - min_x) / (max_x - min_x) * (shape[-1] - padding * 2)\n",
    "        coords[:, 1] = (coords[:, 1] - min_y) / (max_y - min_y) * (shape[-2] - padding * 2)\n",
    "        return coords.to(torch.int16)\n",
    "    \n",
    "    def render_image_tensor(self, shape: Tuple[int, int], num_iterations: int, padding: int = 2) -> torch.Tensor:\n",
    "        coords = self.render_coordinates(shape, num_iterations, padding)\n",
    "        image = torch.zeros((1, *shape))\n",
    "        for x, y in coords:\n",
    "            image[0, y, x] = 1\n",
    "            \n",
    "        return image.clamp(0, 1)\n",
    "        \n",
    "ifs = IFS_Torch()\n",
    "start_time = time.time()\n",
    "img = ifs.render_image_tensor((256, 256), 100_000)\n",
    "seconds = time.time() - start_time\n",
    "print(seconds)\n",
    "VF.to_pil_image(img)\n",
    "#coords = np.array(list(ifs.iter_coordinates(100)))\n",
    "#px.scatter(x=coords[:, 0], y=coords[:, 1], height=400, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbdb54-d98a-4041-9bd0-cc697984b963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_samples(\n",
    "        iterable, \n",
    "        total: int = 32, \n",
    "        nrow: int = 8, \n",
    "        return_image: bool = False, \n",
    "        show_compression_ratio: bool = False,\n",
    "        label: Optional[Callable] = None,\n",
    "):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    f = ImageFilter()\n",
    "    try:\n",
    "        for entry in tqdm(iterable, total=total):\n",
    "            image = entry\n",
    "            if isinstance(entry, (list, tuple)):\n",
    "                image = entry[0]\n",
    "            if image.ndim == 4:\n",
    "                image = image.squeeze(0)\n",
    "            samples.append(image)\n",
    "            if show_compression_ratio:\n",
    "                labels.append(round(f.calc_compression_ratio(image), 3))\n",
    "            elif label is not None:\n",
    "                labels.append(label(entry))\n",
    "                \n",
    "            if len(samples) >= total:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    if labels:\n",
    "        image = VF.to_pil_image(make_grid_labeled(samples, nrow=nrow, labels=labels))\n",
    "    else:\n",
    "        image = VF.to_pil_image(make_grid(samples, nrow=nrow))\n",
    "    if return_image:\n",
    "        return image\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bc099-ce7b-46d9-9542-fb33b0e8a1eb",
   "metadata": {},
   "source": [
    "# IFS class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b5c44-69a0-4c36-a631-d9004fe39961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IFS:\n",
    "    max_coordinate = 1e10\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            seed: Optional[int] = None, \n",
    "            num_parameters: int = 2,\n",
    "            parameters: Optional[np.ndarray] = None,\n",
    "            probabilities: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        self.rng = np.random.Generator(np.random.MT19937(\n",
    "            seed if seed is not None else random.randint(0, int(1e10))\n",
    "        ))\n",
    "        self.rng.bytes(100)\n",
    "        self.parameters = self.rng.uniform(-1., 1., (num_parameters, 6))\n",
    "        self.probabilities = self.rng.uniform(0., 1., (num_parameters, ))\n",
    "        if parameters is not None:\n",
    "            self.parameters = parameters\n",
    "        if probabilities is not None:\n",
    "            self.probabilities = probabilities\n",
    "        \n",
    "    def iter_coordinates(self, num_iterations: int) -> Generator[Tuple[float, float], None, None]:\n",
    "        x, y = 0., 0.\n",
    "        for iteration in range(num_iterations):\n",
    "            param_index = None\n",
    "            while param_index is None:\n",
    "                idx = self.rng.integers(0, self.parameters.shape[0])\n",
    "                if self.rng.uniform(0., 1.) < self.probabilities[idx]:\n",
    "                    param_index = idx\n",
    "            \n",
    "            a, b, c, d, e, f = self.parameters[param_index]\n",
    "            \n",
    "            x, y = (\n",
    "                x * a + y * b + e,\n",
    "                x * c + y * d + f\n",
    "            )\n",
    "            if np.abs(x) > self.max_coordinate or np.abs(y) > self.max_coordinate:\n",
    "                #print(f\"early stop at iteration {iteration}\")\n",
    "                break\n",
    "                \n",
    "            if not (np.isnan(x) or np.isnan(y) or np.isinf(x) or np.isinf(y)):\n",
    "                yield x, y\n",
    "            else:\n",
    "                #print(f\"early stop at iteration {iteration}\")\n",
    "                break\n",
    "\n",
    "    def render_coordinates(self, shape: Tuple[int, int], num_iterations: int, padding: int = 2) -> np.ndarray:\n",
    "        coords = np.array(list(self.iter_coordinates(num_iterations)))\n",
    "        min_x, max_x = coords[:, 0].min(), coords[:, 0].max()\n",
    "        min_y, max_y = coords[:, 1].min(), coords[:, 1].max()\n",
    "        if max_x != min_x:\n",
    "            coords[:, 0] = (coords[:, 0] - min_x) / (max_x - min_x) * (shape[-1] - padding * 2) + padding\n",
    "        if max_y != min_y:\n",
    "            coords[:, 1] = (coords[:, 1] - min_y) / (max_y - min_y) * (shape[-2] - padding * 2) + padding\n",
    "        return coords.astype(np.uint16)\n",
    "    \n",
    "    def render_image(\n",
    "            self, \n",
    "            shape: Tuple[int, int], \n",
    "            num_iterations: int, \n",
    "            padding: int = 2,\n",
    "            alpha: float = 0.1,\n",
    "            patch_size: int = 1,\n",
    "    ) -> np.ndarray:\n",
    "        \n",
    "        extra_padding = 0\n",
    "        if patch_size > 1:\n",
    "            extra_padding = patch_size\n",
    "            shape = (shape[-2] + extra_padding * 2, shape[-1] + extra_padding * 2)\n",
    "            \n",
    "        coords = self.render_coordinates(shape, num_iterations, padding + extra_padding)\n",
    "        image = np.zeros((1, *shape))\n",
    "        \n",
    "        if patch_size <= 1:\n",
    "            for x, y in coords:\n",
    "                image[0, y, x] += alpha\n",
    "                \n",
    "        else:\n",
    "            half_patch_size = patch_size // 2\n",
    "            patch = np.hamming(patch_size).repeat(patch_size).reshape(patch_size, patch_size)\n",
    "            patch *= patch.T * alpha\n",
    "            \n",
    "            for x, y in coords:\n",
    "                x -= half_patch_size\n",
    "                y -= half_patch_size\n",
    "                image[0, y:y + patch_size, x:x + patch_size] += patch\n",
    "            \n",
    "            \n",
    "            image = image[:, extra_padding:-extra_padding, extra_padding:-extra_padding]\n",
    "        \n",
    "        return image.clip(0, 1)\n",
    "    \n",
    "images = []\n",
    "for i in tqdm(range(8)):\n",
    "    ifs = IFS(seed=i+0)\n",
    "    img = ifs.render_image((128, 128), 10_000)\n",
    "    images.append(torch.Tensor(img))\n",
    "\n",
    "grid = VF.to_pil_image(make_grid_labeled(images, nrow=8, labels=True))\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8bccd4-8684-4a2f-92ff-6b844aba117a",
   "metadata": {},
   "source": [
    "# num-parameters variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab88ee6-9a48-43a8-9e1f-dfb3b10aad87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrow = 32\n",
    "images = []\n",
    "for i in tqdm(range(nrow * 4)):\n",
    "    ifs = IFS(num_parameters=2 + i // nrow)\n",
    "    img = ifs.render_image((128, 128), 10_000)\n",
    "    images.append(torch.Tensor(img))\n",
    "#print(seconds)\n",
    "grid = VF.to_pil_image(make_grid(images, nrow=nrow))\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bf9a6-5567-46b9-abff-f69e7067518a",
   "metadata": {},
   "source": [
    "# class variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b6952-dcfd-43f0-b539-3ffc86623257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in tqdm(range(8*4)):\n",
    "    if i % 8 == 0:\n",
    "        ifs = IFS()\n",
    "    if i % 8 == 7:\n",
    "        images.append(\n",
    "            signed_to_image(images[-7] - images[-1]).clamp(0, 1)\n",
    "        )\n",
    "    else:\n",
    "        img = ifs.render_image((128, 128), 10_000)\n",
    "        images.append(torch.Tensor(img).repeat(3, 1, 1))\n",
    "\n",
    "grid = VF.to_pil_image(make_grid(images, nrow=8))\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b42648-c82f-4bc8-8b1f-741f4bfc7586",
   "metadata": {},
   "source": [
    "# parameter permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ce2dd-d463-447a-a66c-5cf3ccc339f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in tqdm(range(8*8)):\n",
    "    ifs = IFS(seed=i // 8)\n",
    "    ifs.parameters += 0.03 * np.random.uniform(-1., 1., ifs.parameters.shape)\n",
    "    if i % 8 == 7:\n",
    "        images.append(\n",
    "            signed_to_image(images[-7] - images[-1]).clamp(0, 1)\n",
    "        )\n",
    "    else:\n",
    "        img = ifs.render_image((128, 128), 10_000)\n",
    "        images.append(torch.Tensor(img).repeat(3, 1, 1))\n",
    "\n",
    "grid = VF.to_pil_image(make_grid(images, nrow=8))\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369944a4-ac61-4f79-bebf-23e8b5907e1b",
   "metadata": {},
   "source": [
    "# iteration depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73cb24-c7fa-4e9e-af0f-4187e2dd41fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "ITERATIONS = [100, 1000, 10_000, 50_000, 100_000, 200_000, 500_000, 1_000_000]\n",
    "for i in tqdm(range(8*4)):\n",
    "    ifs = IFS(seed=i // 8)\n",
    "    img = ifs.render_image((128, 128), ITERATIONS[i % 8])\n",
    "    images.append(torch.Tensor(img))\n",
    "\n",
    "grid = VF.to_pil_image(make_grid(images, nrow=8))\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1e657-c943-41a7-8535-2b4c99789b7f",
   "metadata": {},
   "source": [
    "# CLIP guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba01260-2fff-4acd-8c9c-063ed3dfdd39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import clip as cliplib\n",
    "CODE_SIZE = 512\n",
    "class ToRGB(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.repeat(1, 3, 1, 1)\n",
    "class ToDevice(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.half().cuda()\n",
    "class FromDevice(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.cpu().to(torch.float32)\n",
    "clip, preproc = cliplib.load(\"ViT-B/32\")\n",
    "encoder = nn.Sequential(\n",
    "    VT.Resize((224, 224), VF.InterpolationMode.BICUBIC),\n",
    "    ToRGB(),\n",
    "    preproc.transforms[-1],\n",
    "    ToDevice(),\n",
    "    clip.visual,\n",
    "    FromDevice(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a23aedd-5a6a-4560-b675-27c1c38324eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    target_features = clip.encode_text(cliplib.tokenize([\n",
    "        \"drawing of a building\", #\"leave\", #\"bird\"\n",
    "    ]).cuda()).cpu().float()\n",
    "    \n",
    "    target_features /= target_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    for seed in tqdm(range(1000)):\n",
    "        ifs = IFS(seed=seed)\n",
    "        image = torch.Tensor(ifs.render_image((32, 32), 1000, alpha=.5))\n",
    "        features = encoder(image.unsqueeze(0))\n",
    "        features /= features.norm(dim=-1, keepdim=True)\n",
    "        dots = features @ target_features.T\n",
    "        if torch.any(dots > .23):\n",
    "            image = torch.Tensor(ifs.render_image((128, 128), 10000, alpha=.2))\n",
    "            print(dots)\n",
    "            display(VF.to_pil_image(image))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9dde27-4ab3-4825-960a-1d3e7f8ef5bf",
   "metadata": {},
   "source": [
    "# dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e26413-36d7-440a-ad93-b2496b066d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IFSClassIterableDataset(IterableDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        shape: Tuple[int, int],\n",
    "        num_classes: int,\n",
    "        num_instances_per_class: int = 1,\n",
    "        num_iterations: int = 10_000,\n",
    "        seed: Optional[int] = None,\n",
    "        alpha: float = 0.1,\n",
    "        patch_size: int = 1,\n",
    "        parameter_variation: float = 0.03,\n",
    "        parameter_variation_max: Optional[float] = None,\n",
    "        alpha_variation: float = 0.05,\n",
    "        patch_size_variations: Optional[Iterable[int]] = None,\n",
    "        num_iterations_variation: int = 0,\n",
    "        image_filter: Optional[ImageFilter] = None,\n",
    "        filter_num_iterations: Optional[int] = None,\n",
    "        filter_shape: Optional[Tuple[int, int]] = None,\n",
    "        filter_alpha: Optional[float] = None,\n",
    "    ):\n",
    "        self.shape = shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_instances_per_class = num_instances_per_class\n",
    "        self.num_iterations = num_iterations\n",
    "        self.seed = seed if seed is not None else random.randint(0, 1e10)\n",
    "        self.alpha = alpha\n",
    "        self.patch_size = patch_size\n",
    "        self.parameter_variation = parameter_variation\n",
    "        self.parameter_variation_max = parameter_variation_max\n",
    "        self.alpha_variation = alpha_variation\n",
    "        self.patch_size_variations = list(patch_size_variations) if patch_size_variations is not None else None\n",
    "        self.num_iterations_variation = num_iterations_variation\n",
    "        \n",
    "        self.image_filter = image_filter\n",
    "        self.filter_num_iterations = filter_num_iterations\n",
    "        self.filter_shape = filter_shape\n",
    "        self.filter_alpha = filter_alpha\n",
    "        \n",
    "        self.rng = np.random.Generator(np.random.MT19937(\n",
    "            seed if seed is not None else random.randint(0, int(1e10))\n",
    "        ))\n",
    "        self.rng.bytes(42)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.num_classes * self.num_instances_per_class\n",
    "    \n",
    "    def _iter_class_seeds(self) -> Generator[int, None, None]:\n",
    "        class_index = 0\n",
    "        class_count = 0\n",
    "        while class_count < self.num_classes:\n",
    "            seed = class_index ^ self.seed\n",
    "            \n",
    "            ifs = IFS(seed=seed)\n",
    "            class_index += 1\n",
    "            \n",
    "            if self.image_filter is not None:\n",
    "            \n",
    "                image = torch.Tensor(ifs.render_image(\n",
    "                    shape=self.filter_shape or self.shape,\n",
    "                    num_iterations=self.filter_num_iterations or self.num_iterations,\n",
    "                    alpha=self.filter_alpha or self.alpha,\n",
    "                    patch_size=self.patch_size,\n",
    "                ))\n",
    "                if not self.image_filter(image):\n",
    "                    continue\n",
    "            \n",
    "            yield seed\n",
    "            class_count += 1\n",
    "        \n",
    "    def __iter__(self) -> Generator[Tuple[torch.Tensor, int], None, None]:\n",
    "        for class_index, seed in enumerate(self._iter_class_seeds()):\n",
    "            \n",
    "            instance_count = 0\n",
    "            base_mean = None\n",
    "            while instance_count < self.num_instances_per_class:\n",
    "                ifs = IFS(seed=seed)\n",
    "                \n",
    "                alpha = self.alpha\n",
    "                patch_size = self.patch_size\n",
    "                num_iterations = self.num_iterations\n",
    "                \n",
    "                if instance_count > 0:\n",
    "                    t = (instance_count + 1) / self.num_instances_per_class\n",
    "                    \n",
    "                    amt = self.parameter_variation\n",
    "                    if self.parameter_variation_max is not None:\n",
    "                        amt = amt * (1. - t) + t * self.parameter_variation_max\n",
    "                        \n",
    "                    ifs.parameters += amt* self.rng.uniform(-1., 1., ifs.parameters.shape)\n",
    "                    alpha = max(.001, alpha + self.alpha_variation * self.rng.uniform(-1., 1.))\n",
    "                    if self.patch_size_variations is not None:\n",
    "                        patch_size = self.patch_size_variations[self.rng.integers(len(self.patch_size_variations))]\n",
    "                    if self.num_iterations_variation:\n",
    "                        num_iterations += self.rng.integers(self.num_iterations_variation)\n",
    "                    \n",
    "                image = torch.Tensor(ifs.render_image(\n",
    "                    shape=self.shape,\n",
    "                    num_iterations=num_iterations,\n",
    "                    alpha=alpha,\n",
    "                    patch_size=patch_size,\n",
    "                ))\n",
    "                \n",
    "                if base_mean is None:\n",
    "                    base_mean = image.mean()\n",
    "                else:\n",
    "                    mean = image.mean()\n",
    "                    if mean < base_mean / 1.5:\n",
    "                        continue\n",
    "                    \n",
    "                yield image, seed\n",
    "                instance_count += 1\n",
    "                \n",
    "ds = IFSClassIterableDataset(\n",
    "    num_classes=32, num_instances_per_class=32, seed=int(1e6),\n",
    "    shape=(128, 128), num_iterations=10_000, alpha=.15,\n",
    "    #shape=(32, 32), num_iterations=1_000, alpha=1,\n",
    "    parameter_variation=0.05,\n",
    "    parameter_variation_max=0.09,\n",
    "    alpha_variation=0.12,\n",
    "    patch_size_variations=[1, 1, 1, 3, 3, 5],\n",
    "    num_iterations_variation=10_000,\n",
    "    image_filter=ImageFilter(\n",
    "        min_mean=0.2,\n",
    "        max_mean=0.27,\n",
    "        #min_blurred_compression_ratio=.6,\n",
    "    ),\n",
    "    filter_shape=(32, 32),\n",
    "    filter_num_iterations=1000,\n",
    "    filter_alpha=1.\n",
    ")\n",
    "plot_samples(\n",
    "    ds, total=len(ds), nrow=32, \n",
    "    label=lambda i: str(i[1]), # show seed\n",
    "    #label=lambda i: round(float(i[0].mean()), 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea1477-2579-48c9-b544-ecdbb1ac7894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e041889-5678-42d0-b285-4135805b2219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "128*128*16*1000 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8817c-3567-4cae-8198-f729335d16fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VF.to_pil_image(torch.Tensor(IFS(seed=955).render_image((512, 512), 400_000, alpha=0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d26a19b-c3d1-4d10-9512-94ced70a2146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = IFSClassIterableDataset(\n",
    "    num_classes=1, num_instances_per_class=8, seed=955,\n",
    "    shape=(128, 128), num_iterations=10_000, alpha=.2,\n",
    "    #shape=(32, 32), num_iterations=1_000, alpha=1,\n",
    "    image_filter=ImageFilter(\n",
    "        min_mean=0.2,\n",
    "        max_mean=0.27,\n",
    "        #min_blurred_compression_ratio=.6,\n",
    "    ),\n",
    "    filter_shape=(32, 32),\n",
    "    filter_num_iterations=1000,\n",
    "    filter_alpha=1.\n",
    ")\n",
    "plot_samples(\n",
    "    ds, total=len(ds), nrow=8, \n",
    "    label=lambda i: str(i[1]), # show seed\n",
    "    #label=lambda i: round(float(i[0].mean()), 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23397396-4c69-48c2-a2e1-f88af51161e4",
   "metadata": {},
   "source": [
    "# store dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840dec5-af31-40ec-8dd6-b151d0921efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d578435-0465-4d22-bbf4-31a26e795737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = IFSClassIterableDataset(\n",
    "    num_classes=100, num_instances_per_class=8, seed=3746385,\n",
    "    shape=(128, 128), num_iterations=30_000, alpha=.15,\n",
    "    #shape=(32, 32), num_iterations=1_000, alpha=1,\n",
    "    parameter_variation=0.05,\n",
    "    alpha_variation=0.12,\n",
    "    patch_size_variations=[1, 1, 1, 3, 3, 5],\n",
    "    num_iterations_variation=50_000,\n",
    "    image_filter=ImageFilter(\n",
    "        min_mean=0.2,\n",
    "        max_mean=0.27,\n",
    "        #min_blurred_compression_ratio=.6,\n",
    "    ),\n",
    "    filter_shape=(32, 32),\n",
    "    filter_num_iterations=1000,\n",
    "    filter_alpha=1.\n",
    ")\n",
    "plot_samples(dataset, total=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24617b13-c1cd-408c-8293-08030d42b02e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = \"../datasets/ifs-1x128x128-uint8-100x8\"\n",
    "\n",
    "def store_dataset(\n",
    "        images: Iterable,\n",
    "        output_filename,\n",
    "        max_megabyte=4096,\n",
    "):\n",
    "    tensor_batch = []\n",
    "    label_batch = []\n",
    "    tensor_size = 0\n",
    "    last_print_size = 0\n",
    "    try:\n",
    "        for image, label in tqdm(images):\n",
    "\n",
    "            image = (image.clamp(0, 1) * 255).to(torch.uint8)\n",
    "\n",
    "            if len(image.shape) < 4:\n",
    "                image = image.unsqueeze(0)\n",
    "            tensor_batch.append(image)\n",
    "            label_batch.append(torch.Tensor([label]).to(torch.int64))\n",
    "            \n",
    "            tensor_size += math.prod(image.shape)\n",
    "\n",
    "            if tensor_size - last_print_size > 1024 * 1024 * 100:\n",
    "                last_print_size = tensor_size\n",
    "\n",
    "                print(f\"size: {tensor_size:,}\")\n",
    "\n",
    "            if tensor_size >= max_megabyte * 1024 * 1024:\n",
    "                break\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    tensor_batch = torch.cat(tensor_batch)\n",
    "    torch.save(tensor_batch, f\"{output_filename}.pt\")\n",
    "    label_batch = torch.cat(label_batch)\n",
    "    torch.save(label_batch, f\"{output_filename}-labels.pt\")\n",
    "\n",
    "store_dataset(dataset, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b2873a-3b62-482a-8d5e-207e085cbe86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = \"../datasets/ifs-1x128x128-uint8-200x32-seed3482374923\"\n",
    "ds = TensorDataset(\n",
    "    torch.load(f\"{dataset_name}.pt\"),\n",
    "    torch.load(f\"{dataset_name}-labels.pt\"),\n",
    ")\n",
    "print(\"label:\", ds[0][1])\n",
    "VF.to_pil_image(ds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6ef9f-e3d1-4c3f-8471-8e7b4336d782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_samples(DataLoader(ds, shuffle=False), total=32*200, nrow=32, label=lambda e: int(e[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01dc31d-9669-4da0-b86b-0a4b8c8de51d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STORE BIG ONE\n",
    "\n",
    "grid = plot_samples(DataLoader(ds, shuffle=True), total=64*64, nrow=64, label=lambda e: int(e[1]), return_image=True)\n",
    "#grid.save(\"/home/bergi/Pictures/ifs-database-shuffled.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c867a2-b6d5-4707-bc89-5a73c5a27a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de95a48-1866-4e07-a409-f5a6f67080ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = torch.load(f\"../datasets/ifs-1x128x128-uint8-200x32-seed3482374923-labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3df1fe-0a9f-49e0-86fa-2ec93726412e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set(labels.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
