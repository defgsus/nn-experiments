{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5361111-b408-40c4-a200-f5f4f9f6d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *\n",
    "from src.clipig.app.images import LImage\n",
    "from src.util.files.filestream import Filestream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1081d6-5e53-4e20-9414-56bf732aa26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_limage(filename, task: int = 0):\n",
    "    with Filestream(filename) as fs:\n",
    "        limage = LImage()\n",
    "        limage.load_from_filestream(fs, f\"task_{task:02}/limage/config.yaml\")\n",
    "    return limage\n",
    "\n",
    "\n",
    "tiling_ec = load_limage(\"../src/clipig/projects/wang-ec2-grass-water.clipig.tar\").tiling\n",
    "#tiling_ec.attributes_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92354007-6391-4c4d-9bbc-59c6924398cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_set(filename, tiling=tiling_ec, name=\"tileset\"):\n",
    "    if isinstance(filename, PIL.Image.Image):\n",
    "        image_pil = filename\n",
    "    else:\n",
    "        image_pil = PIL.Image.open(filename).convert(\"RGB\")\n",
    "    image = VF.to_tensor(image_pil)\n",
    "    map = tiling.render_tile_map(\n",
    "        image,\n",
    "        tiling.create_map_stochastic_perlin(size=(7*4, 7*4)),\n",
    "    )\n",
    "    display(f\"image:{name}-preview\")\n",
    "    display(VF.to_pil_image(make_grid([\n",
    "        resize(image, 4),\n",
    "        map,\n",
    "    ])))\n",
    "    display(f\"image:{name}-ec-16x16px-7x7map\")\n",
    "    display(image_pil)\n",
    "\n",
    "#show_set(\"/home/bergi/prog/data/game-art/clipig/sdf-gen_grass-100d-cthulhu-dungeon-masked.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1f3bd-215d-4952-9284-a684ac959820",
   "metadata": {},
   "source": [
    "# Generating wang tile sets with CLIP\n",
    "\n",
    "*Tile sets* in computer games are images containing a number of graphics that fit together at certain edges. \n",
    "With these one can draw nice minimal game maps and backgrounds. It would be awesome to create those via text prompts,\n",
    "and i've been trying just long enough...\n",
    "\n",
    "This is in the making since a couple of years. I played with the OpenAI CLIP model, **a lot** and \n",
    "here's a brief summary of my findings so far:\n",
    "\n",
    "### 1. Use *Robust CLIP*\n",
    "\n",
    "*Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models,\n",
    "Christian Schlarmann, Naman Deep Singh, Francesco Croce, Matthias Hein* ([arxiv:2402.12336](https://arxiv.org/abs/2402.12336))\n",
    "\n",
    "To recapitulate quickly: CLIP (**C**ontrastive **L**anguage **I**mage **P**rocessing) is a framework to train an \n",
    "image encoder and a text encoder to output a similar stream of numbers (an encoding) for similar images and/or texts, and, of course, \n",
    "a dissimilar stream of numbers for dissimilar images and/or texts. The stream of numbers as such is not so important.\n",
    "Important is, how close or far different encodings are. \n",
    "\n",
    "A trained model can be used to search for images using a text prompt. But it also can be used to change an image (e.g. noise) \n",
    "to match a certain text prompt. It does not create images in the quality of Stable Diffusion but, in comparison, \n",
    "the process is very easy to control. One can apply a few steps of CLIP prompt-matching to the source image, then make some adjustments,\n",
    "apply some transformations and apply a few more CLIP steps. All in the actual image space.\n",
    "\n",
    "The OpenAI CLIP model was trained on 200,000,000 image/text pairs, if i remember that right, which was never heared of at that time. \n",
    "They released the model code and the weights, because, i guess, they thought it can not be used for evil circumstances. However,\n",
    "the enormous datasets was kept closed. \n",
    "\n",
    "Soon after [LAION](https://laion.ai/projects/) took the effort of creating similar datasets of image/text pairs and released it.\n",
    "The largest of it containg 5 billion image/text pairs!\n",
    "The [Open CLIP](https://github.com/mlfoundations/open_clip) project reimplemented the model **and** the training code\n",
    "and researchers with access to a cluster of expensive GPUS trained new models released new weights.\n",
    "\n",
    "In the following, i use the Robust CLIP model [chs20/FARE4-ViT-B-32-laion2B-s34B-b79K](https://huggingface.co/chs20/FARE4-ViT-B-32-laion2B-s34B-b79K), released on huggingface. As the name suggests, it was initially trained on 2 billion LAION image/text pairs\n",
    "and then *adversarially fine-tuned* on the ImageNet dataset.\n",
    "\n",
    "This fine-tuning makes the model much more usable to *create* images.  \n",
    "Compare these renderings, 1000 steps each, run on a simple gray head template, with prompt: \"the face of h.p. lovecraft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ee679-8c21-453d-a581-1aefa01bd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"image:portrait-lovecraft-clip-vs-robustclip\")\n",
    "limage = load_limage(\"../src/clipig/projects/lovecraft-face-pixelart.clipig.tar\", 2)\n",
    "VF.to_pil_image(resize(make_grid([\n",
    "    limage.layers[2].to_torch(),\n",
    "    limage.layers[3].to_torch(),\n",
    "]), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f5ed8-3b46-4c1a-90fc-c398c1db356e",
   "metadata": {},
   "source": [
    "OpenAI CLIP is left, the Robost CLIP is right.\n",
    "They both do not really look like a photo of Lovecraft and the usual CLIP generation issues, like duplicate mouths and such,\n",
    "are visible but robust CLIP produces much more pronounced renderings and less indefinite color gradients in general. \n",
    "\n",
    "### 2. Know your tiling\n",
    "\n",
    "I certainly recommend this resource **cr31.co.uk**, which is now gone but fortunately mirrored at\n",
    "[boristhebrave.com](https://www.boristhebrave.com/permanent/24/06/cr31/stagecast/wang/intro.html)\n",
    "\n",
    "There is ongoing research about optimal packings of larger tile sets. For the **edge-and-corner-tiles** shown below, i used\n",
    "a variant released by user [caeles](https://opengameart.org/users/caeles) on opengameart.org\n",
    "\n",
    "When `T`, `TL`, `L` aso. are constants with exclusive bits, you can use this definition to represent the tileset:\n",
    "```python\n",
    "EDGE_AND_CORNER_TILESET = [\n",
    "    [TL|L|BL|T|B|TR|R|BR, TL|T|TR|L|BL|B|BR, TL|T|TR|BL, TL|T|TR, TL|T|TR|BR, TL|T|TR|R|BR|BL, TL|L|BL|T|B|TR|R|BR],\n",
    "    [BL|L|TL|T|TR|R|BR, BL|L|TL|T|TR|BR, TL|BL|BR, BL, TR|R|BR, TL|L|BL|TR|BR, TL|T|TR|R|BR|B|BL],\n",
    "    [TL|L|BL|TR, TL|TR|BR, BL|TL|TR|BR, TL|BL|B|BR, BL|TR, TL|TR, TL|T|TR|R|BR],  \n",
    "    [TL|L|BL, TR, TL|TR|R|BR, BL|L|TL|T|TR, TL, BR, BL|TR|R|BR],\n",
    "    [TL|L|BL|BR, BL|B|BR, BL|BR|TR, TL|BL, 0, TR|BR, TL|BL|TR|R|BR],\n",
    "    [TL|L|BL|B|BR|TR, TL|T|TR|BL|BR, TL|TR|BL, TL|BR, BL|BR, BL|B|BR|R|TR, TL|L|BL|TR|R|BR],\n",
    "    [TL|L|BL|T|B|TR|R|BR, TL|L|BL|B|BR|R|TR, TL|L|BL|B|BR, BL|B|BR|TR, TL|TR|BL|B|BR, TL|T|TR|BL|B|BR, TL|BL|B|BR|R|TR], \n",
    "]\n",
    "```\n",
    "\n",
    "To just run experiments without immediately falling back to using a painting application, let's have a little framework to \n",
    "render tile templates. They are useful for testing and as *suggestions* to the image generation pipeline.\n",
    "\n",
    "Thanks to the articles by [iQ](https://iquilezles.org/articles/), every graphics programmer knows\n",
    "about *Signed Distance Functions*. The implicit distance-based representation \n",
    "makes it easy to render smooth masks, boundaries or normal-maps for lighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0758d8-24c1-4bbf-8013-e1a9521dec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"image:edge-corner-demo\")\n",
    "VF.to_pil_image(resize(make_grid([\n",
    "    VF.to_tensor(PIL.Image.open(\"/home/bergi/Pictures/nn/tileset-sdf-gen5.png\")),\n",
    "    VF.to_tensor(PIL.Image.open(\"/home/bergi/Pictures/nn/tileset-sdf-gen5-norm.png\"))\n",
    "]), 2))\n",
    "#PIL.Image.open(\"/home/bergi/Pictures/nn/tileset-sdf-gen.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed9e36-b937-4665-8ece-a9420959a6a0",
   "metadata": {},
   "source": [
    "A random map generator can compare the edges and corner settings of adjacent tiles, and generate endless, seemless random maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46386392-ffda-4e3e-bbd7-fbb4bad0860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_set(\n",
    "    \"/home/bergi/Pictures/nn/tileset-sdf-gen5-16.png\",\n",
    "    #load_limage(\"../src/clipig/projects/wang-ec2-masking.openclip.tar\", 15).layers[0].to_pil()\n",
    "    name=\"edge-corner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcea9-251b-4b82-91e5-4477105d1c9d",
   "metadata": {},
   "source": [
    "(The small image you can download and use as a tileset template. It's 7x7 tiles with 16x16 pixels each)\n",
    "\n",
    "Playing with the objects used on the edges and corners creates quite versatile templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e074a-d09a-4250-836a-fe4c38830f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_set(\n",
    "    load_limage(\"../src/clipig/projects/wang-ec2-grass-water.clipig.tar\", 11).layers[0].to_pil(),\n",
    "    name=\"edge-corner-round\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217290fe-9db6-404d-8950-ebfb43d043a8",
   "metadata": {},
   "source": [
    "These endless random maps can then be fed into CLIP, and the gradient of the prompt target passes back to the tileset image.\n",
    "The map images are slightly rotated and some noise is added to make the result look smoother.\n",
    "\n",
    "Starting from random noise with the prompt \"rpg tile map\", the algorithm yielded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecda6ba-9d0f-4353-a127-ad17530cca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_set(\n",
    "    load_limage(\"../src/clipig/projects/wang-ec2-masking.openclip.tar\", 16).layers[1].to_pil(),\n",
    "    name=\"rpg-tileset-from-noise\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48710959-bf12-445b-97e7-e6d55a719cd4",
   "metadata": {},
   "source": [
    "It's nice and smooth and tileable. But it's also pretty chaotic. \n",
    "Using the spiky lighting template from above as source creates a tileset that better follows the inside/outside \n",
    "logic of the tiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d5887-24bb-430a-836a-91d9bc596b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_set(\n",
    "    load_limage(\"../src/clipig/projects/wang-ec2-masking.openclip.tar\", 16).layers[4].to_pil(),\n",
    "    name=\"rpg-tileset-from-template\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78189109-ebf0-4fe5-964d-a0106d72a314",
   "metadata": {},
   "source": [
    "To gain complete control over the image generation, i use a soft or hard mask to apply different prompts at\n",
    "the inside and outside of the tiling.\n",
    "\n",
    "In this case \"desert wasteland\" and \"top-down view of an ancient castle\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717b3c0-3398-443a-8832-9dc8fcea409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_set(\n",
    "    load_limage(\"../src/clipig/projects/wang-ec2-masking.openclip.tar\", 17).layers[6].to_pil(),\n",
    "    name=\"desert-castle\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e1e9c-d274-4851-8215-6af5f640739c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ff466-3093-4a65-acf6-b3a3fa4f13ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc8f927-3a7d-435e-8c81-7c9e2995b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_set(\"/home/bergi/prog/data/game-art/clipig/sdf-gen_grass-100d-cthulhu-dungeon-masked.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e838c8-4b2f-4589-a26d-58b455726411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
