{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eaf51c-c556-43c0-90ed-cd7de088eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display\n",
    "\n",
    "from src.datasets import *\n",
    "from src.util.image import *\n",
    "from src.util import *\n",
    "from src.algo import *\n",
    "from src.models.decoder import *\n",
    "from src.models.transform import *\n",
    "from src.models.util import *\n",
    "from experiments import datasets\n",
    "\n",
    "def resize(img, scale: float, mode: VF.InterpolationMode = VF.InterpolationMode.NEAREST):\n",
    "    return VF.resize(img, [max(1, int(s * scale)) for s in img.shape[-2:]], mode, antialias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbf8a2-56af-4275-af13-bac5d7c136fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = VF.to_tensor(PIL.Image.open(\n",
    "    #\"/home/bergi/Pictures/diffusion/cthulhu-06.jpeg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/HourSlack-EarsBleed-2-72SM.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/2000_subgenius_bobco_primer.jpg\"\n",
    "    \"/home/bergi/Pictures/__diverse/longtime.png\"\n",
    ").convert(\"L\"))\n",
    "VF.to_pil_image(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260f514-0aaa-4f8f-81c0-9bd37f2ac113",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMatchingPersuit:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            atom_shape: Tuple[int, int, int],\n",
    "            size: int,\n",
    "    ):\n",
    "        self.atom_shape = atom_shape\n",
    "        self.atoms = torch.rand(size, *atom_shape) * 0.001\n",
    "        self.atom_counts = torch.zeros(size, dtype=torch.int64)\n",
    "        \n",
    "    def get_random_image_patches(self, image: torch.Tensor, count: int) -> torch.Tensor:\n",
    "        patches = []\n",
    "        positions = []\n",
    "        for i in range(count):\n",
    "            y = random.randrange(image.shape[-2] - self.atom_shape[-2])\n",
    "            x = random.randrange(image.shape[-1] - self.atom_shape[-1])\n",
    "            patches.append(image[None, :, y: y + self.atom_shape[-2], x: x + self.atom_shape[-1]])\n",
    "            positions.append((y, x))\n",
    "        \n",
    "        return torch.concat(patches), positions\n",
    "\n",
    "    def get_atom_matches(self, patches: torch.Tensor):\n",
    "        \"\"\"Returns [P, A]\"\"\"\n",
    "        dots = patches.flatten(1) @ self.atoms.flatten(1).T\n",
    "        return dots\n",
    "\n",
    "    def subtract_random_atoms(self, image: torch.Tensor, count: int, weight: float = 1.):\n",
    "        image = image + 0\n",
    "        positions = []\n",
    "        atom_ids = []\n",
    "        for i in range(count):\n",
    "            pos = (\n",
    "                random.randrange(image.shape[-2] - self.atom_shape[-2]),\n",
    "                random.randrange(image.shape[-1] - self.atom_shape[-1]),\n",
    "            )\n",
    "            atom_idx = random.randrange(self.atoms.shape[0])\n",
    "            \n",
    "            atom = self.atoms[atom_idx]\n",
    "            image[:, pos[-2]: pos[-2] + self.atom_shape[-2], pos[-1]: pos[-1] + self.atom_shape[-1]] -= atom * weight\n",
    "\n",
    "            positions.append(pos)\n",
    "            atom_ids.append(atom_idx)\n",
    "            \n",
    "        return image, positions, atom_ids\n",
    "\n",
    "    def random_trial_learning(\n",
    "            self,\n",
    "            image: torch.Tensor, \n",
    "            iterations: int = 100, \n",
    "            patches_per_trial: int = 10,\n",
    "            learnrate=0.0001,\n",
    "    ):\n",
    "        trials = []\n",
    "        for trial in range(iterations):\n",
    "            sub_image, positions, atom_ids = self.subtract_random_atoms(image, patches_per_trial)\n",
    "\n",
    "            loss = sub_image.mean()\n",
    "            trials.append((loss, sub_image, positions, atom_ids))\n",
    "\n",
    "        trials.sort(key=lambda t: t[0])\n",
    "        \n",
    "        for pos, atom_id in zip(trials[0][2], trials[0][3]):\n",
    "            patch = image[:, pos[0]: pos[0] + self.atom_shape[-2], pos[1]: pos[1] + self.atom_shape[-1]]\n",
    "            self.atoms[atom_id] += learnrate * (patch - self.atoms[atom_id])\n",
    "\n",
    "        return trials[0]\n",
    "        \n",
    "    def digest_image(\n",
    "            self,\n",
    "            image: torch.Tensor,\n",
    "            iterations: int = 100,\n",
    "            patches_per_iter: int = 1000,\n",
    "            learnrate=0.001,\n",
    "    ):\n",
    "        image = image - image.mean()  # copy image\n",
    "        \n",
    "        for iteration in tqdm(range(iterations)):\n",
    "\n",
    "            patches, positions = self.get_random_image_patches(image, patches_per_iter)\n",
    "            patches = patches - patches.flatten(1).mean(1)[:, None, None, None]\n",
    "            matches = self.get_atom_matches(patches)\n",
    "            #print(matches.min(), matches.max())\n",
    "            matches /= matches.abs().max()\n",
    "            #matches -= .1 * (1. - self.atom_counts / self.atom_counts.max())\n",
    "            #print(patches.mean(dim=-3, keepdim=True))\n",
    "            best_indices = matches.argsort(descending=True)\n",
    "\n",
    "            for patch, pos, best_atom_ids in zip(patches, positions, best_indices):\n",
    "                #patch = image[:, pos[0]: pos[0] + self.atom_shape[-2], pos[1]: pos[1] + self.atom_shape[-1]]\n",
    "                #best_id = random.randrange(max(1, random.randrange(best_atom_ids.shape[0] // 2)))\n",
    "                best_id = random.randrange(best_atom_ids.shape[0] // 2)\n",
    "                atom_id = best_atom_ids[best_id]\n",
    "                #atom_id = random.choice(best_atom_ids[:best_atom_ids.shape[0] // 2])\n",
    "                self.atoms[atom_id] += learnrate * ((patch - patch.mean()) - self.atoms[atom_id])\n",
    "                self.atom_counts[atom_id] += 1\n",
    "                #atom_idx = best_indices[patch_idx][0]\n",
    "            #    atom_idx = random.randrange(self.atoms.shape[0])\n",
    "                \n",
    "            #image = trials[0][1].clamp(0, 1)  # sub_image    \n",
    "\n",
    "        return image\n",
    "            \n",
    "\n",
    "    def display_atoms(self, scale: float = 1., normalize: bool = True):\n",
    "        nrows = int(math.ceil(math.sqrt(self.atoms.shape[0])))\n",
    "        grid = make_grid(self.atoms, nrow=nrows, normalize=normalize)\n",
    "        grid = resize(grid, scale)\n",
    "        display(VF.to_pil_image(grid))\n",
    "        \n",
    "mp = ImageMatchingPersuit((1, 16, 16), 8*8)\n",
    "mp.random_trial_learning(image)\n",
    "dimage = mp.digest_image(image)\n",
    "mp.display_atoms(scale=2)\n",
    "#print(mp.atom_counts)\n",
    "display(px.bar(mp.atom_counts))\n",
    "#display(VF.to_pil_image(dimage))\n",
    "#patches, posi = mp.get_random_image_patches(image, 16*10)\n",
    "#VF.to_pil_image(make_grid(patches, nrow=16))\n",
    "#mp.match_atoms(patches).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecbe5e5-6c37-4fa7-9c22-9f9cc65e9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dimage = mp.digest_image(image, iterations=1000)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "mp.display_atoms(scale=2)\n",
    "print(mp.atom_counts)\n",
    "#display(VF.to_pil_image(dimage))\n",
    "display(px.histogram(mp.atom_counts))\n",
    "display(px.bar(mp.atom_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebf1cb-635e-4c82-b753-e56a0a9c1eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(mp.atoms.flatten(1) @ mp.atoms.flatten(1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15718cbf-3a5c-4e97-9d02-c2a1bbf2711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "60_000 * 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
