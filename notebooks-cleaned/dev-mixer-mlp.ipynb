{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e36fb7-b6ac-47a3-bd4b-8ac83bb37093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *\n",
    "from src.util.module import dump_module_stacktrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a0e61-71e1-49c7-90e6-fc3416ca0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "60_000 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e92122-0ea3-4460-a907-7e095839f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patchify(nn.Module):\n",
    "    def __init__(self, patch_size: int):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"patch_size={self.patch_size}\"\n",
    "        \n",
    "    def forward(self, batch: torch.Tensor) -> torch.Tensor:\n",
    "        B, C, H, W = batch.shape\n",
    "        assert W % self.patch_size == 0, f\"width must be divisible by patch_size, got {W} / {self.patch_size}\"\n",
    "        assert H % self.patch_size == 0, f\"height must be divisible by patch_size, got {H} / {self.patch_size}\"\n",
    "\n",
    "        return (\n",
    "            batch.permute(0, 2, 3, 1)                     # B, H, W, C\n",
    "            .unfold(1, self.patch_size, self.patch_size)  # B, H/s, W, C, s\n",
    "            .unfold(2, self.patch_size, self.patch_size)  # B, H/s, W/s, C, s, s\n",
    "        )\n",
    "\n",
    "class Unpatchify(nn.Module):\n",
    "    def __init__(self, patch_size: int):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"patch_size={self.patch_size}\"\n",
    "\n",
    "    def forward(self, batch: torch.Tensor) -> torch.Tensor:\n",
    "        B, Y, X, C, H, W = batch.shape\n",
    "\n",
    "        return (\n",
    "            batch.permute(0, 1, 3, 4, 2, 5)               # B, Y, C, H, X, W \n",
    "            .reshape(B, Y, C, H, W * X)\n",
    "            .permute(0, 2, 1, 3, 4)                       # B, C, Y, H, W*X\n",
    "            .reshape(B, C, H * Y, W * X)\n",
    "        )\n",
    "\n",
    "inp = torch.ones(2, 3, 64, 64)\n",
    "patches = Patchify(8)(inp)\n",
    "shape = patches.shape\n",
    "patches = patches.reshape(math.prod(shape[:3]), -1)\n",
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee486d-51c8-4ba9-a0df-ce4eb903745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLayer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels_in: int,\n",
    "            channels_out: int,\n",
    "            activation: Union[None, str, Callable] = None,\n",
    "            bias: bool = True,\n",
    "            residual: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._residual = residual and channels_in == channels_out\n",
    "\n",
    "        self.module = nn.Linear(channels_in, channels_out, bias=bias)\n",
    "            \n",
    "        self.act = activation_to_module(activation)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"residual={self._residual}\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.module(x)\n",
    "        if self.act is not None:\n",
    "            y = self.act(y)\n",
    "        if self._residual:\n",
    "            y = y + x\n",
    "        return y\n",
    "\n",
    "\n",
    "class MLPMixerLayer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels: int,\n",
    "            activation: Union[None, str, Callable] = None,\n",
    "            bias: bool = True,\n",
    "            residual: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._residual = residual\n",
    "        self.channels = channels\n",
    "\n",
    "        self.module = nn.Conv1d(channels, channels, kernel_size=1, bias=bias)\n",
    "            \n",
    "        self.act = activation_to_module(activation)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"residual={self._residual}\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        shape = x.shape\n",
    "        x = x.reshape(x.shape[0] // self.channels, self.channels, -1) \n",
    "        y = self.module(x)\n",
    "        if self.act is not None:\n",
    "            y = self.act(y)\n",
    "        if self._residual:\n",
    "            y = y + x\n",
    "        return y.reshape(shape)\n",
    "\n",
    "        \n",
    "class MixerMLP(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            image_shape: Tuple[int, int, int],\n",
    "            patch_size: int,\n",
    "            hidden_channels: Tuple[int, ...],\n",
    "            mixer_at: Tuple[int, ...],\n",
    "    ):\n",
    "        assert image_shape[-1] % patch_size == 0, f\"width must be divisible by patch_size, got {image_shape[-1]} / {patch_size}\"\n",
    "        assert image_shape[-2] % patch_size == 0, f\"height must be divisible by patch_size, got {image_shape[-2]} / {patch_size}\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.image_shape = image_shape\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_dim = image_shape[0] * (self.patch_size ** 2)\n",
    "        patches_shape = (image_shape[1] // self.patch_size, image_shape[2] // self.patch_size)\n",
    "        self._last_patch_shape = None\n",
    "        # self.patcher = nn.Conv2d(in_channels, hidden_channels, kernel_size=patch_size, stride=patch_size)\n",
    "        self.patchify = Patchify(patch_size)\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.unpatchify = Unpatchify(patch_size)\n",
    "\n",
    "        channels = (self.patch_dim, *self.hidden_channels)\n",
    "        for i, (ch, next_ch) in enumerate(zip(channels, channels[1:])):\n",
    "            self.encoder.append(MLPLayer(ch, next_ch))\n",
    "            self.decoder.insert(0, MLPLayer(next_ch, ch))\n",
    "            if i + 1 in mixer_at:\n",
    "                self.encoder.append(MLPMixerLayer(math.prod(patches_shape)))\n",
    "                self.decoder.insert(0, MLPMixerLayer(math.prod(patches_shape)))\n",
    "\n",
    "        self.encoder.append(MLPLayer(next_ch * math.prod(patches_shape), next_ch))\n",
    "        self.decoder.insert(0, MLPLayer(next_ch, next_ch * math.prod(patches_shape)))\n",
    "        \n",
    "    def encode(self, batch: torch.Tensor) -> Tuple[torch.Tensor, Tuple[int, ...]]:\n",
    "        B, C, H, W = batch.shape\n",
    "        assert (C, H, W) == self.image_shape, f\"Expected image shape {self.image_shape}, got {(C, H, W)}\"\n",
    "\n",
    "        patch_batch = self.patchify(batch)\n",
    "        self._last_patch_shape = patch_shape = patch_batch.shape\n",
    "        y = patch_batch.reshape(math.prod(patch_shape[:3]), -1)  # B*X*Y, C*S*S\n",
    "        # print(y.shape, self._patch_batch_shape, self.encoder)\n",
    "        for i, module in enumerate(self.encoder):\n",
    "            if i == len(self.encoder) - 1:\n",
    "                y = y.reshape(B, -1)\n",
    "            y = module(y)\n",
    "        return y\n",
    "\n",
    "    def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        assert self._last_patch_shape is not None, \"Must call encode() before decode()\"\n",
    "        patch_shape = self._last_patch_shape\n",
    "\n",
    "        y = x\n",
    "        for i, module in enumerate(self.decoder):\n",
    "            y = module(y)\n",
    "            if i == 0:\n",
    "                y = y.reshape(math.prod(patch_shape[:3]), -1)\n",
    "\n",
    "        y = y.reshape(patch_shape)\n",
    "        y = self.unpatchify(y)\n",
    "        return y\n",
    "\n",
    "    def forward(self, batch: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.encode(batch)\n",
    "        y = self.decode(y)\n",
    "        return y\n",
    "        \n",
    "module = MixerMLP((3, 8, 12), 4, [128, 16], mixer_at=[1])\n",
    "# print(\"patcher:\", module.patcher.weight.shape)\n",
    "inp = torch.ones(2, 3, 8, 12)\n",
    "outp = dump_module_stacktrace(module, inp)\n",
    "print(\"outp\", outp.shape)\n",
    "display(module)\n",
    "display(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2afc4-8974-4d23-b109-ee2b956bff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.arange(2*6*48).reshape(2, 6, 48).float()\n",
    "mixer = nn.Conv1d(6, 6, kernel_size=1)\n",
    "outp = mixer(inp)\n",
    "print(outp.shape)\n",
    "outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a2b82-586c-40a2-8c34-7e1c72dc4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "[torch.split(o, 16, -2) for o in torch.split(inp, 16, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a759a-01ea-46b8-a824-97a0b1700a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.arange(0, 2*3*8*8).reshape(2, 3, 8, 8)\n",
    "display(batch)\n",
    "u = batch.unfold(-2, 4, 4).unfold(-2, 4, 4)\n",
    "display(u.shape)\n",
    "display(u)\n",
    "#inp.unfold(-2, 16, 16).shape #.unfold(-3, 16, 16).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b6ee5f-b553-466d-b1ef-fb3c85a138af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.arange(0, 2*3*8*8).reshape(2, 3, 8, 8)\n",
    "display(batch)\n",
    "p = nn.Conv2d(3, 3, kernel_size=1, stride=4)(batch.float())\n",
    "display(p.shape)\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709aa5a-051b-4858-a3a1-5f62e8d6d5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca79bfe-adb3-426c-b48c-d39c9bc310bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f83e07d-f8a6-4e3b-b131-3aafb5837239",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = BaseDataset(TensorDataset(torch.load(\n",
    "    \"../datasets/colorful-uint-64x64-340k.pt\"\n",
    ")))\n",
    "\n",
    "images = [i[0] for i in ds.limit(64)]\n",
    "VF.to_pil_image(make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4ba05-c657-4326-b0d1-55f05e4ed8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
