{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ce722-a145-414a-8592-2965fb211ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset, RandomSampler\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display\n",
    "\n",
    "from src.datasets import *\n",
    "from src.util.image import *\n",
    "from src.util import *\n",
    "from src.algo import *\n",
    "from src.models.cnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a2503-ecdb-4a2d-bd4a-6263db578e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SHAPE = (1, 32, 32)\n",
    "CODE_SIZE = 64\n",
    "dataset = TensorDataset(torch.load(f\"../datasets/fonts-regular-{SHAPE[-2]}x{SHAPE[-1]}.pt\"))\n",
    "#dataset = TransformDataset(dataset, dtype=torch.float, multiply=255.)\n",
    "assert SHAPE == dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe2c868-d037-45df-b4b8-de824338b188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = torch.cat([dataset[i][0].unsqueeze(0) for i in RandomSampler(dataset, num_samples=16)])\n",
    "VF.to_pil_image(make_grid(images, nrow=16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98719e6-01a3-4a0a-a9f7-b8e49ab6cc89",
   "metadata": {},
   "source": [
    "# dataset -> features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df73e7-3234-48bf-af0c-77100d062f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(dataset):\n",
    "    feature_list = []\n",
    "    for image_batch, in tqdm(DataLoader(dataset, batch_size=50, shuffle=True)):\n",
    "        feature_list.append(image_batch.view(-1, math.prod(SHAPE)))\n",
    "        #if len(feature_list) >= 300:\n",
    "        #    break\n",
    "    return torch.cat(feature_list)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = encode_dataset(dataset)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c3c131-e636-4012-987f-2be26b6cb0c1",
   "metadata": {},
   "source": [
    "# PCA of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68993f47-3086-49ef-84c8-4c3c399f7700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "pca = PCA(CODE_SIZE)\n",
    "pca.fit(features)\n",
    "#pca.components_\n",
    "pca_weight = torch.Tensor(pca.components_)\n",
    "pca_features = features @ pca_weight.T\n",
    "VF.to_pil_image(pca_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbc85f-f881-452e-a85d-f02747692086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.line(pca_features.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fda3b1-1f5e-465e-921a-29026002f721",
   "metadata": {
    "tags": []
   },
   "source": [
    "# generate from PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe1a65-6e59-441d-a74e-26c1360f6d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_pca_samples(features, nrow=16, comps=5):\n",
    "    repros = features @ pca_weight\n",
    "    repros = repros.clip(0, 1).view(-1, *SHAPE)\n",
    "    display(VF.to_pil_image(make_grid(repros, nrow=nrow)))\n",
    "    \n",
    "plot_pca_samples(pca_features[:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5750ee03-7480-4347-94ed-927aa76d79c6",
   "metadata": {},
   "source": [
    "# random features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e11a8-d411-41d4-9695-6c2322e17744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_random_pca(num=16*4, nrow=16):\n",
    "    features = torch.randn(num, CODE_SIZE) * pca_features.std().unsqueeze(0) + pca_features.mean(0).unsqueeze(0)\n",
    "    repros = features @ pca_weight\n",
    "    repros = repros.clip(0, 1).view(-1, *SHAPE)\n",
    "    display(VF.to_pil_image(make_grid(repros, nrow=nrow)))\n",
    "    \n",
    "plot_random_pca()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d505cbc-ed42-4da0-81e0-bf62e65d1ddc",
   "metadata": {},
   "source": [
    "# manipulate PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7f75c-acf0-4448-b3c7-d512ebea07fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_features.min(), pca_features.mean(), pca_features.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635890fe-f20b-4913-a5dc-388c8eb2faa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def manipulate_pca_sample(pca_sample, nrow=16, comps=5):\n",
    "    modified_samples = pca_sample.view(1, -1).repeat(nrow * comps, 1)\n",
    "    for i, sample in enumerate(modified_samples):\n",
    "        t = ((i % nrow) / 15.) * 2. - 1.\n",
    "        idx = i // nrow\n",
    "        sample[idx] = t * 10.\n",
    "    repros = modified_samples @ pca_weight\n",
    "    repros = repros.clip(0, 1).view(-1, *SHAPE)\n",
    "    display(VF.to_pil_image(make_grid(repros, nrow=nrow)))\n",
    "    \n",
    "manipulate_pca_sample(pca_features[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab3725-c1ba-4449-b441-1765ae755f23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61085fc-ec16-4633-8ee3-23b3ce791487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_feature_plot(sample1, samples2, nrow=16):\n",
    "    samples = []\n",
    "    for sample2 in samples2:\n",
    "        for i in range(nrow):\n",
    "            t = i / (nrow - 1)\n",
    "            samples.append( (sample1 * (1. - t) + t * sample2).unsqueeze(0) )\n",
    "\n",
    "    repros = torch.cat(samples) @ pca_weight\n",
    "    repros = repros.clip(0, 1).view(-1, *SHAPE)\n",
    "    display(VF.to_pil_image(make_grid(repros, nrow=nrow)))\n",
    "    \n",
    "blend_feature_plot(pca_features[13], pca_features[20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187d194-8694-4cdb-bcd1-ea0e4d2c21dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce24aa9-b4cd-4628-a3a6-d629da6b0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(\n",
    "        iterable, \n",
    "        total: int = 16, \n",
    "        nrow: int = 16, \n",
    "        return_image: bool = False, \n",
    "):\n",
    "    samples = []\n",
    "    f = ImageFilter()\n",
    "    try:\n",
    "        for image in tqdm(iterable, total=total):\n",
    "            samples.append(image)\n",
    "                \n",
    "            if len(samples) >= total:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    image = VF.to_pil_image(make_grid(samples, nrow=nrow))\n",
    "    if return_image:\n",
    "        return image\n",
    "    display(image)\n",
    "    \n",
    "plot_samples(\n",
    "    ()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54286f81-6d1c-4694-b06b-0789788da73c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
