{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ed52b-36ad-43d0-99d3-236d6bb06640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from src.datasets import *\n",
    "from src.util.image import * \n",
    "from src.util import ImageFilter\n",
    "from src.algo import Space2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a060a39-bb85-47cf-abf1-d7ad15d5e5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_samples(\n",
    "        iterable, \n",
    "        total: int = 32, \n",
    "        nrow: int = 8, \n",
    "        return_image: bool = False, \n",
    "        show_compression_ratio: bool = False,\n",
    "        label: Optional[Callable] = None,\n",
    "):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    f = ImageFilter()\n",
    "    try:\n",
    "        for image in tqdm(iterable, total=total):\n",
    "            samples.append(image)\n",
    "            if show_compression_ratio:\n",
    "                labels.append(round(f.calc_compression_ratio(image), 3))\n",
    "            elif label is not None:\n",
    "                labels.append(label(image))\n",
    "                \n",
    "            if len(samples) >= total:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    if labels:\n",
    "        image = VF.to_pil_image(make_grid_labeled(samples, nrow=nrow, labels=labels))\n",
    "    else:\n",
    "        image = VF.to_pil_image(make_grid(samples, nrow=nrow))\n",
    "    if return_image:\n",
    "        return image\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c13ff-c8b6-49b9-867b-338f70467b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def menger_sponge_2d(\n",
    "        space: Space2d,\n",
    "        iterations: int = 3,\n",
    "        radius: float = .25,\n",
    "        repeat_size: Union[float, Iterable[float]] = 1.,\n",
    "        rotate_z_deg: float = 45.,\n",
    "        scale_factor: float = 2.,\n",
    "        offset: Iterable[float] = (0., 0.),\n",
    "        shape: str = \"torus\",  # \"square\", \"circle\", \"stripe\"\n",
    "        aa: int = 1,\n",
    ") -> torch.Tensor:\n",
    "    offset = torch.Tensor(list(offset)).reshape(2, 1, 1).to(space.dtype)\n",
    "    if not isinstance(repeat_size, (int, float)):\n",
    "        repeat_size = torch.Tensor(list(repeat_size)).reshape(2, 1, 1).to(space.dtype)\n",
    "    rotate_z = rotate_z_deg * 3.14159265 / 180.\n",
    "    \n",
    "    def _render(coords: torch.Tensor):\n",
    "        dist_accum = torch.empty(1, *coords.shape[-2:], dtype=space.dtype).fill_(100000.)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            l_coords = (coords + repeat_size * .5) % repeat_size - repeat_size * .5\n",
    "            \n",
    "            if shape in (\"circle\", \"torus\"):\n",
    "                dist = torch.sqrt(torch.sum(torch.square(l_coords), dim=0, keepdim=True))\n",
    "                dist1, _ = torch.min(dist - radius, dim=0, keepdim=True)\n",
    "                dist = dist1\n",
    "                if shape == \"torus\":\n",
    "                    dist2, _ = torch.min(dist - radius * .5, dim=0, keepdim=True)\n",
    "                    dist = torch.maximum(-dist1, dist2)\n",
    "                    \n",
    "            elif shape in (\"square\", \"stripe\"):\n",
    "                if shape == \"stripe\": \n",
    "                    dist = torch.abs(l_coords[0]).unsqueeze(0) \n",
    "                else:\n",
    "                    dist = torch.abs(l_coords) \n",
    "                dist, _ = torch.max(dist - radius, dim=0, keepdim=True)\n",
    "            \n",
    "            if iteration == 0:\n",
    "                dist_accum = torch.minimum(dist_accum, -dist)\n",
    "            else:\n",
    "                dist_accum = torch.maximum(dist_accum, -dist)\n",
    "        \n",
    "            si = math.sin(rotate_z)\n",
    "            co = math.cos(rotate_z)\n",
    "            coords = torch.cat([\n",
    "                (co * coords[1] + si * coords[0]).unsqueeze(0),\n",
    "                (co * coords[0] - si * coords[1]).unsqueeze(0)\n",
    "            ])\n",
    "            coords = coords * scale_factor\n",
    "            coords = coords + offset\n",
    "            \n",
    "        #output = -dist_accum    \n",
    "        output = 1. - dist_accum * 100.\n",
    "        return torch.clamp(output, 0, 1)\n",
    "\n",
    "    if aa <= 1:\n",
    "        return _render(space.space())\n",
    "    else:\n",
    "        return space.reduce_aa_output(aa, _render(space.aa_space(aa)))\n",
    "\n",
    "space = Space2d((2, 64, 64), offset=torch.Tensor([0,0]), scale=1.)\n",
    "img = menger_sponge_2d(\n",
    "    space,\n",
    "    #iterations=35,\n",
    "    aa=4,\n",
    "    #rotate_z_deg=22.5,\n",
    "    #offset=(.5, .2),\n",
    ")\n",
    "img\n",
    "VF.to_pil_image(VF.resize(img, (img.shape[-2]*3, img.shape[-1]*3), VF.InterpolationMode.NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed29a4-3729-463d-a31d-acbc636a4cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6409f6-502d-4c00-8836-398af6f035a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932259a-c056-47d7-bd12-b38b101a1470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae915d9-f6cd-4cff-b64a-4f22f148fed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MengerSponge2dDataset(Dataset):\n",
    "    available_shapes = (\"circle\", \"square\", \"stripe\", \"torus\")\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        shape: Tuple[int, int, int],\n",
    "        size: int = 1000,\n",
    "        seed: int = 23,\n",
    "        min_scale: float = .1,\n",
    "        max_scale: float = 1.,\n",
    "        min_offset: float = 0.,\n",
    "        max_offset: float = 0.,\n",
    "        rotation_steps: int = 4,\n",
    "        min_radius: float = .1,\n",
    "        max_radius: float = .25,\n",
    "        min_iterations: int = 2,\n",
    "        max_iterations: int = 10,\n",
    "        min_recursive_scale: float = 1.,\n",
    "        max_recursive_scale: float = 3.,\n",
    "        recursive_offset_steps: int = 1,\n",
    "        recursive_rotation_steps: int = 4,\n",
    "        shapes: Optional[Iterable[str]] = None,#(\"circle\", \"square\"),\n",
    "        dtype: torch.dtype = torch.float,\n",
    "        aa: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        self._size = size\n",
    "        self.seed = seed\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.min_offset = min_offset\n",
    "        self.max_offset = max_offset\n",
    "        self.rotation_steps = rotation_steps\n",
    "        self.min_recursive_scale = min_recursive_scale\n",
    "        self.max_recursive_scale = max_recursive_scale\n",
    "        self.recursive_offset_steps = recursive_offset_steps\n",
    "        self.recursive_rotation_steps = recursive_rotation_steps\n",
    "        self.min_radius = min_radius\n",
    "        self.max_radius = max_radius\n",
    "        self.min_iterations = min_iterations\n",
    "        self.max_iterations = max_iterations\n",
    "        self.shapes = self.available_shapes if shapes is None else list(shapes)\n",
    "        self.dtype = dtype\n",
    "        self.aa = aa\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return self._size\n",
    "    \n",
    "    def __getitem__(self, idx) -> torch.Tensor:\n",
    "        rng = torch.Generator().manual_seed(idx ^ self.seed)\n",
    "        def _rand(mi: float, ma: float) -> float:\n",
    "            return torch.rand(1, generator=rng, dtype=self.dtype) * (ma - mi) + mi\n",
    "        \n",
    "        rotation = math.pi * math.floor(_rand(-1., 1.) * self.rotation_steps) / max(1, self.rotation_steps)\n",
    "        \n",
    "        space = Space2d(\n",
    "            shape=(2, *self.shape[-2:]),\n",
    "            offset=_rand(self.min_offset, self.max_offset),\n",
    "            scale=_rand(self.min_scale, self.max_scale),\n",
    "            rotate_2d=rotation,\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "        \n",
    "        menger_shape = self.shapes[torch.randint(0, len(self.shapes), (1,), generator=rng).item()]\n",
    "        iterations = max(self.min_iterations, min(self.max_iterations, \n",
    "            int(.5 + _rand(self.min_iterations, self.max_iterations))\n",
    "        ))\n",
    "        radius = _rand(self.min_radius, self.max_radius)\n",
    "        scale = _rand(self.min_recursive_scale, self.max_recursive_scale)\n",
    "        rotation = 360. * math.floor(_rand(-1., 1.) * self.recursive_rotation_steps) / max(1, self.recursive_rotation_steps)\n",
    "        offset = torch.rand(2, dtype=self.dtype, generator=rng)\n",
    "        offset = torch.floor(offset * self.recursive_offset_steps) / max(1, self.recursive_offset_steps)\n",
    "        return menger_sponge_2d(\n",
    "            space=space,\n",
    "            shape=menger_shape,\n",
    "            iterations=iterations,\n",
    "            scale_factor=scale,\n",
    "            radius=radius,\n",
    "            rotate_z_deg=rotation,\n",
    "            offset=offset,\n",
    "            aa=self.aa,\n",
    "        )\n",
    "        \n",
    "dataset = MengerSponge2dDataset(\n",
    "    (1, 64, 64), aa=4, size=1_000_000, \n",
    "    #min_iterations=17,\n",
    "    #min_scale=0.01, max_scale=2.,\n",
    "    #min_offset=-2., max_offset=2.\n",
    ")\n",
    "plot_samples(\n",
    "    dataset,\n",
    "    nrow=8, total=8*8,\n",
    "    show_compression_ratio=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d225cf1-7d2a-4428-abe4-f274920989b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MengerSponge2dFilteredIterableDataset(IterableDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        shape: Tuple[int, int, int],\n",
    "        size: int = 1000,\n",
    "        seed: int = 23,\n",
    "        min_scale: float = .1,\n",
    "        max_scale: float = 1.,\n",
    "        min_offset: float = 0.,\n",
    "        max_offset: float = 0.,\n",
    "        rotation_steps: int = 4,\n",
    "        min_radius: float = .1,\n",
    "        max_radius: float = .25,\n",
    "        min_iterations: int = 2,\n",
    "        max_iterations: int = 10,\n",
    "        min_recursive_scale: float = 1.,\n",
    "        max_recursive_scale: float = 3.,\n",
    "        min_recursive_offset: float = 0.,\n",
    "        recursive_offset_steps: int = 1,\n",
    "        recursive_rotation_steps: int = 4,\n",
    "        shapes: Optional[Iterable[str]] = None,\n",
    "        dtype: torch.dtype = torch.float,\n",
    "        aa: int = 0,\n",
    "        image_filter: Optional[ImageFilter] = None,\n",
    "        filter_shape: Optional[Tuple[int, int, int]] = None,\n",
    "        filter_aa: Optional[int] = None,\n",
    "\n",
    "    ):\n",
    "        kwargs = dict(\n",
    "            shape=shape,\n",
    "            size=size,\n",
    "            seed=seed,\n",
    "            min_scale=min_scale,\n",
    "            max_scale=max_scale,\n",
    "            min_offset=min_offset,\n",
    "            max_offset=max_offset,\n",
    "            rotation_steps=rotation_steps,\n",
    "            min_radius=min_radius,\n",
    "            max_radius=max_radius,\n",
    "            min_iterations=min_iterations,\n",
    "            max_iterations=max_iterations,\n",
    "            min_recursive_scale=min_recursive_scale,\n",
    "            max_recursive_scale=max_recursive_scale,\n",
    "            recursive_offset_steps=recursive_offset_steps,\n",
    "            recursive_rotation_steps=recursive_rotation_steps,\n",
    "            shapes=shapes,\n",
    "            dtype=dtype,\n",
    "            aa=aa,\n",
    "        )\n",
    "        self.dataset = MengerSponge2dDataset(**kwargs)\n",
    "        self.image_filter = image_filter\n",
    "        self.filter_dataset = None\n",
    "        if image_filter is not None:\n",
    "            if (filter_aa is not None and filter_aa != aa) or (filter_shape is not None and filter_shape != shape):\n",
    "                if filter_aa is not None:\n",
    "                    kwargs[\"aa\"] = filter_aa\n",
    "                if filter_shape is not None:\n",
    "                    kwargs[\"shape\"] = filter_shape\n",
    "                self.filter_dataset = MengerSponge2dDataset(**kwargs)\n",
    "            \n",
    "    def __iter__(self) -> torch.Tensor:\n",
    "        for i in range(len(self.dataset)):\n",
    "            if self.image_filter is not None:\n",
    "                if self.filter_dataset is not None:\n",
    "                    image = self.filter_dataset[i]\n",
    "                else:\n",
    "                    image = self.dataset[i]\n",
    "\n",
    "                if not self.image_filter(image):\n",
    "                    continue\n",
    "\n",
    "                if self.filter_dataset is not None:\n",
    "                    image = self.dataset[i]\n",
    "\n",
    "            else:\n",
    "                image = self.dataset[i]\n",
    "\n",
    "            yield image\n",
    "\n",
    "\n",
    "plot_samples(\n",
    "    MengerSponge2dFilteredIterableDataset(\n",
    "        shape=(1, 128, 128),\n",
    "        aa=4,\n",
    "        max_iterations=8,\n",
    "        rotation_steps=3,\n",
    "        recursive_offset_steps=12,\n",
    "        image_filter=ImageFilter(\n",
    "            min_blurred_compression_ratio=.5,\n",
    "            max_compression_ratio=.5,\n",
    "        ),\n",
    "        filter_shape=(1, 32, 32),\n",
    "        #filter_aa=2,\n",
    "    ),\n",
    "    show_compression_ratio=True, total=8*8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea5d4d6-a9b6-4e2a-a66b-5043d90b2c7d",
   "metadata": {},
   "source": [
    "# dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e3737-21a0-429c-be91-f65265d2a8e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SHAPE = (1, 128, 128)\n",
    "AA = 4\n",
    "SIZE = 1_000_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa32d25-be9d-4756-89c1-793ac30369be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds1 = MengerSponge2dFilteredIterableDataset(\n",
    "    shape=SHAPE,\n",
    "    aa=AA,\n",
    "    size=SIZE,\n",
    "    min_iterations=5,\n",
    "    max_iterations=8,\n",
    "    rotation_steps=3,\n",
    "    recursive_offset_steps=12,\n",
    "    image_filter=ImageFilter(\n",
    "        max_mean=.2,\n",
    "        min_blurred_compression_ratio=.3,\n",
    "        #min_compression_ratio=.1,\n",
    "        #max_compression_ratio=.3,\n",
    "    ),\n",
    "    #filter_shape=(1, 32, 32),\n",
    "    filter_aa=0,\n",
    ")\n",
    "plot_samples(ds1, show_compression_ratio=True, total=8*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e768b-8292-422e-878b-e7b6040b2494",
   "metadata": {
    "tags": []
   },
   "source": [
    "# dataset #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304e52d-71a0-4e30-a029-d380807046c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds2 = MengerSponge2dFilteredIterableDataset(\n",
    "    shape=SHAPE,\n",
    "    aa=AA,\n",
    "    size=SIZE,\n",
    "    min_iterations=3,\n",
    "    max_iterations=5,\n",
    "    #rotation_steps=3,\n",
    "    recursive_offset_steps=12,\n",
    "    recursive_rotation_steps=12,\n",
    "    image_filter=ImageFilter(\n",
    "        #min_mean=.2,\n",
    "        #min_blurred_compression_ratio=.3,\n",
    "        #min_compression_ratio=.1,\n",
    "        max_compression_ratio=.2,\n",
    "    ),\n",
    "    #filter_shape=(1, 32, 32),\n",
    "    #filter_aa=0,\n",
    ")\n",
    "plot_samples(ds2, show_compression_ratio=True, total=8*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1c4df-bed1-4162-90dc-c4b5fe017f4a",
   "metadata": {},
   "source": [
    "# find unsimilar ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4555b-8bcd-4db4-b8d5-6e62cfcc970d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToRGB(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.repeat(1, 3, 1, 1)\n",
    "\n",
    "if 0:\n",
    "    CODE_SIZE = 512\n",
    "    from scripts.train_from_dataset import EncoderMLP, EncoderTrans\n",
    "\n",
    "    #model = EncoderMLP((3, *SHAPE[-2:]), channels=[CODE_SIZE])\n",
    "    #model.load_state_dict(torch.load(\"../checkpoints/clip2/best.pt\")[\"state_dict\"])\n",
    "    model = EncoderTrans((3, 64, 64), code_size=CODE_SIZE)\n",
    "    model.load_state_dict(torch.load(\"../checkpoints/clip5-tr/best.pt\")[\"state_dict\"])\n",
    "    model = nn.Sequential(\n",
    "        VT.Resize((64, 64), VF.InterpolationMode.BICUBIC),\n",
    "        ToRGB(),\n",
    "        model\n",
    "    )\n",
    "if 1:\n",
    "    CODE_SIZE = 512\n",
    "    import clip\n",
    "    class ToDevice(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return x.half().cuda()\n",
    "    class FromDevice(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return x.cpu().float()\n",
    "    model, preproc = clip.load(\"ViT-B/32\")\n",
    "    model = nn.Sequential(\n",
    "        VT.Resize((224, 224), VF.InterpolationMode.BICUBIC),\n",
    "        ToRGB(),\n",
    "        preproc.transforms[-1],\n",
    "        ToDevice(),\n",
    "        model.visual,\n",
    "        FromDevice(),\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff0134-3011-49ce-8895-fc1ea5a2a8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iter_unsimilar_images(ds, max_dot: float = 0.9, total: int = 10):\n",
    "    def _iter_image_and_feature():\n",
    "        for image_batch in DataLoader(ds, batch_size=20):\n",
    "            features = model(image_batch)\n",
    "            features = features / features.norm(dim=-1, keepdim=True)\n",
    "            for image, feature in zip(image_batch, features):\n",
    "                yield image, feature\n",
    "                \n",
    "    count = 0\n",
    "    count_tried = 0\n",
    "    last_count_tried = 0\n",
    "    all_features = None\n",
    "    \n",
    "    for image, feature in _iter_image_and_feature():\n",
    "        count_tried += 1\n",
    "        \n",
    "        if all_features is None:\n",
    "            all_features = feature.unsqueeze(0)\n",
    "        else:\n",
    "            dots = feature @ all_features.T\n",
    "            \n",
    "            if count_tried - last_count_tried > 1000:\n",
    "                last_count_tried = count_tried\n",
    "                print(f\"found {count} in {count_tried}, current dots: {dots.tolist()}\")\n",
    "        \n",
    "            if torch.any(dots >= max_dot):\n",
    "                continue\n",
    "                \n",
    "            all_features = torch.cat([all_features, feature.unsqueeze(0)])\n",
    "\n",
    "        yield image\n",
    "        count += 1\n",
    "        if count >= total:\n",
    "            break\n",
    "\n",
    "plot_samples(iter_unsimilar_images(ds1, .95, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d6037-2267-47c4-9ba9-dc9eab28397c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_samples(iter_unsimilar_images(ds2, .95, 128), total=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c76813-e131-4e04-bd72-96e55df6be0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def store_dataset(\n",
    "        images: Iterable,\n",
    "        dtype=torch.float32,\n",
    "        #image_folder=\"~/Pictures/__diverse/\",\n",
    "        output_filename=\"../datasets/photos-32x32-std01.pt\",\n",
    "        max_megabyte=1_000,\n",
    "):\n",
    "    tensor_batch = []\n",
    "    tensor_size = 0\n",
    "    last_print_size = 0\n",
    "    for image in tqdm(images):\n",
    "        if len(image.shape) < 4:\n",
    "            image = image.unsqueeze(0)\n",
    "        tensor_batch.append(image.clamp(0, 1))\n",
    "        tensor_size += math.prod(image.shape) * 4\n",
    "\n",
    "        if tensor_size - last_print_size > 1024 * 1024 * 50:\n",
    "            last_print_size = tensor_size\n",
    "\n",
    "            print(f\"size: {tensor_size:,}\")\n",
    "\n",
    "        if tensor_size >= max_megabyte * 1024 * 1024:\n",
    "            break\n",
    "\n",
    "    tensor_batch = torch.cat(tensor_batch)\n",
    "    torch.save(tensor_batch, output_filename)\n",
    "\n",
    "store_dataset(iter_images())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75290a4b-136d-4ad4-9827-cc860d21bbb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ds = TensorDataset(torch.load(\"../datasets/diverse-32x32-std01.pt\"))\n",
    "ds = TensorDataset(torch.load(\"../datasets/photos-32x32-std01.pt\"))\n",
    "dl = DataLoader(ds, shuffle=True, batch_size=24*24)\n",
    "for batch in dl:\n",
    "    img = VF.to_pil_image(make_grid(batch[0], nrow=24))\n",
    "    break\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c1f44-9eb9-4911-bf43-682fe4db7a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = torch.rand(16, 8)\n",
    "torch.concat([t, t]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
