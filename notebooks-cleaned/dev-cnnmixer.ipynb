{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654dd98-a179-423f-98ad-6f8ee48da92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c66920-0a6e-464a-8948-c8f091eba139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvMixer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels: int,\n",
    "            factor: int,\n",
    "            num_layers: int = 2,\n",
    "            kernel_size: int = 3,\n",
    "            activation: Union[None, str, Callable] = None,\n",
    "            batch_norm: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        padding = int(math.floor(kernel_size / 2))\n",
    "        chan_mult = factor ** 2\n",
    "        cur_channels = channels\n",
    "        \n",
    "        self.encoder = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.encoder.add_module(f\"unshuffle_{i + 1}\", nn.PixelUnshuffle(factor))\n",
    "            cur_channels = cur_channels * chan_mult\n",
    "            self.encoder.add_module(f\"conv_{i + 1}\", nn.Conv2d(cur_channels, cur_channels, kernel_size, padding=padding, groups=cur_channels))\n",
    "            if activation is not None:\n",
    "                self.encoder.add_module(f\"act_{i + 1}\", activation_to_module(activation))\n",
    "            if batch_norm and i < num_layers - 1:\n",
    "                self.encoder.add_module(f\"norm_{i + 1}\", nn.BatchNorm2d(cur_channels))\n",
    "\n",
    "        self.decoder = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.decoder.add_module(f\"shuffle_{i + 1}\", nn.PixelShuffle(factor))\n",
    "            cur_channels = cur_channels // chan_mult\n",
    "            self.decoder.add_module(f\"conv_{i + 1}\", nn.Conv2d(cur_channels, cur_channels, kernel_size, padding=padding, groups=cur_channels))\n",
    "            if activation is not None and i < num_layers - 1:\n",
    "                self.decoder.add_module(f\"act_{i + 1}\", activation_to_module(activation))\n",
    "            if batch_norm and i < num_layers - 1:\n",
    "                self.decoder.add_module(f\"norm_{i + 1}\", nn.BatchNorm2d(cur_channels))\n",
    "                \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.decoder(self.encoder(x)) + x\n",
    "\n",
    "\n",
    "m = ConvMixer(3, 8, 1, activation=\"gelu\", batch_norm=True, kernel_size=5)\n",
    "print(f\"params: {num_module_parameters(m):,}\")\n",
    "for size in (32, 64, 128):\n",
    "    inp = torch.zeros(1, 3, size, size)\n",
    "    inp[..., :, size//2, size//2] = 100\n",
    "    outp = m(inp)\n",
    "    print(inp.shape, \"->\", outp.shape)\n",
    "    display(VF.to_pil_image(outp[0].clamp(0, 1)))\n",
    "\n",
    "display(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1303b-129c-4680-a8d5-d697c72422ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvStrideMixer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels: int,\n",
    "            stride: int,\n",
    "            hidden_channels: Optional[int] = None,\n",
    "            activation: Union[None, str, Callable] = None,\n",
    "            residual: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._channels = channels\n",
    "        self._hidden_channels = channels * stride if hidden_channels is None else hidden_channels\n",
    "        self._stride = stride\n",
    "        self._residual = residual\n",
    "        \n",
    "        self.encoder = nn.Sequential()\n",
    "        self.encoder.add_module(\"patch\", nn.Conv2d(channels, self._hidden_channels, stride * 2, stride=stride))\n",
    "        if activation is not None:\n",
    "            self.encoder.add_module(\"act\", activation_to_module(activation))\n",
    "        self.encoder.add_module(\"conv\", nn.Conv2d(self._hidden_channels, self._hidden_channels, 1))\n",
    "        self.encoder.add_module(\"unpatch\", nn.ConvTranspose2d(self._hidden_channels, channels, stride * 2, stride=stride))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.encoder(x)\n",
    "        if self._residual:\n",
    "            y = y + x\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"channels={self._channels}, stride={self._stride}, residual={self._residual}\"\n",
    "\n",
    "\n",
    "m = ConvStrideMixer(3, 16)\n",
    "print(f\"params: {num_module_parameters(m):,}\")\n",
    "\n",
    "for size in (32, 64, 128):\n",
    "    inp = torch.zeros(1, 3, size, size)\n",
    "    inp[..., :, size//2, size//2] = 100\n",
    "    outp = m(inp)\n",
    "    print(inp.shape, \"->\", outp.shape)\n",
    "    outp = VF.pad(outp, 1, fill=.5)\n",
    "    display(VF.to_pil_image(resize(outp[0, :3].clamp(0, 1), 3)))\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b4d722-d2b1-46aa-8349-83f7e018a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDilationMixer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels: int,\n",
    "            dilations: Tuple[int, ...] = (6, 5, 3),\n",
    "            hidden_channels: Optional[int] = None,\n",
    "            activation: Union[None, str, Callable] = None,\n",
    "            residual: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._channels = channels\n",
    "        self._dilations = tuple(dilations)\n",
    "        self._hidden_channels = channels if hidden_channels is None else hidden_channels\n",
    "        self._residual = residual\n",
    "        \n",
    "        self.encoder = nn.Sequential()\n",
    "        ch = channels\n",
    "        next_ch = self._hidden_channels\n",
    "        for i, dil in enumerate(dilations):\n",
    "            self.encoder.add_module(f\"conv_{i+1}\", nn.Conv2d(ch, next_ch, 3, padding=dil, dilation=dil))\n",
    "            if activation is not None:\n",
    "                self.encoder.add_module(f\"act_{i+1}\", activation_to_module(activation))\n",
    "            ch = next_ch\n",
    "        self.encoder.add_module(f\"conv_{i+2}\", nn.Conv2d(ch, channels, 3, padding=1))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.encoder(x)\n",
    "        if self._residual:\n",
    "            y = y + x\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"channels={self._channels}, dilations={self._dilations}, residual={self._residual}\"\n",
    "\n",
    "#m = nn.Sequential(\n",
    "#    nn.Conv2d(3, 3, 3, padding=6, dilation=6),\n",
    "#    nn.Conv2d(3, 3, 3, padding=5, dilation=5),\n",
    "#    nn.Conv2d(3, 3, 3, padding=3, dilation=3),\n",
    "#    nn.Conv2d(3, 3, 3, padding=1, dilation=1),\n",
    "#)\n",
    "m = ConvDilationMixer(3, hidden_channels=10)\n",
    "print(f\"params: {num_module_parameters(m):,}\")\n",
    "\n",
    "for size in (32, 64, 128):\n",
    "    inp = torch.zeros(1, 3, size, size)\n",
    "    inp[..., :, size//2, size//2] = 100\n",
    "    inp[..., :, :size//2, size//2] = 100\n",
    "    outp = m(inp)\n",
    "    print(inp.shape, \"->\", outp.shape)\n",
    "    outp = VF.pad(outp, 1, fill=.5)\n",
    "    display(VF.to_pil_image(resize(outp[0, :3].clamp(0, 1), 3)))\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ba32e-c5b8-4fb9-90a7-1fc96395886a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
