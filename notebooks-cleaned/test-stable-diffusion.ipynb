{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9bcdd6e-fed7-47b4-b902-f8e62bdd0b56",
   "metadata": {},
   "source": [
    "### from https://github.com/riveSunder/simple_diffusion_demo/blob/master/diffusion_demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b244ae-33a7-4adc-86ed-9ac6b3271198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ccc16-923a-4525-a468-4f8a02370fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_image = VF.to_tensor(PIL.Image.open(\"/home/bergi/Pictures/csv-turing.png\"))\n",
    "some_image = resize(some_image, 1/8)\n",
    "print(some_image.shape)\n",
    "VF.to_pil_image(some_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab877d-b090-41bc-8a3e-967aac9c74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, AutoPipelineForImage2Image\n",
    "\n",
    "from diffusers.pipelines.pipeline_utils import numpy_to_pil\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler, LMSDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04d35e-ddae-414d-8191-f5caaba7f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_name = \"CompVis/stable-diffusion-v1-4\"\n",
    "if 1:\n",
    "    my_dtype = torch.float32 #torch.float16\n",
    "    my_device = torch.device(\"cpu\") #torch.device(\"cuda\")\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(pipe_name, torch_dtype=my_dtype, safety_checker=None).to(my_device)\n",
    "else:\n",
    "    my_dtype = torch.float16\n",
    "    my_device = torch.device(\"cuda\")\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        pipe_name, torch_dtype=my_dtype, safety_checker=None,\n",
    "    ).to(my_device)\n",
    "    pipe.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a520f10f-ce4d-42c4-8e4d-d6e1fae78ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = ImageWidget()\n",
    "display(image_widget)\n",
    "\n",
    "def _callback(pipe, i, timestep, data: dict):\n",
    "    # print(i, timestep, data[\"latents\"].mean(), data[\"latents\"].shape)\n",
    "    images = pipe.vae.decode(data[\"latents\"] / pipe.vae.config.scaling_factor).sample * .5 + .5\n",
    "    image_widget.set_torch(make_grid(images).clamp(0, 1))\n",
    "    return data\n",
    "    \n",
    "my_output = pipe(\n",
    "    #\"happy workers in the butter factory\", \n",
    "    \"red square on yellow background\",\n",
    "    num_inference_steps=20, num_images_per_prompt=3, guidance_scale=9.0,\n",
    "    callback_on_step_end=_callback, width=64, height=64,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54b03c-9fb2-4099-92b1-29413a5125e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0ede5-03f3-477b-825a-2720524fb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = pipe.components[\"vae\"]\n",
    "print(f\"params: {num_module_parameters(vae):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65239b4a-0ca3-4571-9716-2c8ae71eb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VF.to_pil_image(make_grid(\n",
    "    vae.decoder(torch.randn(2, vae.config.latent_channels, 8, 8) * .5)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805637b-a7c7-4926-b2b8-f50bd3182b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab6313-8c1c-4bba-a169-d01e9eac3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.encode(torch.rand(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc206d4c-1e47-40c4-9e30-05b37b659d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = vae.encoder(some_image[:, :128, :128].unsqueeze(0))\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445f18e8-bafd-48f3-8939-3681aac19e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    #display(VF.to_pil_image(vae(some_image[None, ...]).sample[0]))\n",
    "    dist = vae.encode(resize(some_image, .5)[:, :64, :64].unsqueeze(0)).latent_dist\n",
    "    encoded = dist.sample()\n",
    "    print(encoded.shape)\n",
    "\n",
    "    decoded = vae.decode(encoded).sample\n",
    "    display(VF.to_pil_image(decoded[0]))\n",
    "\n",
    "    input_latents = encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73751bf1-66ef-42cb-9a1f-43c36dffcec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = pipe.components[\"unet\"]\n",
    "tokenizer = pipe.components[\"tokenizer\"]\n",
    "text_encoder = pipe.components[\"text_encoder\"]\n",
    "scheduler = pipe.components[\"scheduler\"]\n",
    "\n",
    "print(f\"params: {num_module_parameters(unet):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ece29-07c7-4961-bc74-b9cb6169667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(\"cthulhu\", padding=\"max_length\",\\\n",
    "        max_length=tokenizer.model_max_length, truncation=True,\\\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "empty_tokens = tokenizer([\"\"], padding=\"max_length\",\\\n",
    "        max_length=tokenizer.model_max_length, truncation=True,\\\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(tokens.input_ids.to(my_device))[0]\n",
    "    max_length = tokens.input_ids.shape[-1]\n",
    "    \n",
    "    notext_embeddings = text_encoder(empty_tokens.input_ids.to(my_device))[0]\n",
    "\n",
    "text_embeddings = torch.cat([notext_embeddings, text_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a92ec-d54e-4b49-86ef-d27fbb616c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    latents_in = vae.encode(torch.rand(2, 3, 512, 512)).latent_dist.sample()\n",
    "    latents_in = latents_in * scheduler.init_noise_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021bc14-3036-4512-83f0-f6088daeb364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scheduler = PNDMScheduler?#(**scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0301694-8625-405d-bf9c-29451b0b7eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latents = input_latents.repeat(2, 1, 1, 1) \n",
    "latents = latents_in\n",
    "\n",
    "latents_history = []\n",
    "image_widget = ImageWidget()\n",
    "display(image_widget)\n",
    "scheduler.set_timesteps(10)\n",
    "with torch.inference_mode():\n",
    "    latents = scheduler.scale_model_input(latents, timestep).to(my_device)\n",
    "    \n",
    "    for step_idx, timestep in enumerate(tqdm(scheduler.timesteps)):\n",
    "               \n",
    "        predicted_latents = unet(latents, timestep, text_embeddings).sample\n",
    "        #print(\"P\", latents.shape, \"->\", predicted_latents.shape)\n",
    "        latents = scheduler.step(predicted_latents, timestep, latents).prev_sample\n",
    "        #print(\"X\", predicted_latents.shape, \"->\", latents.shape)\n",
    "        \n",
    "        latents_history.append(latents)\n",
    "        images = vae.decode(latents).sample.clamp(0, 1)\n",
    "        image_widget.set_torch(make_grid(images))\n",
    "        \n",
    "        #latents = scheduler.step(latents, timestep, latents).prev_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974876f0-6b1b-45fd-b1bd-5d7a9056349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.ets[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7aeb8-8e07-4230-9eee-944f99f26af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    images = vae.decode(torch.concat(latents_history)).sample.clamp(0, 1)\n",
    "VF.to_pil_image(make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e0804c-b8c7-4fce-aea3-eea6fa1028d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
