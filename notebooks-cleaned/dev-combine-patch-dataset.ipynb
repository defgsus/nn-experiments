{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06090339-3db2-4a3c-9b9b-9f2e69a9d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset, RandomSampler\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.models as VM \n",
    "from IPython.display import display\n",
    "\n",
    "from src.util.image import *\n",
    "from src.util import *\n",
    "from src.models.util import *\n",
    "from src.algo import ca1\n",
    "from experiments.datasets import rpg_tile_dataset_3x32x32\n",
    "\n",
    "def resize(img, scale: float, mode: VF.InterpolationMode = VF.InterpolationMode.NEAREST):\n",
    "    return VF.resize(img, [max(1, int(s * scale)) for s in img.shape[-2:]], mode, antialias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f980ff-eeb5-4a7b-a281-f81cc1863d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "3*64*64 // 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54de808-a029-4ec0-bc7f-4ce06b22eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineImagePatchDataset(IterableDataset):\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            ds: Union[Dataset, IterableDataset],\n",
    "            shape: Tuple[int, int],\n",
    "            num_combine: int = 4,\n",
    "            black_is_alpha: bool = True,\n",
    "    ):\n",
    "        self.ds = ds\n",
    "        self.shape = shape\n",
    "        self.num_combine = num_combine\n",
    "        self.black_is_alpha = black_is_alpha\n",
    "        self.sub_transforms = VT.Compose([\n",
    "            VT.RandomVerticalFlip(.3),\n",
    "            VT.RandomHorizontalFlip(.3),\n",
    "        ])\n",
    "\n",
    "    def __iter__(self):\n",
    "        patches = []\n",
    "        for patch in self.ds:\n",
    "            if isinstance(patch, (list, tuple)):\n",
    "                patch = patch[0]\n",
    "            patches.append(patch)\n",
    "\n",
    "            if len(patches) >= self.num_combine:\n",
    "                yield from self._iter_patch_combinations(patches)\n",
    "                patches.clear()\n",
    "\n",
    "        if len(patches) > 1:\n",
    "            yield from self._iter_patch_combinations(patches)\n",
    "\n",
    "    def _iter_patch_combinations(self, patches):\n",
    "        C, H, W = patches[0].shape[-3:]\n",
    "        #image = torch.zeros(C, *self.shape)\n",
    "        for background_idx in range(len(patches)):\n",
    "            mode = VF.InterpolationMode.NEAREST if torch.randint(0, 2, (1,)).item() else VF.InterpolationMode.BICUBIC\n",
    "            image = VF.resize(patches[background_idx], self.shape, interpolation=mode, antialias=False)\n",
    "            for idx in torch.randperm(len(patches)):\n",
    "                if idx != background_idx:\n",
    "                    x = torch.randint(0, image.shape[-1] - W, (1,)).item()\n",
    "                    y = torch.randint(0, image.shape[-2] - H, (1,)).item()\n",
    "                    patch = self.sub_transforms(patches[idx])\n",
    "                    if self.black_is_alpha: \n",
    "                        mask = (patch.sum(dim=0) > 0).float().unsqueeze(0).expand(C, -1, -1)\n",
    "                        patch = patch + (1. - mask) * image[:, y: y+H, x: x+W]\n",
    "                    image[:, y: y+H, x: x+W] = patch\n",
    "                    \n",
    "            yield image\n",
    "\n",
    "ds = CombineImagePatchDataset(rpg_tile_dataset_3x32x32(), shape=(64, 64))\n",
    "patches = [p for i, p in zip(range(128), ds)]\n",
    "VF.to_pil_image(resize(make_grid(patches), 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151b0fd-780a-4f20-a89c-8c5a8f0ced1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
