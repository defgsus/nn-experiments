{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd5096-b06e-4b91-8c93-746da1754856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *\n",
    "from typing import Literal\n",
    "from src.models.fractal import KaliSetLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063afe4f-b854-454a-a247-ff8c115b1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_grid(\n",
    "    width: int = 256, \n",
    "    height: int = 256, \n",
    "    min_x: float = -1.,\n",
    "    max_x: float = 1.,\n",
    "    min_y: float = -1.,\n",
    "    max_y: float = 1.,\n",
    "    z: float = 1.,\n",
    "):\n",
    "    return torch.concat([\n",
    "        g[None, ...]\n",
    "        for g in torch.meshgrid(\n",
    "            torch.linspace(min_y, max_y, height),\n",
    "            torch.linspace(min_x, max_x, width), \n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "        ] + [torch.ones(1, height, width) * z]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481e328-3f27-4cdd-beb9-6913e9ab8f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612ef52-76df-41c6-b27f-5d266bb714f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2ead7-a115-486a-bd75-9a66be587070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2ba24-16a8-476d-9393-daaf7396e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid = []\n",
    "for accum in (\"none\", \"mean\", \"max\", \"min\", \"submin\", \"alternate\"):\n",
    "    model = KaliSetLayer((.5, .6, .7), iterations=7, axis=0, accumulate=accum, exponent=1.)\n",
    "    grid.append(model(coord_grid()).clamp(0, 1))\n",
    "VF.to_pil_image(make_grid(grid, nrow=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c97bc-7751-4353-905c-757819f30a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503c714-60ca-4a65-b9bd-072ba95c7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = []\n",
    "for scale in (None, .5, 2.):\n",
    "    for offset in (None, (.5, 0, 0), (0, .5, 0)):\n",
    "        model = KaliSetLayer((.5, .6, .7), iterations=7, axis=0, offset=offset, scale=scale, exponent=1.)\n",
    "        grid.append(model(coord_grid(z=0.)).clamp(0, 1))\n",
    "VF.to_pil_image(make_grid(grid, nrow=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff21088-8488-4314-82eb-1d1221148f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = to_torch_device(\"auto\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1118c01-9377-40a8-af11-11343cd0180c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9e844-ac91-4007-9240-cbc70c23bcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc4012-cbe2-47a0-967b-af65fdabaa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image = PIL.Image.open(\n",
    "    #\"/home/bergi/Pictures/DSCN0010.jpg\"\n",
    "    \"/home/bergi/Pictures/__diverse/Screenshot_2025-03-18_16-21-29.png\"\n",
    ").convert(\"RGB\")\n",
    "target_image = resize(target_image, .3)\n",
    "target_image = target_image.crop((100, 150, 250, 270))\n",
    "display(target_image)\n",
    "target_image = VF.to_tensor(target_image).to(device)\n",
    "print(target_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a8075-c8c1-499a-88eb-0d716134867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image2 = PIL.Image.new(\"RGB\", (200, 120))\n",
    "draw = PIL.ImageDraw.ImageDraw(target_image2)\n",
    "draw.text((0, -20), \"YO!\", font=PIL.ImageFont.truetype(\"/usr/share/fonts/truetype/noto/NotoSans-ExtraBold.ttf\", 120))\n",
    "display(target_image2)\n",
    "target_image2 = VF.to_tensor(target_image2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec8332-f4ac-45d5-9707-6113376c873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModel(nn.Module):\n",
    "    def __init__(self, num: int = 4, seed: int = 23):\n",
    "        super().__init__()\n",
    "        self.rng = random.Random(seed)\n",
    "        self.models = nn.ModuleList()\n",
    "        for i in range(num):\n",
    "            self.models.append(KaliSetLayer(\n",
    "                param=tuple(self.rng.uniform(.1, .9) for _ in range(3)),\n",
    "                axis=-3,\n",
    "                iterations=3 + 2 * self.rng.randrange(5), \n",
    "                accumulate=self.rng.choice(KaliSetLayer.ACCUMULATION_TYPES),\n",
    "                #exponent=10.,\n",
    "                offset=tuple(self.rng.uniform(-.5, .5) for _ in range(3)),\n",
    "                learn_param=True, \n",
    "                learn_mixer=True,\n",
    "                learn_offset=True,\n",
    "                learn_scale=True,\n",
    "            ))\n",
    "    def forward(self, x, num: Optional[int] = None):\n",
    "        y = None\n",
    "        models = self.models[:num] if num is not None else self.models\n",
    "        for m in models:\n",
    "            o = m(x)\n",
    "            if y is None:\n",
    "                y = o\n",
    "            else:\n",
    "                y += o\n",
    "        return y\n",
    "\n",
    "def train_model(model, t_image):\n",
    "    model.to(device)\n",
    "    t_image = t_image.to(device)\n",
    "    #src = torch.rand_like(target_image) * 0.1\n",
    "    src = coord_grid(\n",
    "        t_image.shape[-1], t_image.shape[-2],\n",
    "        #min_x=.5, max_x=.6,\n",
    "        #min_y=.5, max_y=.6,\n",
    "    ).to(device)\n",
    "    image_param = nn.Parameter(src, requires_grad=True)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW([\n",
    "        #image_param, \n",
    "        *model.parameters(),\n",
    "    ], 0.01)\n",
    "    from src.scheduler import CosineAnnealingWarmupLR\n",
    "    scheduler = CosineAnnealingWarmupLR(optimizer, 10000, warmup_steps=50)\n",
    "    loss_func = nn.L1Loss()\n",
    "\n",
    "    try:\n",
    "        num_models = 1\n",
    "        with tqdm(range(scheduler.T_max), ncols=115) as progress:\n",
    "            for i in progress:\n",
    "                output = model(image_param, num=num_models)\n",
    "                if i % 1000 == 0 and num_models < len(model.models):\n",
    "                    num_models += 1\n",
    "                if i % 1000 == 0:\n",
    "                    display(VF.to_pil_image(\n",
    "                        make_grid([image_param, output, t_image]).clamp(0, 1)\n",
    "                    ))\n",
    "                loss = loss_func(output, t_image)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                grad_max = image_param.grad.max().item()\n",
    "                #par = \", \".join(str(round(p.item(), 2)) for p in model.param)\n",
    "                #ofs = \", \".join(str(round(p.item(), 2)) for p in model.offset)\n",
    "                progress.set_postfix({\"lr\": scheduler.get_last_lr()[0], \"grad_max\": grad_max, \"loss\": loss.item()})\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    display(VF.to_pil_image(model(coord_grid().to(device)).clamp(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d14821-53e2-45d5-b250-b65e2c3282bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\n",
    "    MultiModel(8, seed=1001),\n",
    "    resize(target_image, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c4dd35-5de4-4751-a90f-93a07f9d9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\n",
    "    MultiModel(2, seed=123),\n",
    "    resize(target_image2, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea0d0f-fa6c-42be-b634-43c921081890",
   "metadata": {},
   "outputs": [],
   "source": [
    "VF.to_pil_image(model(coord_grid().to(device)).clamp(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b204a-aef3-483b-9b76-1ce03ced8c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de59af4-100c-4361-a084-14e218797754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
