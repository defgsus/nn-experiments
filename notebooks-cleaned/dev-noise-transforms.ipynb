{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19898e36-3fea-48c1-9a82-eb80dc94648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992296a-fcf3-4f42-8234-d20c1a644c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.rpg_tile_dataset_3x32x32(shape=(3, 64, 64))\n",
    "#dataset = datasets.fmnist_dataset(train=True)\n",
    "dataset = datasets.kali_patch_dataset((3, 64, 64))\n",
    "\n",
    "patches = next(iter(DataLoader(dataset, batch_size=64)))\n",
    "print(patches.shape)\n",
    "VF.to_pil_image(resize(make_grid(patches), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023a2f6d-64bf-492c-9181-c69d5f959465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883685e2-5bf7-4617-bd55-1ed90f346787",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCropHalfImage(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            prob: float = 1.,\n",
    "            null_value: float = 0.,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.prob = prob\n",
    "        self.null_value = null_value\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        if input.ndim == 3:\n",
    "            return self._crop_half(input)\n",
    "        elif input.ndim == 4:\n",
    "            return torch.concat([\n",
    "                self._crop_half(img).unsqueeze(0)\n",
    "                for img in input\n",
    "            ])\n",
    "        else:\n",
    "            raise ValueError(f\"input must have 3 or 4 dimensions, got {input}\")\n",
    "\n",
    "    def _crop_half(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        if random.uniform(0, 1) >= self.prob:\n",
    "            return image\n",
    "            \n",
    "        lrtb = random.randrange(4)\n",
    "        if lrtb == 0:\n",
    "            slices = slice(None, None), slice(None, image.shape[-1] // 2) \n",
    "        elif lrtb == 1:\n",
    "            slices = slice(None, None), slice(image.shape[-1] // 2, None) \n",
    "        elif lrtb == 2:\n",
    "            slices = slice(None, image.shape[-2] // 2), slice(None, None)\n",
    "        else:\n",
    "            slices = slice(image.shape[-2] // 2, None), slice(None, None) \n",
    "        \n",
    "        new_image = image + 0\n",
    "        new_image[:, slices[0], slices[1]] = self.null_value\n",
    "        return new_image\n",
    "        \n",
    "\n",
    "noise_patches = RandomCropHalfImage(prob=1.)(patches)\n",
    "VF.to_pil_image(resize(make_grid(noise_patches), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d33c2a-e891-42f1-8f60-16e0bcd5b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNoise(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            amt_min: float = .01,\n",
    "            amt_max: float = .15,\n",
    "            amt_power: float = 2.,\n",
    "            grayscale_prob: float = .1,\n",
    "            prob: float = 1.,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.amt_min = amt_min\n",
    "        self.amt_max = amt_max\n",
    "        self.amt_power = amt_power\n",
    "        self.grayscale_prob = grayscale_prob\n",
    "        self.prob = prob\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        if input.ndim == 3:\n",
    "            return self._noise(input)\n",
    "        elif input.ndim == 4:\n",
    "            return torch.concat([\n",
    "                self._noise(img).unsqueeze(0)\n",
    "                for img in input\n",
    "            ])\n",
    "        else:\n",
    "            raise ValueError(f\"input must have 3 or 4 dimensions, got {input}\")\n",
    "\n",
    "    def _noise(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        if random.uniform(0, 1) >= self.prob:\n",
    "            return image\n",
    "            \n",
    "        amt = math.pow(random.uniform(0, 1), self.amt_power)\n",
    "        amt = self.amt_min + (self.amt_max - self.amt_min) * amt\n",
    "\n",
    "        if random.uniform(0, 1) < self.grayscale_prob:\n",
    "            noise = torch.randn_like(image[..., :1, :, :]).repeat(\n",
    "                *(1 for _ in range(image.ndim - 3)),\n",
    "                image.shape[-3], 1, 1\n",
    "            )\n",
    "        else:\n",
    "            noise = torch.randn_like(image)\n",
    "\n",
    "        return (image + amt * noise).clamp(0, 1)\n",
    "\n",
    "\n",
    "noise_patches = ImageNoise(amt_min=.1, amt_max=.1, prob=1., grayscale_prob=.5)(patches)\n",
    "VF.to_pil_image(resize(make_grid(noise_patches), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa5c08-7816-431c-892e-421e3c532ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMultiNoise(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            amt_min: float = .01,\n",
    "            amt_max: float = .15,\n",
    "            amt_power: float = 2.,\n",
    "            blur_sigma_min: float = 0.,\n",
    "            blur_sigma_max: float = 1.,\n",
    "            prob: float = 1.,\n",
    "            channel_modes: Optional[List[str]] = None,\n",
    "            distribution_modes: Optional[List[str]] = None,\n",
    "    ):\n",
    "        super().__init__()    \n",
    "        self.amt_min = amt_min\n",
    "        self.amt_max = amt_max\n",
    "        self.amt_power = amt_power\n",
    "        self.blur_sigma_min = blur_sigma_min\n",
    "        self.blur_sigma_max = blur_sigma_max\n",
    "        self.prob = prob\n",
    "        if channel_modes is None:\n",
    "            channel_modes = [\"white\", \"color\"]\n",
    "        self.channel_modes = channel_modes\n",
    "        if distribution_modes is None:\n",
    "            distribution_modes = [\"gauss\", \"positive\", \"negative\", \"positive-negative\"]\n",
    "        self.distribution_modes = distribution_modes\n",
    "        \n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        if input.ndim == 3:\n",
    "            return self._noise(input)\n",
    "        elif input.ndim == 4:\n",
    "            return torch.concat([\n",
    "                self._noise(img).unsqueeze(0)\n",
    "                for img in input\n",
    "            ])\n",
    "        else:\n",
    "            raise ValueError(f\"input must have 3 or 4 dimensions, got {input}\")\n",
    "\n",
    "    def _noise(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        if random.uniform(0, 1) >= self.prob:\n",
    "            return image\n",
    "            \n",
    "        amt = math.pow(random.uniform(0, 1), self.amt_power)\n",
    "        amt = self.amt_min + (self.amt_max - self.amt_min) * amt\n",
    "\n",
    "        channel_mode = random.choice(self.channel_modes)\n",
    "        distribution_mode = random.choice(self.distribution_modes)\n",
    "\n",
    "        if distribution_mode == \"gauss\":\n",
    "            rand_func = torch.randn_like\n",
    "        elif distribution_mode in (\"positive\", \"negative\"):\n",
    "            rand_func = torch.rand_like\n",
    "        elif distribution_mode == \"positive-negative\":\n",
    "            rand_func = lambda x: torch.rand_like(x) - torch.rand_like(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown distribution_mode '{distribution_mode}'\")\n",
    "            \n",
    "        if channel_mode == \"white\":\n",
    "            noise = rand_func(image[..., :1, :, :]).repeat(\n",
    "                *(1 for _ in range(image.ndim - 3)),\n",
    "                image.shape[-3], 1, 1\n",
    "            )\n",
    "        elif channel_mode == \"color\":\n",
    "            noise = rand_func(image)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown channel_mode '{channel_mode}'\")\n",
    "\n",
    "        blur_sigma = random.uniform(self.blur_sigma_min, self.blur_sigma_max)\n",
    "        if blur_sigma > 0.:\n",
    "            noise = VF.gaussian_blur(noise, 5, blur_sigma)\n",
    "        \n",
    "        if distribution_mode == \"negative\":\n",
    "            noise = -noise\n",
    "\n",
    "        return (image + amt * noise).clamp(0, 1)\n",
    "\n",
    "\n",
    "noise_patches = ImageMultiNoise(amt_min=.0, amt_max=.3)(patches)\n",
    "VF.to_pil_image(resize(make_grid(noise_patches), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e507fd6-7875-4f06-b5dd-026f79f469c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = [\n",
    "    torch.rand(10000) - torch.rand(10000),\n",
    "    torch.randn(10000),\n",
    "]\n",
    "    \n",
    "for data in noises:\n",
    "    display(px.histogram(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a7dcb-be96-466e-a972-15f565811c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelartDataset(Dataset):\n",
    "\n",
    "    LABELS = [\n",
    "        'creature',\n",
    "        'wall',\n",
    "        'tree',\n",
    "        'carpet',\n",
    "        'grass',\n",
    "        'rock',\n",
    "        'water',\n",
    "        'wood',\n",
    "        'sand',\n",
    "        'roof',\n",
    "        'sword',\n",
    "        'cobblestone',\n",
    "        'plant',\n",
    "        'platform',\n",
    "        'stairs',\n",
    "        'shelf',\n",
    "        'block',\n",
    "        'axe',\n",
    "        'food',\n",
    "        'door',\n",
    "        'dirt',\n",
    "        'window',\n",
    "        'pipe',\n",
    "        'floor',\n",
    "        'table',\n",
    "        'bridge',\n",
    "        'stone',\n",
    "        'bed',\n",
    "        'fire',\n",
    "        'other',\n",
    "    ]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        shape: Tuple[int, int, int] = (3, 32, 32),\n",
    "    ):\n",
    "        self._out_shape = shape\n",
    "        self._patch_dataset = None\n",
    "        self._label_to_id = {l: i for i, l in enumerate(self.LABELS)}\n",
    "        self._fallback_id = self._label_to_id[\"other\"]\n",
    "        \n",
    "    def __len__(self):\n",
    "        self._lazy_load()\n",
    "        return self._meta[\"count\"]\n",
    "\n",
    "    def _lazy_load(self):\n",
    "        if self._patch_dataset is None:\n",
    "            path = Path(\"~/prog/python/github/pixelart-dataset/datasets/v2/\").expanduser()\n",
    "            self._meta = json.loads((path / \"tiles.json\").read_text())\n",
    "            patch_shape = (self._out_shape[0], *self._meta[\"shape\"])\n",
    "            self._patch_dataset = ImagePatchDataset((3, 32, 32), path / \"tiles.png\")\n",
    "            self._patch_df = pd.read_csv(path / \"tiles.csv\")\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        self._lazy_load()\n",
    "        item = self._patch_dataset[index]\n",
    "        label = self._patch_df.iloc[index][\"label\"]\n",
    "        \n",
    "        if label not in self._label_to_id:\n",
    "            for base_label in self.LABELS:\n",
    "                if base_label in label:\n",
    "                    self._label_to_id[label] = self._label_to_id[base_label]\n",
    "                    break\n",
    "                    \n",
    "        #print(self._patch_df.iloc[index])\n",
    "        return item, self._label_to_id.get(label, self._fallback_id)\n",
    "\n",
    "ds = PixelartDataset()\n",
    "\n",
    "counts = {}\n",
    "for image, label in tqdm(ds):\n",
    "    label = ds.LABELS[label]\n",
    "    counts[label] = counts.get(label, 0) + 1\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11077d94-0316-4aac-b13e-1804a8027068",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12963458-3a04-48e1-89ae-47100160e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(counts, index=[\"count\"]).T.sort_values(\"count\", ascending=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a80064-daba-4740-8844-3f4dfefb7ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dist = {'creature': 2003,\n",
    "    'wall': 1577,\n",
    "    'tree': 734,\n",
    "    'carpet': 645,\n",
    "    'grass': 593,\n",
    "    'rock': 530,\n",
    "    'water': 515,\n",
    "    'wood': 432,\n",
    "    'sand': 369,\n",
    "    'roof': 349,\n",
    "    'sword': 319,\n",
    "    'cobblestone': 285,\n",
    "    'plant': 273,\n",
    "    'platform': 270,\n",
    "    'stairs': 257,\n",
    "    'shelf': 254,\n",
    "    'block': 234,\n",
    "    'axe': 211,\n",
    "    'grass/sand': 209,\n",
    "    'food': 198,\n",
    "    'door': 185,\n",
    "    'dirt': 183,\n",
    "    'window': 173,\n",
    "    'pipe': 167,\n",
    "    'floor': 166,\n",
    "    'table': 163,\n",
    "    'bridge': 157,\n",
    "    'sceptre': 133,\n",
    "    'stone': 127,\n",
    "    'bed': 125,\n",
    "    'fire': 125,\n",
    "    'statue': 122,\n",
    "    'shield': 122,\n",
    "    'boundary': 119,\n",
    "    'ice': 114,\n",
    "    'steel': 111,\n",
    "    'glow': 109,\n",
    "    'fish': 109,\n",
    "    'armour': 101,\n",
    "    'grass/rock': 100,\n",
    "    'dirt/sand': 96,\n",
    "    'book': 89,\n",
    "    'fence': 88,\n",
    "    'terrain': 88,\n",
    "    'chair': 88,\n",
    "    'symbol': 84,\n",
    "    'cobblestone/grass': 77,\n",
    "    'dirt/rock': 76,\n",
    "    'sand/water': 76,\n",
    "    'spear': 74,\n",
    "    'dirt/grass': 72,\n",
    "    'column': 71,\n",
    "    'potion': 71,\n",
    "    'doorway': 69,\n",
    "    'tombstone': 67,\n",
    "    'boat': 65,\n",
    "    'helmet': 61,\n",
    "    'gear': 56,\n",
    "    'arrow': 55,\n",
    "    'jewelry': 54,\n",
    "    'scroll': 52,\n",
    "    'fountain': 52,\n",
    "    'pot': 51,\n",
    "    'ring': 51,\n",
    "    'chest': 50,\n",
    "    'lamp': 50,\n",
    "    'rock/water': 50,\n",
    "    'cloth': 50,\n",
    "    'bow': 45,\n",
    "    'doorway/wall': 45,\n",
    "    'boots': 44,\n",
    "    'rock/wall': 44,\n",
    "    'grass/tree': 43,\n",
    "    'sign': 38,\n",
    "    'explosion': 37,\n",
    "    'machine': 37,\n",
    "    'wall/window': 35,\n",
    "    'cobblestone/dirt': 32,\n",
    "    'dirt/water': 32,\n",
    "    'slime': 31,\n",
    "    'grass/water': 30,\n",
    "    'wall/water': 30,\n",
    "    'rock/terrain': 29,\n",
    "    'barrel': 29,\n",
    "    'hand': 29,\n",
    "    'ice/water': 29,\n",
    "    'well': 28,\n",
    "    'ladder': 28,\n",
    "    'sphere': 28,\n",
    "    'coin': 26,\n",
    "    'grass/platform': 26,\n",
    "    'lava': 25,\n",
    "    'background': 24,\n",
    "    'leaves': 24,\n",
    "    'tool': 23,\n",
    "    'skull': 21,\n",
    "    'snow': 21,\n",
    "    'grass/terrain': 20,\n",
    "    'creature/tree': 20,\n",
    "    'curtain': 18,\n",
    "    'ground': 17,\n",
    "    'house': 17,\n",
    "    'dirt/wall': 16,\n",
    "    'anvil': 16,\n",
    "    'mace': 16,\n",
    "    'clock': 16,\n",
    "    'cloud': 14,\n",
    "    'head': 14,\n",
    "    'steel/wood': 14,\n",
    "    'mountain': 14,\n",
    "    'key': 13,\n",
    "    'mushroom': 12,\n",
    "    'spikes': 12,\n",
    "    'door/wall': 12,\n",
    "    'bones': 11,\n",
    "    'sand/tree': 11,\n",
    "    'barricade': 10,\n",
    "    'gun': 10,\n",
    "    'hat': 10,\n",
    "    'dirt/tree': 10,\n",
    "    'stone/terrain': 9,\n",
    "    'stars': 9,\n",
    "    'background/wall': 9,\n",
    "    'crystal': 8,\n",
    "    'ornament': 8,\n",
    "    'roof/wood': 8,\n",
    "    'sarcophargus': 7,\n",
    "    'grass/stone': 7,\n",
    "    'background/doorway': 6,\n",
    "    'blood': 6,\n",
    "    'carpet/wood': 6,\n",
    "    'robot': 4,\n",
    "    'clock/tree': 4,\n",
    "    'bomb': 3,\n",
    "    'stain': 3,\n",
    "    'block/steel': 3,\n",
    "    'hole': 3,\n",
    "    'fire/glow': 3,\n",
    "    'cobblestone/water': 3,\n",
    "    'creature/fire': 3,\n",
    "    'gloves': 2,\n",
    "    'plant/pot': 2,\n",
    "    'paper': 2,\n",
    "    'tank': 2,\n",
    "    'cobblestone/sand': 2,\n",
    "    'boomerang': 2,\n",
    "    'dirt/grass/rock': 2,\n",
    "    'block/wood': 2,\n",
    "    'flag': 2,\n",
    "    'window/wood': 2,\n",
    "    'bucket': 1,\n",
    "    'sand/wall': 1,\n",
    "    'terrain/wall': 1,\n",
    "    'tunnel': 1,\n",
    "    'spaceship': 1,\n",
    "    'ground/skull': 1,\n",
    "    'explosion/glow': 1,\n",
    "    'skull/symbol': 1,\n",
    "    'background/cobblestone': 1,\n",
    "    'head/helmet': 1,\n",
    "    'arrow/sword': 1,\n",
    "    'lamp/wall': 1,\n",
    "    'candle': 1,\n",
    "    'floor/hole/wall': 1,\n",
    "    'carpet/sword': 1,\n",
    "    'door/wood': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198fd375-3073-41d5-9899-8ed5fe467340",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\n",
    "    'creature',\n",
    "    'wall',\n",
    "    'tree',\n",
    "    'carpet',\n",
    "    'grass',\n",
    "    'sand',\n",
    "    'cobblestone',\n",
    "    'rock',\n",
    "    'water',\n",
    "    'wood',\n",
    "    'roof',\n",
    "    'sword',\n",
    "    'weapon',\n",
    "    'plant',\n",
    "    'platform',\n",
    "    'stairs',\n",
    "    'shelf',\n",
    "    'block',\n",
    "    'food',\n",
    "    'door',\n",
    "    'dirt',\n",
    "    'window',\n",
    "    'pipe',\n",
    "    'floor',\n",
    "    'furniture',\n",
    "    \"fire\",\n",
    "    \"statue\",\n",
    "    \"armour\",\n",
    "    \"boundary\",\n",
    "]\n",
    "len(LABELS)\n",
    "\n",
    "label_mapping = {\n",
    "    \"bridge\": \"wood\",\n",
    "    \"sword\": \"weapon\",\n",
    "    \"axe\": \"weapon\",\n",
    "    \"sceptre\": \"weapon\",\n",
    "    \"spear\": \"weapon\",\n",
    "    \"stone\": \"rock\",\n",
    "    \"bed\": \"furniture\",\n",
    "    \"table\": \"furniture\",\n",
    "    \"chair\": \"furniture\",\n",
    "    \"shield\": \"armour\",\n",
    "    \"glow\": \"fire\",\n",
    "    \"fish\": \"food\",\n",
    "    \"arrow\": \"weapon\",\n",
    "}\n",
    "\n",
    "for label, c in label_dist.items():\n",
    "    label = label_mapping.get(label, label)\n",
    "    if label not in LABELS:\n",
    "        found = False\n",
    "        for top_label in LABELS:\n",
    "            if top_label in label:\n",
    "                label = top_label\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print(label, c)\n",
    "            continue\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bc482-8cbe-4881-8c88-4ac522554b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(label_dist.keys())[:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4000ae-f491-4e6c-b8da-49176679e861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3fc5d3-ebd5-47b7-bc0b-4a6ed476885d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d15ed-6b17-4fd5-9029-32c8ede37369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNoiseDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            image_dataset: Dataset,\n",
    "            amt_min: float = .01,\n",
    "            amt_max: float = .15,\n",
    "            amt_power: float = 1.,\n",
    "            amounts_per_arg: Iterable[float] = (1,),\n",
    "            grayscale_prob: float = .0,\n",
    "            prob: float = 1.,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._image_dataset = image_dataset\n",
    "        self._amt_min = amt_min\n",
    "        self._amt_max = amt_max\n",
    "        self._amt_power = amt_power\n",
    "        self._amounts_per_arg = amounts_per_arg\n",
    "        self._grayscale_prob = grayscale_prob\n",
    "        self._prob = prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._image_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self._image_dataset[index]\n",
    "\n",
    "        is_tuple = isinstance(item, (list, tuple))\n",
    "        if is_tuple:\n",
    "            image, *rest = item\n",
    "        else:\n",
    "            image, rest = item, []\n",
    "\n",
    "        amt = math.pow(random.uniform(0, 1), self._amt_power)\n",
    "        amt = self._amt_min + (self._amt_max - self._amt_min) * amt\n",
    "        is_grayscale = random.uniform(0, 1) < self._grayscale_prob\n",
    "        \n",
    "        if random.uniform(0, 1) >= self._prob:\n",
    "            noisy_images = [image for _ in self._amounts_per_arg]\n",
    "        else:\n",
    "            noisy_images = []\n",
    "            noisy_image = image\n",
    "            for sub_amt in self._amounts_per_arg:\n",
    "                if is_grayscale:\n",
    "                    noise = torch.randn_like(image[..., :1, :, :]).repeat(\n",
    "                        *(1 for _ in range(image.ndim - 3)),\n",
    "                        image.shape[-3], 1, 1\n",
    "                    )\n",
    "                else:\n",
    "                    noise = torch.randn_like(image)\n",
    "\n",
    "                noisy_image = (noisy_image + sub_amt * amt * noise).clamp(0, 1)\n",
    "                noisy_images.append(noisy_image)\n",
    "\n",
    "        if is_tuple:\n",
    "            return *noisy_images, *rest\n",
    "        else:\n",
    "            if len(noisy_images) == 1:\n",
    "                return noisy_images[0]\n",
    "            else:\n",
    "                return *noisy_images,\n",
    "\n",
    "ds = ImageNoiseDataset(\n",
    "    PixelartDataset(), \n",
    "    amt_min=.1, amt_max=1.,\n",
    "    amounts_per_arg=(1., 1.3),\n",
    ")\n",
    "images = []\n",
    "for i, tup in zip(range(32), ds):\n",
    "    images.append(tup[0])\n",
    "    images.append(tup[1])\n",
    "VF.to_pil_image(resize(make_grid(images), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9729a-747e-40cb-b9b2-aa0956782e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = torch.utils.data.sampler.RandomSampler([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d16369-9945-4f86-b73e-baa718f58edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sampler:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdfcc12-af55-457a-992a-d5e853da111e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
