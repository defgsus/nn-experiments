{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896580de-dfbd-4fec-9480-fcc6b6ff9d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from src.datasets.ca import *\n",
    "from src.models.rbm import RBM\n",
    "from src.models.cnn import ConvAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3b9d5b-3d87-40f7-a7a3-4860d59255db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = TotalCADataset(\n",
    "    (32, 32), \n",
    "    seed=23,\n",
    "    #num_repetitions=8,\n",
    "    #num_iterations=[1, 20],\n",
    "    #init_prob=[0, 1],\n",
    "    #rules=[\"3-23\", \"124-45\"],\n",
    "    dtype=torch.float,\n",
    ")\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c590a-d3a1-45d3-811b-f07d51b16dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_images(iterable, num: int = 8*8, nrow: int = 8):\n",
    "    images = []\n",
    "    for image in iterable:\n",
    "        if isinstance(image, (list, tuple)):\n",
    "            image = image[0]\n",
    "        if image.ndim == 2:\n",
    "            image = image.unsqueeze(0)\n",
    "        images.append(image)\n",
    "        if len(images) >= num:\n",
    "            break\n",
    "    return VF.to_pil_image(make_grid(images, nrow=nrow))\n",
    "\n",
    "dl = DataLoader(ds)\n",
    "plot_images(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ef8e8-f657-40a1-a587-07f56156e778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_FILE = \"../checkpoints/ae-ca-32x32x32-fft/snapshot.pt\"\n",
    "FEATURES_FILE = \"../checkpoints/ae-ca-32x32x32-fft/ca-features.pt\"\n",
    "IMAGES_FILE = \"../datasets/ca-32x32.pt\"\n",
    "RULES_FILE = \"../datasets/ca-32x32-rules.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb676d70-d945-4791-8a8a-62c795e7154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = RBM(math.prod(ds.shape), 32)\n",
    "model = ConvAutoEncoder((1, 32, 32), channels=[32, 64], code_size=32)\n",
    "model.load_state_dict(torch.load(MODEL_FILE)[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9dc65-2b11-4877-9a7b-02b2a6b78b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store ca -> features\n",
    "\n",
    "if Path(FEATURES_FILE).exists() and Path(IMAGES_FILE).exists() and Path(RULES_FILE).exists():\n",
    "    features = torch.load(FEATURES_FILE)\n",
    "    images = torch.load(IMAGES_FILE)\n",
    "    \n",
    "else:\n",
    "    torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "    dl = DataLoader(ds, batch_size=100, num_workers=3)\n",
    "\n",
    "    features = []\n",
    "    image_array = []\n",
    "    rules_array = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl):\n",
    "            images, rules = batch\n",
    "            images = images.reshape(-1, 1, 32, 32)\n",
    "            features.append(model.encode(images))\n",
    "            image_array.append(images)\n",
    "            rules_array.append(rules)\n",
    "            #if len(features) > 5:\n",
    "            #    break\n",
    "        features = torch.cat(features)\n",
    "        torch.save(features, FEATURES_FILE)\n",
    "        images = torch.cat(image_array)\n",
    "        torch.save(images, IMAGES_FILE)\n",
    "        rules = torch.cat(rules_array)\n",
    "        torch.save(rules, RULES_FILE)\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e98bd-07b8-4650-8ce4-bf67f6854636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d64778-999c-4c21-97b3-723ce5d2b72f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import cluster\n",
    "from IPython.display import display, HTML\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94637af-31aa-461d-88ff-7be3dc60cc37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#clusterer = cluster.BisectingKMeans(32, verbose=0, n_init=\"auto\")\n",
    "clusterer = cluster.BisectingKMeans(32, verbose=0, init=\"k-means++\")\n",
    "#clusterer.fit(images.reshape(images.shape[0], -1))\n",
    "clusterer.fit(features)\n",
    "\n",
    "#labels = clusterer.predict(images.reshape(images.shape[0], -1))\n",
    "labels = clusterer.predict(features)\n",
    "\n",
    "cluster_sizes = [\n",
    "    (labels == l).sum()\n",
    "    for l in range(clusterer.n_clusters)\n",
    "]\n",
    "px.bar(y=cluster_sizes, title=\"cluster sizes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c1e82-7a5a-4791-b3e8-2578bcb4a6e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for label in range(clusterer.n_clusters):\n",
    "    cluster_images = images[labels == label]\n",
    "    display(HTML(f\"<h3>label #{label}: {cluster_images.shape[0]}</h3>\"))\n",
    "    display(plot_images(cluster_images, nrow=21, num=21*3))\n",
    "\n",
    "    cluster_rules = rules[labels == label].mean(axis=0).reshape(1, 2, 9)\n",
    "    cluster_rules = VF.resize(cluster_rules, (40, 180), interpolation=VF.InterpolationMode.NEAREST)\n",
    "    display(VF.to_pil_image(cluster_rules))\n",
    "    #print(cluster_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100973c-0085-4b27-821b-7a4c19c723ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
