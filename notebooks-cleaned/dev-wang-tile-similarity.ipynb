{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eccb303-8302-421e-8ec9-05848a20fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef74b4f-fa29-4a8d-bcc0-c635c1bc2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.datasets import PixelartDataset\n",
    "\n",
    "ds = PixelartDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632cccbb-0017-4ef7-b956-73c9ae41622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wang_patches = []\n",
    "for wang_tiles in (wangtiles.WangTiles2E(), wangtiles.WangTiles2C()):\n",
    "    wang_template = wang_tiles.create_template((32, 32), fade=3., padding=-.5)\n",
    "    # VF.to_pil_image(wang_template.image)\n",
    "    wang_patches.extend([\n",
    "        i.unsqueeze(0) for i in iter_image_patches(wang_template.image, (32, 32))\n",
    "    ])\n",
    "\n",
    "wang_patches = torch.concat(wang_patches)\n",
    "display(VF.to_pil_image(make_grid(wang_patches, nrow=4)))\n",
    "\n",
    "wang_weights = wang_patches.flatten(1) / torch.norm(wang_patches.flatten(1), dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa3551-7d68-498f-becd-c496f4261cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_image_batch(input):\n",
    "    return (input.flatten(1) / torch.norm(input.flatten(1), dim=1, keepdim=True)).reshape(input.shape)\n",
    "\n",
    "def get_similarity(input, weights=wang_weights):\n",
    "    input = input.flatten(1)\n",
    "    input = input / torch.norm(input, dim=1, keepdim=True)\n",
    "    return input @ weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b0851-467f-4f63-90c1-9d05d576dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = []\n",
    "label_filter = PixelartDataset.LABELS.index(\"wall\") \n",
    "for patch, label in DataLoader(ds, shuffle=True):\n",
    "    if label == label_filter:\n",
    "        patches.append(patch)\n",
    "    if len(patches) >= 512:\n",
    "        break\n",
    "patches = torch.concat(patches)       \n",
    "#patches = ds.sample(256)[0]\n",
    "print(patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a8100-809b-477a-b1e5-cf16a3b6fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = get_similarity(patches)\n",
    "print(wang_weights.shape)\n",
    "px.imshow(sim.T, height=400, aspect=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33707f6c-b5d8-4260-a1b0-d2e80fc5a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_t = sim.T\n",
    "indices = sim_t.argsort(dim=1, descending=True)\n",
    "grid = []\n",
    "grid_labels = [\"\"] * wang_patches.shape[0]\n",
    "grid.extend(wang_patches)\n",
    "for j in range(20):\n",
    "    for i in range(wang_patches.shape[0]):\n",
    "        grid.append(patches[indices[i][j]])\n",
    "        grid_labels.append(round(float(sim_t[i, indices[i][j]]), 2))\n",
    "\n",
    "VF.to_pil_image(make_grid_labeled(grid, labels=grid_labels, nrow=wang_patches.shape[0]))\n",
    "#indices.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835aae1-5a1f-4a03-ab2c-a2a694a6e431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a7bf977-e576-41a9-a0b8-35a678bec7f5",
   "metadata": {},
   "source": [
    "# compare PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656babbd-b10c-44df-98d1-bc5be933ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(32)\n",
    "pca.fit(ds.sample(len(ds))[0].flatten(1))\n",
    "VF.to_pil_image(make_grid(torch.Tensor(pca.components_).reshape(-1, 4, 32, 32), normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210dd071-49d3-49ef-9394-6b985f577684",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_weights = torch.Tensor(pca.components_)\n",
    "pca_weights /= torch.norm(pca_weights, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86812a46-b0a3-47a4-b517-3ceddd81db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_t = get_similarity(patches, pca_weights).T\n",
    "print(sim_t.shape)\n",
    "px.imshow(sim_t, height=400, aspect=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d46dadc-5fdd-4f56-8ea5-c16036fa33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = sim_t.argsort(dim=1, descending=True)\n",
    "grid = []\n",
    "grid_labels = [\"\"] * wang_patches.shape[0]\n",
    "grid.extend(pca_weights.reshape(-1, 3, 32, 32))\n",
    "for j in range(20):\n",
    "    for i in range(sim_t.shape[0]):\n",
    "        grid.append(patches[indices[i][j]])\n",
    "        grid_labels.append(round(float(sim_t[i, indices[i][j]]), 2))\n",
    "\n",
    "VF.to_pil_image(make_grid_labeled(grid, labels=grid_labels, nrow=wang_patches.shape[0]))\n",
    "#indices.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9d365-f41b-46dd-b628-44c98dd6b95d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
