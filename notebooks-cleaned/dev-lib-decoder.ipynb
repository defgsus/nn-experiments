{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37c33f-4429-49ff-ba3f-5a7abd35f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union, Type\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset, RandomSampler\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display\n",
    "\n",
    "from src.util.image import *\n",
    "from src.util import *\n",
    "from src.algo import ca1\n",
    "from src.models.util import *\n",
    "from src.models.transform import *\n",
    "from src.models.debug import DebugLayer\n",
    "\n",
    "def resize(img, scale: float, mode: VF.InterpolationMode = VF.InterpolationMode.NEAREST):\n",
    "    return VF.resize(img, [max(1, int(s * scale)) for s in img.shape[-2:]], mode, antialias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a50ef-d64e-4949-95fb-5c316fcf027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = torch.load(\"../datasets/rpg-3x32x32-uint-test.pt\").float() / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200002d-614b-4639-8954-ba58eb8ddf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_patches = []\n",
    "for p in patches:\n",
    "    for sp in iter_image_patches(p, shape=(16, 16), stride=(4, 4)):\n",
    "        small_patches.append(sp.unsqueeze(0))\n",
    "small_patches = torch.concat(small_patches)\n",
    "small_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55600330-2a91-4650-8356-55790a0ed014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(128)\n",
    "pca.fit(small_patches.flatten(1))\n",
    "lib = torch.Tensor(pca.components_).view(-1, 3, *small_patches.shape[-2:])\n",
    "#lib = (lib - lib.min()) / (lib.max() - lib.min())\n",
    "print(f\"min/max: {lib.min()}/{lib.max()}\")\n",
    "\n",
    "display(VF.to_pil_image(resize(make_grid(lib, normalize=True, nrow=16), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10dbe37-430d-49b4-8226-37a1679c25d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lib, \"../datasets/pca-128x3x16x16.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef8b43-989d-4855-abce-2b3a5b118be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_size = lib.shape[0]\n",
    "patch_size = lib.shape[-1]\n",
    "\n",
    "w = torch.randn(8, lib_size, 4, 4)\n",
    "c = nn.ConvTranspose2d(lib_size, 3, patch_size, stride=patch_size, bias=False)\n",
    "with torch.no_grad():\n",
    "    c.weight[:] = lib\n",
    "print(\"w\", c.weight.shape)\n",
    "o = c(w)#.view(-1, 3, 10, 32, 32)\n",
    "print(f\"output {o.shape}, min/max: {o.min()}/{o.max()}\")\n",
    "o = F.sigmoid(o)\n",
    "VF.to_pil_image(resize(make_grid(\n",
    "    o#.clamp(0, 1)\n",
    ", normalize=False, nrow=4), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f934e2-ce8f-4de7-a917-d7aa78f75cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibDecoder2d(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            shape: Tuple[int, int, int],\n",
    "            code_size: int,\n",
    "            lib_size: int,\n",
    "            patch_size: Union[int, Tuple[int, int]],\n",
    "            patch_filename: Optional[str] = None,\n",
    "            output_activation: Union[None, str, Callable] = \"sigmoid\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.shape = tuple(shape)\n",
    "        self.code_size = code_size\n",
    "        self.lib_size = lib_size\n",
    "        if isinstance(patch_size, int):\n",
    "            patch_size = [patch_size, patch_size]\n",
    "            \n",
    "        self.grid_shape = (shape[-2] // patch_size[-2], shape[-1] // patch_size[-1]) \n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(code_size, lib_size * math.prod(self.grid_shape))  \n",
    "        )\n",
    "         \n",
    "        self.conv = nn.ConvTranspose2d(lib_size, shape[0], kernel_size=patch_size, stride=patch_size)\n",
    "        if patch_filename:\n",
    "            with torch.no_grad():\n",
    "                self.conv.weight[:] = torch.load(patch_filename)\n",
    "                \n",
    "        self.output_activation = activation_to_callable(output_activation)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        grid = self.mlp(x).reshape(-1, self.lib_size, *self.grid_shape)\n",
    "        return self.output_activation(self.conv(grid))\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return f\"shape={self.shape}, code_size={self.code_size}, lib_size={self.lib_size}\"\n",
    "\n",
    "model = LibDecoder2d((3, 64, 64), 100, 128, (16, 16), patch_filename=\"../datasets/pca-128x3x16x16.pt\")\n",
    "print(f\"params: {num_module_parameters(model):,}\")\n",
    "print(\"out:\", model(torch.rand(1, 100)).shape)\n",
    "\n",
    "display(VF.to_pil_image(resize(make_grid(\n",
    "    model(torch.rand(16, 100))\n",
    ", normalize=False, nrow=4), 4)))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f8338-10e4-4206-b913-d9a67bd68cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResMLP(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_channels: int,\n",
    "            num_hidden: int,\n",
    "            activation: Union[None, str, Callable] = \"relu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_hidden = num_hidden\n",
    "\n",
    "        self.mlp = nn.Sequential()\n",
    "        self.mlp.add_module(\"linear1\", nn.Linear(num_channels, num_hidden))\n",
    "        self.mlp.add_module(\"act1\", activation_to_module(activation))\n",
    "        self.mlp.add_module(\"linear2\", nn.Linear(num_hidden, num_hidden))\n",
    "        self.mlp.add_module(\"act2\", activation_to_module(activation))\n",
    "        self.mlp.add_module(\"linear3\", nn.Linear(num_hidden, num_channels))\n",
    "        self.mlp.add_module(\"act3\", activation_to_module(activation))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.mlp(x)\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1ed29-3efb-47f5-a797-2fbdf2072eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class PatchConv(nn.Module):\n",
    "    \n",
    "\n",
    "class PatchAutoencoder2d(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            shape: Tuple[int, int, int],\n",
    "            code_size: int,\n",
    "            lib_size: int,\n",
    "            patch_size: Union[int, Tuple[int, int]],\n",
    "            mlp_blocks: int = 2,\n",
    "            mlp_cells: Optional[int] = None,\n",
    "            mlp_activation: Union[None, str, Callable] = \"relu\",\n",
    "            output_activation: Union[None, str, Callable] = \"sigmoid\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.shape = tuple(shape)\n",
    "        self.code_size = code_size\n",
    "        self.lib_size = lib_size\n",
    "        if isinstance(patch_size, int):\n",
    "            patch_size = [patch_size, patch_size]\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        self.grid_shape = (shape[-2] // patch_size[-2], shape[-1] // patch_size[-1])\n",
    "        grid_size = lib_size * math.prod(self.grid_shape)\n",
    "        if mlp_cells is None:\n",
    "            mlp_cells = grid_size\n",
    "            \n",
    "        self.encoder = nn.Sequential()\n",
    "        self.encoder.add_module(\"patch\", nn.Conv2d(shape[0], lib_size, kernel_size=patch_size, stride=patch_size))\n",
    "        self.encoder.add_module(\"flatten\", nn.Flatten(-3))\n",
    "        for i in range(mlp_blocks):\n",
    "            self.encoder.add_module(f\"block{i+1}\", ResMLP(grid_size, mlp_cells, activation=mlp_activation))\n",
    "        #self.encoder.add_module(\"d\", DebugLayer())\n",
    "        self.encoder.add_module(f\"proj\", nn.Linear(grid_size, code_size))\n",
    "        \n",
    "        print(self.grid_shape, grid_size)\n",
    "        self.decoder = nn.Sequential()\n",
    "        self.decoder.add_module(f\"proj\", nn.Linear(code_size, grid_size))\n",
    "        for i in range(mlp_blocks):\n",
    "            self.decoder.add_module(f\"block{i+1}\", ResMLP(grid_size, mlp_cells, activation=mlp_activation))\n",
    "        self.decoder.add_module(\"unflatten\", Reshape((lib_size, *self.grid_shape)))\n",
    "        self.decoder.add_module(\"patch\", nn.ConvTranspose2d(lib_size, shape[0], kernel_size=patch_size, stride=patch_size))\n",
    "        if output_activation is not None:\n",
    "            self.decoder.add_module(\"act_out\", activation_to_module(output_activation))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"shape={self.shape}, code_size={self.code_size}, lib_size={self.lib_size}, patch_size={self.patch_size}\"\n",
    "\n",
    "model = PatchAutoencoder2d((3, 64, 64), 100, 256, (16, 16), mlp_cells=128)\n",
    "print(f\"params: {num_module_parameters(model):,}\")\n",
    "print(model)\n",
    "model(torch.rand(1, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42171bb7-7cf4-4e1a-8116-28854625c9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da082d9-bc5b-4204-b7a3-894dae18edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.decoder import *\n",
    "from src.models.encoder import *\n",
    "\n",
    "class EnsembleDecoder2d(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            shape: Tuple[int, int, int],\n",
    "            code_size: int,\n",
    "            activation: Union[None, str, Callable] = \"relu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.shape = tuple(shape)\n",
    "        self.code_size = code_size\n",
    "\n",
    "        self.conv = DecoderConv2d(shape=shape, code_size=code_size)\n",
    "        self.manifold = ImageManifoldDecoder(\n",
    "            default_shape=shape[-2:], num_input_channels=code_size, num_output_channels=shape[0],\n",
    "            pos_embedding_freqs=(7, 17, 77,),\n",
    "            activation_out=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.conv(x)\n",
    "        y2 = self.manifold(x)\n",
    "        return F.sigmoid(y1) + y2\n",
    "\n",
    "\n",
    "model = EnsembleDecoder2d((3, 64, 64), 100)\n",
    "print(f\"params: {num_module_parameters(model):,}\")\n",
    "out = model(torch.rand(8, 100))\n",
    "print(out.shape)\n",
    "display(VF.to_pil_image(make_grid(out)))\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b4040-fc69-4bfb-bd65-ca75e460ca30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2d5fe-692e-4ee4-9923-37e1176e479c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9746d4a-8564-4c61-a78f-f961b154986d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
