{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785da0b-6841-43a6-b1e2-f132b18d4634",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd4865-7b57-45cc-b8ed-8d09195d2e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from init_notebook import *\n",
    "import lark\n",
    "\n",
    "lark.logger.setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f57a31-323c-4f67-b74a-031495879504",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "start: elements\n",
    "elements: element (\"-\" element)*\n",
    "element: layer | loop | default_assignment\n",
    "loop: UINT \"x(\" elements \")\"\n",
    "layer: conv | activation_layer | batch_norm_layer | residual_layer\n",
    "\n",
    "activation_layer: ACTIVATION\n",
    "\n",
    "batch_norm_layer: \"bn\"\n",
    "\n",
    "residual_layer: \"r(\" layer \")\"\n",
    "\n",
    "default_assignment: (kernel_size | stride | dilation | padding | activation)+\n",
    "\n",
    "conv: channels \"x\" (kernel_size | stride | dilation | padding | activation)*\n",
    "channels: UINT | UFLOAT\n",
    "kernel_size: \"k\" UINT | UINT\n",
    "stride: \"s\" UINT\n",
    "dilation: \"d\" UINT\n",
    "padding: \"p\" UINT\n",
    "activation: \"a\" ACTIVATION\n",
    "\n",
    "ACTIVATION: \"relu\" | \"gelu\" | \"sigmoid\" | \"tanh\"\n",
    "UINT: /0|[1-9]\\d*/\n",
    "UFLOAT: UINT? \".\" /\\d/*\n",
    "\"\"\"\n",
    "class Transformer(lark.Transformer):\n",
    "    def UINT(self, token: lark.Token):\n",
    "        return int(token.value)\n",
    "    def UFLOAT(self, token: lark.Token):\n",
    "        return float(token.value)\n",
    "    def ACTIVATION(self, token: lark.Token):\n",
    "        return activation_to_module(token.value)\n",
    "        \n",
    "parser = lark.Lark(grammar, parser=\"lalr\", transformer=Transformer())\n",
    "try:\n",
    "    tree = parser.parse(\n",
    "        #\"r(32x3p1arelu)-3x(64xk5p2s3-bn)-tanh\"\n",
    "        #\"k9s3arelu-24x-48xatanh-64x\"\n",
    "        \"16x-3x(1.5x)-r(1.x)-.5x\"\n",
    "    )\n",
    "    print(tree)\n",
    "    print(tree.pretty())\n",
    "except lark.exceptions.LarkError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050a904-0be0-430e-a44f-af2a0b741e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context:\n",
    "    def __init__(\n",
    "            self,\n",
    "            layers: nn.Sequential,\n",
    "            default_conv_attrs: dict,\n",
    "            previous_channels: int = 3\n",
    "    ):\n",
    "        self.layers = layers\n",
    "        self.default_conv_attrs = default_conv_attrs\n",
    "        self.previous_channels = previous_channels\n",
    "\n",
    "    def __copy__(self):\n",
    "        return self.__class__(\n",
    "            layers=self.layers, \n",
    "            default_conv_attrs=self.default_conv_attrs,\n",
    "            previous_channels=self.previous_channels,\n",
    "        )\n",
    "        \n",
    "    def replace(self, key: str, value: Any) -> \"Context\":\n",
    "        new_context = self.__copy__()\n",
    "        setattr(new_context, key, value)\n",
    "        return new_context\n",
    "        \n",
    "def add_layers(\n",
    "        context: Context,\n",
    "        tree: lark.Tree,\n",
    "):  \n",
    "    #context = context.__copy__()\n",
    "    if tree.data.value in (\"start\", \"elements\"):\n",
    "        for ch in tree.children:\n",
    "            add_layers(context, ch)\n",
    "    \n",
    "    elif tree.data.value == \"element\":\n",
    "        if tree.children[0].data.value == \"loop\":\n",
    "            for i in range(int(tree.children[0].children[0])):\n",
    "                add_layers(context, tree.children[0].children[1])\n",
    "        \n",
    "        elif tree.children[0].data.value == \"layer\":\n",
    "            add_layers(context, tree.children[0])\n",
    "\n",
    "        elif tree.children[0].data.value == \"default_assignment\":\n",
    "            for conv_attr in tree.children[0].children:\n",
    "                context.default_conv_attrs[conv_attr.data.value] = conv_attr.children[0]\n",
    "\n",
    "    elif tree.data.value == \"layer\":\n",
    "        if tree.children[0].data.value == \"conv\":\n",
    "            conv_attrs = context.default_conv_attrs.copy()\n",
    "            for conv_attr in tree.children[0].children:\n",
    "                conv_attrs[conv_attr.data.value] = conv_attr.children[0]\n",
    "            out_channels = conv_attrs.pop(\"channels\")\n",
    "            if isinstance(out_channels, float):\n",
    "                out_channels = int(context.previous_channels * out_channels)\n",
    "            act = conv_attrs.pop(\"activation\", None)\n",
    "            context.layers.append(\n",
    "                nn.Conv2d(in_channels=context.previous_channels, out_channels=out_channels, **conv_attrs)\n",
    "            )\n",
    "            if act is not None:\n",
    "                context.layers.append(act)\n",
    "            context.previous_channels = out_channels\n",
    "\n",
    "        elif tree.children[0].data.value == \"activation_layer\":\n",
    "            act = tree.children[0].children[0]\n",
    "            if act is not None:\n",
    "                context.layers.append(act)\n",
    "\n",
    "        elif tree.children[0].data.value == \"batch_norm_layer\":\n",
    "            context.layers.append(nn.BatchNorm2d(num_features=context.previous_channels))\n",
    "\n",
    "        elif tree.children[0].data.value == \"residual_layer\":\n",
    "            sub_context = context.__copy__()\n",
    "            sub_context.layers = nn.Sequential()\n",
    "            print(\"R\", tree.children[0].children[0])\n",
    "            add_layers(sub_context, tree.children[0].children[0])\n",
    "            context.layers.append(ResidualAdd(sub_context.layers))\n",
    "            context.previous_channels = sub_context.previous_channels\n",
    "\n",
    "context = Context(\n",
    "    layers = nn.Sequential(),\n",
    "    default_conv_attrs = {\n",
    "        \"channels\": 16, \n",
    "        \"kernel_size\": 3, \n",
    "        \"stride\": 1, \n",
    "        \"dilation\": 1, \n",
    "        \"padding\": 0, \n",
    "        \"bias\": True,\n",
    "    },\n",
    "    previous_channels=3,\n",
    ")\n",
    "add_layers(context, tree)\n",
    "context.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef554a2d-3f39-4e5f-96ef-dbbc1b96259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BatchNorm2d?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
