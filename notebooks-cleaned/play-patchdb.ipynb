{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed27b1-5eb4-4b6b-ab64-a2fe8e2c88f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union, Dict\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset, RandomSampler\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display\n",
    "\n",
    "from src.datasets import *\n",
    "from src.algo import GreedyLibrary\n",
    "from src.util.image import *\n",
    "from src.util import to_torch_device\n",
    "from src.patchdb import PatchDB, PatchDBIndex\n",
    "from src.models.encoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e22bd-aa06-4f83-b69e-d716d97908f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -l ../models/encoder2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5533ca-9f23-4d0e-9ca4-0f3a2b01ac97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encoder = EncoderConv2d.from_torch(\"../models/encoder2d/encoder-1x32x32-128-photo-5.pt\", device=\"cpu\")\n",
    "encoder = EncoderConv2d.from_torch(\"../models/encoder2d/conv-1x32x32-128-all1.pt\", device=\"cpu\")\n",
    "#encoder = BoltzmanEncoder2d.from_torch(\"../models/encoder2d/boltzman-1x32x32-128-photo-300M.pt\", device=\"cpu\")\n",
    "encoder.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf2211-961e-448c-a7f6-87714bf728d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = PatchDB(\n",
    "    #\"../db/photos-1x32x32-2.patchdb\", \n",
    "    #\"../db/photos-bigpatch-1x32x32.patchdb\",\n",
    "    #\"../db/kali-1x32x32.patchdb\",\n",
    "    #\"../db/diverse-1x32x32-3b.patchdb\",\n",
    "    #\"../db/diverse-1x32x32-3b-rbm-300M.patchdb\",\n",
    "    #\"../db/kali-1x64x64-rbm300M.patchdb\",\n",
    "    #\"../db/bob-1x32x32-convall1.patchdb\",\n",
    "    #\"../db/fjord-1x32x32-convall1.patchdb\",\n",
    "    #\"../db/serifs-1x32x32-convall1.patchdb\",\n",
    "    #\"../db/hyperplane-1x32x32-convall1.patchdb\",\n",
    "    #\"../db/hyperplane-inv-1x32x32-convall1.patchdb\",\n",
    "    \"../db/topping-1x32x32-convall1.patchdb\",\n",
    "    #\"../db/cells-1x32x32-convall1.patchdb\",\n",
    "    #\"../db/sand-1x32x32-convall1.patchdb\",\n",
    "    \n",
    "    encoder=encoder,\n",
    "    verbose=True, limit=1_000_000, \n",
    ")\n",
    "index = db.index()\n",
    "print(f\"{index.size} patches, {len(index.filenames())} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38b004-5d41-43b5-b960-32ebccedafa8",
   "metadata": {},
   "source": [
    "# random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47561466-69d6-49e2-8e71-acd9542ef64e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VF.to_pil_image(make_grid(\n",
    "    [index.patches[random.randrange(index.size)].patch for _ in range(30*30)], \n",
    "    nrow=30,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb74ec-87cc-4b55-a6a3-ba03b949fdbe",
   "metadata": {},
   "source": [
    "# samples per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ceea3c-5db8-417e-a949-0cf2a9fa42e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_per_image = {}\n",
    "for patch in index.patches:\n",
    "    if patch.filename not in samples_per_image:\n",
    "        samples_per_image[patch.filename] = []\n",
    "    samples_per_image[patch.filename].append(patch)\n",
    "\n",
    "for filename in sorted(samples_per_image):\n",
    "    print(filename)\n",
    "    patches = samples_per_image[filename]\n",
    "    display(VF.to_pil_image(make_grid(\n",
    "        [patches[random.randrange(len(patches))].patch for _ in range(30)], \n",
    "    nrow=30,\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19026e-0003-4a07-8d00-133e6dd4d8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1140c27-142c-44ee-82de-4fdaa094abdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# random similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11d3d9-afff-4be9-b5ee-14abd1a0dfec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_random_similars(index, encoder, count=30, count_sim=50):\n",
    "    patch_ids = list(range(index.size))\n",
    "    random.shuffle(patch_ids)\n",
    "    patch_ids = patch_ids[:count]\n",
    "    grid = []\n",
    "    sim_patches = []\n",
    "    for patch_id in tqdm(patch_ids):\n",
    "        patch = index.patches[patch_id].patch\n",
    "        # grid.append(patch) # will be the first anyway\n",
    "        sim_patches.append(index.similar_patches(patch, count=count_sim)[0])\n",
    "    \n",
    "    for y in range(count_sim):\n",
    "        for sim_patch in sim_patches:\n",
    "            patch = sim_patch[y].patch\n",
    "            grid.append(patch)\n",
    "            \n",
    "    return VF.to_pil_image(make_grid(grid, nrow=count))\n",
    "\n",
    "img = plot_random_similars(index, encoder, count_sim=30)\n",
    "img#.save(\"/home/bergi/Pictures/random-similars-patchdb-photos6M.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99287b79-b96b-4e8b-b945-23538847a8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_similars(index, patch_or_id, count=30, nrow=30):\n",
    "    if isinstance(patch_or_id, int):\n",
    "        patch = index.patches[patch_or_id].patch\n",
    "    else:\n",
    "        patch = patch_or_id\n",
    "    \n",
    "    sim_patches = index.similar_patches(patch, count=count)[0]\n",
    "    \n",
    "    grid = []\n",
    "    for sim_patch in sim_patches:\n",
    "        patch = sim_patch.patch\n",
    "        grid.append(patch)\n",
    "            \n",
    "    return VF.to_pil_image(make_grid(grid, nrow=nrow))\n",
    "\n",
    "img = plot_similars(index, 23, count=50*50, nrow=50)\n",
    "img#.save(\"/home/bergi/Pictures/random-similars-patchdb-photos6M.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2abd5-f966-4a9c-a4be-4096053226a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c107bfe5-f545-4107-b5eb-2803f8e68031",
   "metadata": {},
   "source": [
    "# image reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c7e27-f66f-4d9b-a647-8a01beaf7096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_window_2d(shape: Tuple[int, int]):\n",
    "    return (\n",
    "          torch.hamming_window(shape[-1], periodic=True).unsqueeze(0).expand(shape[-2], -1)\n",
    "        * torch.hamming_window(shape[-2], periodic=True).unsqueeze(0).expand(shape[-1], -1).T\n",
    "    )\n",
    "\n",
    "def reconstruct_image(\n",
    "        original: torch.Tensor,\n",
    "        index: PatchDBIndex,\n",
    "        sample_patch_shape: Optional[Tuple[int, int]] = None,\n",
    "        sub_sample: float = 1, \n",
    "        multi_sample: int = 1,  # only meaningful with random_first_patches>1\n",
    "        noise: float = 0.,\n",
    "        random_first_patches: int = 1,\n",
    "        padding: Union[None, int, Iterable[int]] = None,\n",
    "        fill: int = 0,\n",
    "):\n",
    "    assert index.db.encoder, \"Must be defined\"\n",
    "    encoder = index.db.encoder\n",
    "    \n",
    "    if sample_patch_shape is None:\n",
    "        sample_patch_shape = encoder.shape[-2:]\n",
    "        _scale = (1., 1.)\n",
    "    else:\n",
    "        _scale = (\n",
    "            sample_patch_shape[-2] / encoder.shape[-2], \n",
    "            sample_patch_shape[-1] / encoder.shape[-1],\n",
    "        )\n",
    "    \n",
    "    #output_shape = (\n",
    "    #    int(original.shape[-2] / encoder.shape[-2]) * encoder.shape[-2],\n",
    "    #    int(original.shape[-1] / encoder.shape[-1]) * encoder.shape[-1],\n",
    "    #)\n",
    "    \n",
    "    if isinstance(padding, int):\n",
    "        padding = [padding] * 4\n",
    "    \n",
    "    recon = torch.zeros(original.shape)\n",
    "    recon_sum = torch.zeros(original.shape)\n",
    "    if padding:\n",
    "        recon = F.pad(recon, padding, value=fill)\n",
    "        recon_sum = F.pad(recon_sum, padding, value=fill)\n",
    "    window = get_window_2d(sample_patch_shape or encoder.shape[-2:])\n",
    "    \n",
    "    try:\n",
    "        patches = []\n",
    "        positions = []\n",
    "        for patch, pos in iter_image_patches(\n",
    "            original, \n",
    "            shape=sample_patch_shape,\n",
    "            stride=(int(s / sub_sample) for s in sample_patch_shape),\n",
    "            with_pos=True,\n",
    "            padding=padding,\n",
    "            fill=fill,\n",
    "        ):\n",
    "            pos = [int(p) for p in pos]\n",
    "            if patch.shape[0] != encoder.shape[0]:\n",
    "                for chan in range(patch.shape[0]):\n",
    "                    patches.append(patch[chan].unsqueeze(0).unsqueeze(0))\n",
    "                    positions.append([chan] + pos)\n",
    "            else:\n",
    "                patches.append(patch.unsqueeze(0))\n",
    "                positions.append([slice(0, patch.shape[0])] + pos)\n",
    "                \n",
    "        similar_patches = []\n",
    "        with torch.no_grad():\n",
    "            with tqdm(desc=\"encoding/searching patches\", total=len(patches)) as progress:\n",
    "                for patch_batch, in DataLoader(TensorDataset(torch.concat(patches)), batch_size=512):\n",
    "                    feature_batch = encoder.encode_image(patch_batch)\n",
    "                    \n",
    "                    if noise:\n",
    "                        feature_batch = feature_batch + noise * torch.randn_like(feature_batch)\n",
    "            \n",
    "                    similar_patches += index.similar_patches(feature_batch, count=random_first_patches)\n",
    "                    \n",
    "                    progress.update(len(feature_batch))            \n",
    "                \n",
    "        for pos, sim_patches in tqdm(zip(positions, similar_patches), total=len(positions)):\n",
    "            chan, pos = pos[0], pos[1:]\n",
    "            \n",
    "            for ms_idx in range(multi_sample):\n",
    "                patch_recon = sim_patches[random.randrange(len(sim_patches))].patch\n",
    "                s1 = chan\n",
    "                s2 = slice(int(pos[0] * _scale[0]), int(pos[0] * _scale[0]) + patch_recon.shape[-2])\n",
    "                s3 = slice(int(pos[1] * _scale[1]), int(pos[1] * _scale[1]) + patch_recon.shape[-1])\n",
    "                recon[s1, s2, s3] = recon[s1, s2, s3] + patch_recon * window\n",
    "                recon_sum[s1, s2, s3] = recon_sum[s1, s2, s3] + window\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    mask = recon_sum > 0\n",
    "    recon[mask] = recon[mask] / recon_sum[mask]\n",
    "    return recon\n",
    "\n",
    "original = PIL.Image.open(\n",
    "    #\"/home/bergi/Pictures/csv-turing.png\"\n",
    "    #\"/home/bergi/Pictures/__diverse/28580_1.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/merkel_sarkozy_g8_regierungOnline_Kuehler_CMS_small_620.jpeg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/honecker.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/plakat01.jpg\"\n",
    "    #\"/home/bergi/Pictures/DWlZbQ5WsAQEzHT.jpg\"\n",
    "    #\"/home/bergi/Pictures/there_is_no_threat.jpeg\"\n",
    "    #\"/home/bergi/Pictures/diffusion/cthulhu-09.jpeg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/HourSlack-EarsBleed-2-72SM.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/parental_advisory.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/BP_Logo_01.png\"\n",
    "    #\"/home/bergi/Pictures/__diverse/994066096.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/EuropeAfricaNato.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/nobluesky2.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/Zeisswerk_Jena_um_1910.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/1907_Panic.png\"\n",
    "    #\"/home/bergi/Pictures/__diverse/schildkroe.bmp\"\n",
    "    #\"/home/bergi/Pictures/__diverse/nk_hammer+brush+sickle.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/Klaus_Naumann.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/cheney2.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/1233217389_800.jpg\"\n",
    "    \"/home/bergi/Pictures/IMG-20210108-WA0001.jpg\"\n",
    ")\n",
    "original = VF.to_tensor(original)\n",
    "original = set_image_channels(original, 1)\n",
    "original = VF.resize(original, [int(s / 1.5) for s in original.shape[-2:]])\n",
    "\n",
    "img = reconstruct_image(\n",
    "    original, index, sub_sample=2, \n",
    "    #noise=.0005, \n",
    "    random_first_patches=100,\n",
    "    multi_sample=1,\n",
    "    #sample_patch_shape=(),\n",
    "    #padding=5, fill=1,\n",
    ")\n",
    "display(VF.to_pil_image(img))\n",
    "display(VF.to_pil_image(original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528834db-5ec9-4310-8447-80bbfedfeeea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VF.to_pil_image(1. - img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee132d-4300-4537-b717-0a21d0c4f002",
   "metadata": {},
   "source": [
    "# reconstruct at random positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5e0ab-245c-4f55-afc5-b1ae65b23e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def reconstruct_image_random(\n",
    "        original: torch.Tensor,\n",
    "        index: PatchDBIndex,\n",
    "        num_patches: int = 1000,\n",
    "        noise: float = 0.,\n",
    "        random_first_patches: int = 1,\n",
    "        batch_size: int = 200,\n",
    "        mix: float = .5,\n",
    "):\n",
    "    assert index.db.encoder, \"Must be defined\"\n",
    "    encoder = index.db.encoder\n",
    "          \n",
    "    recon = torch.zeros(original.shape)\n",
    "    recon_sum = torch.zeros(original.shape)\n",
    "    window = get_window_2d(encoder.shape[-2:])\n",
    "    \n",
    "    def iter_patch_batches():\n",
    "        patch_batch = []\n",
    "        pos_batch = []\n",
    "        for i in tqdm(range(num_patches)):\n",
    "            s = random.randint(encoder.shape[-2] // 2, original.shape[-2] // 3)\n",
    "            rect = [s, s]\n",
    "            pos = [\n",
    "                random.randint(0, recon.shape[-2] - rect[-2]),\n",
    "                random.randint(0, recon.shape[-1] - rect[-1])\n",
    "            ]\n",
    "            patch = VF.resize(VF.crop(original, *pos, *rect), encoder.shape[-2:])\n",
    "            \n",
    "            patch_batch.append(patch.unsqueeze(0))\n",
    "            pos_batch.append(pos + rect)\n",
    "            \n",
    "            if len(patch_batch) >= batch_size:\n",
    "                yield torch.concat(patch_batch), pos_batch\n",
    "                patch_batch.clear()\n",
    "                pos_batch.clear()\n",
    "                \n",
    "        if len(patch_batch):\n",
    "            yield torch.concat(patch_batch), pos_batch\n",
    "    \n",
    "    try:\n",
    "        for patch_batch, pos_batch in iter_patch_batches():\n",
    "            feature_batch = encoder.encode_image(patch_batch)\n",
    "            sim_patches_batch = index.similar_patches(feature_batch, random_first_patches)\n",
    "            \n",
    "            for pos, sim_patches in zip(pos_batch, sim_patches_batch):\n",
    "            \n",
    "                patch_recon = sim_patches[random.randrange(len(sim_patches))].patch\n",
    "                patch_recon = VF.resize(patch_recon, pos[-2:])\n",
    "                \n",
    "                s1 = 0\n",
    "                s2 = slice(pos[0], pos[0] + pos[2])\n",
    "                s3 = slice(pos[1], pos[1] + pos[3])\n",
    "                \n",
    "                wmix = mix# * get_window_2d(patch_recon.shape[-2:])\n",
    "                recon[s1, s2, s3] = recon[s1, s2, s3] * (1. - wmix) + wmix * patch_recon \n",
    "                #recon_sum[s1, s2, s3] = recon_sum[s1, s2, s3] + wmix\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    mask = recon_sum > 0\n",
    "    #recon[mask] = recon[mask] / recon_sum[mask]\n",
    "    return recon\n",
    "\n",
    "original = PIL.Image.open(\n",
    "    \"/home/bergi/Pictures/csv-turing.png\"\n",
    "    #\"/home/bergi/Pictures/__diverse/28580_1.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/merkel_sarkozy_g8_regierungOnline_Kuehler_CMS_small_620.jpeg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/honecker.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/plakat01.jpg\"\n",
    "    #\"/home/bergi/Pictures/DWlZbQ5WsAQEzHT.jpg\"\n",
    "    #\"/home/bergi/Pictures/there_is_no_threat.jpeg\"\n",
    "    #\"/home/bergi/Pictures/diffusion/cthulhu-09.jpeg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/HourSlack-EarsBleed-2-72SM.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/parental_advisory.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/BP_Logo_01.png\"\n",
    "    #\"/home/bergi/Pictures/__diverse/994066096.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/EuropeAfricaNato.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/nobluesky2.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/Zeisswerk_Jena_um_1910.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/1907_Panic.png\"\n",
    "    #\"/home/bergi/Pictures/__diverse/schildkroe.bmp\"\n",
    "    #\"/home/bergi/Pictures/__diverse/nk_hammer+brush+sickle.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/Klaus_Naumann.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/cheney2.jpg\"\n",
    "    #\"/home/bergi/Pictures/__diverse/1233217389_800.jpg\"\n",
    ")\n",
    "original = VF.to_tensor(original)\n",
    "original = set_image_channels(original, 1)\n",
    "original = VF.resize(original, [s * 1 for s in original.shape[-2:]])\n",
    "\n",
    "img = reconstruct_image_random(\n",
    "    original, index, \n",
    "    num_patches=1000,\n",
    "    #noise=.002, \n",
    "    mix=.5,\n",
    "    #random_first_patches=100,\n",
    ")\n",
    "display(VF.to_pil_image(img))\n",
    "display(VF.to_pil_image(original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2213eec-5534-46fc-b822-7a8e4c1b0c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99079032-98e7-470c-a937-8df8fd4b5b19",
   "metadata": {},
   "source": [
    "# extend by patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc58cb6-e718-43cb-8428-0774a0f2b449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extend_patch_image(image, index, iters=1, mix=1., num_rand=1):\n",
    "    if iters > 1:\n",
    "        image = extend_patch_image(image, index, iters-1, mix=mix)\n",
    "        print(iters, end=\", \")\n",
    "    p_shape = index.db.patch_shape\n",
    "    padding = (p_shape[-2] // 4, p_shape[-1] // 3)\n",
    "    new_image = VF.pad(image, padding, padding_mode=\"reflect\")\n",
    "    def iter_slices():\n",
    "        for x in range(0, new_image.shape[-1], p_shape[-1]):\n",
    "            if x + p_shape[-1] <= new_image.shape[-1]:\n",
    "                yield slice(0, p_shape[-2]), slice(x, x + p_shape[-1])\n",
    "                yield slice(-p_shape[-2], None), slice(x, x + p_shape[-1])\n",
    "        for y in range(0, new_image.shape[-2], p_shape[-2]):\n",
    "            if y + p_shape[-2] <= new_image.shape[-2]:\n",
    "                yield slice(y, y + p_shape[-2]), slice(0, p_shape[-1])\n",
    "                yield slice(y, y + p_shape[-2]), slice(-p_shape[-1], None)\n",
    "    \n",
    "    source_patches = []\n",
    "    for s1, s2 in iter_slices():\n",
    "        source_patch = new_image[..., s1, s2]\n",
    "        source_patches.append(source_patch.unsqueeze(0))\n",
    "    \n",
    "    sim_patches = index.similar_patches(torch.concat(source_patches), num_rand)\n",
    "    for (s1, s2), sim_patch in zip(iter_slices(), sim_patches):#, desc=f\"iteration {iters}\"):\n",
    "        sim_patch = sim_patch[random.randrange(len(sim_patch))]\n",
    "        new_image[..., s1, s2] = new_image[..., s1, s2] * (1.-mix) + mix * sim_patch.patch\n",
    "    #display(VF.to_pil_image(new_image))\n",
    "    return new_image\n",
    "\n",
    "ex = extend_patch_image(VF.resize(index.patches[57].patch, (64, 64)), index, 35, mix=.1, num_rand=1000)\n",
    "VF.to_pil_image(ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
