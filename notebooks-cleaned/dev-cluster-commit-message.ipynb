{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340baff0-02e2-442a-b88f-a3feedb11f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union, Dict\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display, HTML\n",
    "import plotly\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "from src.datasets import *\n",
    "from src.util.image import *\n",
    "from src.util import *\n",
    "from src.util.files import *\n",
    "from src.util.embedding import *\n",
    "from src.algo import *\n",
    "from src.models.encoder import *\n",
    "from src.models.decoder import *\n",
    "from src.models.util import *\n",
    "from src.util.text_encoder import TextEncoder\n",
    "from src.util.gharchive import GHArchive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627b842-b6c1-43ba-b6da-dc5c9495fc4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = TextEncoder(\"bytefreq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea263ca-1b80-407a-8de0-66045b3ce532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iter_messages(\n",
    "    dates: Iterable[datetime.date] = (\n",
    "        datetime.date(2018, 1, 7),\n",
    "        datetime.date(2021, 1, 7),\n",
    "        datetime.date(2022, 1, 7),\n",
    "        datetime.date(2023, 11, 20)\n",
    "    ),\n",
    "    message_buffer_size: int = 1_000_000,\n",
    "    prob: float = 1.,\n",
    "    encodings: Optional[torch.Tensor] = None,\n",
    "    encoding_weights: Optional[torch.Tensor] = None,\n",
    "):\n",
    "    gharchive = GHArchive(verbose=True)\n",
    "    \n",
    "    if encodings is not None and encoding_weights is None:\n",
    "        assert encodings.ndim == 2, encodings.ndim\n",
    "        encoding_weights = torch.ones(encodings.shape[0])\n",
    "    \n",
    "    def _iter_events():\n",
    "        iterables = [\n",
    "            gharchive.iter_events(\n",
    "                day=date, \n",
    "                event_type=\"PushEvent\",\n",
    "                probability=prob,\n",
    "            )\n",
    "            for date in dates\n",
    "        ]\n",
    "        while iterables:\n",
    "            next_iterables = []\n",
    "            for it in iterables:\n",
    "                try:\n",
    "                    yield next(it)\n",
    "                    next_iterables.append(it)\n",
    "                    \n",
    "                except StopIteration:\n",
    "                    pass\n",
    "            iterables = next_iterables\n",
    "            \n",
    "    num_skipped = 0\n",
    "    num_yielded = 0\n",
    "    \n",
    "    def _iter_messages():\n",
    "        nonlocal num_skipped\n",
    "        \n",
    "        message_dict = {}\n",
    "        num_processed = 0\n",
    "        with tqdm() as progress:\n",
    "            for event in _iter_events():            \n",
    "                for commit in event[\"payload\"][\"commits\"]:\n",
    "                    message = commit[\"message\"]\n",
    "                    if message in message_dict:\n",
    "                        num_skipped += 1\n",
    "                        continue\n",
    "                    \n",
    "                    message_dict[message] = num_processed\n",
    "                    num_processed += 1\n",
    "                    \n",
    "                    yield commit[\"message\"]\n",
    "\n",
    "                progress.update(1)\n",
    "                progress.desc = (\n",
    "                    f\"messages/skips {num_yielded:,}/{num_skipped:,}\"\n",
    "                    f\", buffer-size {len(message_dict):,}\"\n",
    "                    f\", date={event['created_at']}\"\n",
    "                )\n",
    "\n",
    "                if len(message_dict) >= message_buffer_size:\n",
    "                    median = sorted(message_dict.values())\n",
    "                    # print(\"min/median/max\", median[0], median[len(median) // 2], median[-1])\n",
    "                    median = median[len(median) // 2]\n",
    "\n",
    "                    message_dict = {\n",
    "                        msg: step\n",
    "                        for msg, step in message_dict.items()\n",
    "                        if step <= median\n",
    "                    }\n",
    "                    # print(\"reduced buffer to\", len(message_dict))\n",
    "    \n",
    "    if encodings is None:\n",
    "        for message in _iter_messages():\n",
    "            yield message\n",
    "            num_yielded += 1\n",
    "    else:    \n",
    "        for batch in iter_batches(_iter_messages(), 128):\n",
    "            with torch.no_grad():\n",
    "                enc = encoder.encode(batch)\n",
    "            \n",
    "            sim_matrix = enc @ encodings.T\n",
    "            # print(sim_matrix)\n",
    "            for text, sims in zip(batch, sim_matrix):\n",
    "                skip = False\n",
    "                #print(len(batch), sim.shape, encoding_weights.shape)\n",
    "                for sim, weight in zip(sims, encoding_weights):\n",
    "                    if (weight >= 0 and sim < weight) or (weight < 0 and sim > -weight):\n",
    "                        skip = True\n",
    "                        break\n",
    "                \n",
    "                if skip:\n",
    "                    num_skipped += 1\n",
    "                else:\n",
    "                    yield text\n",
    "                    num_yielded += 1\n",
    "                \n",
    "try:\n",
    "    count = 0\n",
    "    for m in iter_messages(\n",
    "            prob=1/10, \n",
    "            #encodings=normalize_embedding(cluster_centers[5:6]), encoding_weights=torch.Tensor([.95]),\n",
    "    ):\n",
    "        if count < 10:\n",
    "            count += 1\n",
    "            print(repr(m))\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e56e3-cb96-4b11-930d-18c725cc022c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ac529b1-6f8e-4f65-a2f0-a4dca6734c73",
   "metadata": {
    "tags": []
   },
   "source": [
    "# cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f27e94-cd07-45e1-8dfc-ba7eb526c204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d02fe-9e12-46c9-870f-11220f746ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster as skcluster\n",
    "\n",
    "total = 10000\n",
    "num_clusters = 10\n",
    "\n",
    "try:\n",
    "    texts = []\n",
    "    for m, i in zip(iter_messages(\n",
    "            #prob=1. / 10,\n",
    "            #encodings=normalize_embedding(cluster_centers[5:6]), encoding_weights=torch.Tensor([.9]),\n",
    "            encodings=normalize_embedding(cluster_lib[\"short_texts\"].to_numpy()[None, :]), encoding_weights=torch.Tensor([.9]),\n",
    "    ), range(total)):\n",
    "        texts.append(m)\n",
    "        if len(texts) <= 10:\n",
    "            print(repr(texts[-1]))\n",
    "            \n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = encoder.encode(texts).cpu().numpy()\n",
    "\n",
    "print(\"clustering:\", embeddings.shape)\n",
    "\n",
    "#clusterer = skcluster.KMeans(num_clusters, n_init=\"auto\")\n",
    "#clusterer = skcluster.BisectingKMeans(num_clusters)\n",
    "clusterer = skcluster.SpectralClustering(num_clusters)\n",
    "labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "hist = np.histogram(labels, bins=num_clusters, range=(0, num_clusters))[0]\n",
    "px.bar(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a43460-fb2b-4c71-b9e0-c8ff4f8a8d2c",
   "metadata": {},
   "source": [
    "## get cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7e609-6a76-4e4b-9b21-88765f7a7ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if hasattr(clusterer, \"cluster_centers_\"):\n",
    "    cluster_centers = clusterer.cluster_centers_\n",
    "\n",
    "else:\n",
    "    cluster_centers = []\n",
    "    for ci in range(num_clusters):\n",
    "        c_indices = np.argwhere(labels == ci)[:, 0]\n",
    "        c_embeddings = embeddings[c_indices]\n",
    "        cluster_centers.append(c_embeddings.mean(axis=0)[None, :])\n",
    "    cluster_centers = normalize_embedding(np.concatenate(cluster_centers))\n",
    "\n",
    "df = pd.DataFrame(cluster_centers.T)\n",
    "df[\"char\"] = df.index.map(lambda i: chr(i) if 32 <= i < 128 else f\"0x{i:02x}\")\n",
    "px.line(\n",
    "    df, \n",
    "    title=f\"normalized byte frequencies of {len(texts):,} github commits, {num_clusters} cluster centers\",\n",
    "    hover_data=[\"char\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c6c07-375b-4a10-99c0-aa54c0899154",
   "metadata": {
    "tags": []
   },
   "source": [
    "# display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fce231-3846-4827-a86b-3634b138ac97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_examples = 5\n",
    "\n",
    "for ci in range(num_clusters):\n",
    "    \n",
    "    c_indices = np.argwhere(labels == ci)[:, 0]\n",
    "    c_embeddings = embeddings[c_indices]\n",
    "    c_center = cluster_centers[ci]\n",
    "\n",
    "    c_sim = normalize_embedding(cluster_centers[ci]) @ c_embeddings.T \n",
    "    c_sim_idx = np.argsort(c_sim)\n",
    "    \n",
    "    c_title = f\"cluster #{ci} -- {c_indices.shape[0] / len(texts) * 100:.2f}% ({c_indices.shape[0]} entries)\"\n",
    "    display(HTML(f\"\"\"<h3>{c_title}</h3>\"\"\"))\n",
    "    display(px.bar(c_center, height=300, title=c_title))\n",
    "    \n",
    "    print(\" -- best match --\")\n",
    "    for i in reversed(c_sim_idx[-num_examples:]):\n",
    "        idx, sim = c_indices[i], c_sim[i]\n",
    "        print(f\"  {sim:.3f} {repr(texts[idx][:100])}\")\n",
    "    print(\"\\n -- worst match --\")\n",
    "    for i in c_sim_idx[:num_examples]:\n",
    "        idx, sim = c_indices[i], c_sim[i]\n",
    "        print(f\"  {sim:.3f} {repr(texts[idx][:100])}\")\n",
    "    \n",
    "    display(HTML(\"<hr/>\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969f7a7-f493-4a58-b66f-0a7e7922a6fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_lib = pd.DataFrame()\n",
    "cluster_lib = pd.read_csv(\"./bytefreqs.csv\", index_col=0)\n",
    "cluster_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5dbdf4-d725-4e2e-970d-f05a14b41108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_lib[\"short_texts\"] = cluster_centers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21b29c-c7dc-4282-a3a0-d1e700260381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0dd177-5c77-4d64-954d-167023d1b6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_lib.to_csv(\"./bytefreqs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38479f58-c472-4fe9-a324-ac8af543132a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db1cf9-8ac2-4d37-9392-5c9e83b499ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_lib[\"short_texts\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54ad98b-2719-4085-9aa6-def00f4d0839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316ecd8-b1e3-41f0-82b1-66bf9e81f535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7e6367-9437-4c8b-84da-8827c5329a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87c984-a223-4178-8d1e-3a1d5eddd877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b292f12-eb37-49ac-a10a-842d59f13023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744e37b-fb15-45ce-a0d9-c43999266d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477f3ed-5c0f-4053-9cca-37d4701d809f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d10432-adff-42d4-82c7-f8e39fca62fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2c59d-5082-4b60-8182-914e5b1595b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7297b-6288-493a-8d55-44db032b7fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564d7ae-ad4b-4d0c-b99f-f02701547b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d54a25-3e05-4284-938e-f4bf38087792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e2725-61f6-40c0-aee9-c4edef56859c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1ed4e-54eb-48e0-bf70-1684fb425f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_bytes(texts: Iterable[str], normalize: bool, with_numpy: bool) -> torch.Tensor:\n",
    "    import numpy as np\n",
    "\n",
    "    tensors = []\n",
    "    for text in texts:\n",
    "        \n",
    "        if not with_numpy:\n",
    "            values = [0] * 256\n",
    "            for ch in text.encode():\n",
    "                values[ch] += 1\n",
    "                \n",
    "            tensors.append(torch.Tensor(values).unsqueeze(0))\n",
    "        else:\n",
    "            byte_array = np.frombuffer(text.encode(), dtype=np.uint8)\n",
    "            hist = np.histogram(byte_array, 256, (0, 256))[0]\n",
    "\n",
    "            tensors.append(hist[None, :])\n",
    "    \n",
    "    if with_numpy:\n",
    "        tensors = torch.Tensor(np.concatenate(tensors))\n",
    "    else:\n",
    "        tensors = torch.concat(tensors)\n",
    "    if normalize:\n",
    "        tensors = normalize_embedding(tensors)\n",
    "\n",
    "    return tensors\n",
    "\n",
    "texts = [\"Assignment2: Regression and Classifier models\\n\\nIn this assignment I used supervised learning models.\"] * 10000\n",
    "\n",
    "start_time = time.time()\n",
    "encode_bytes(texts, True, False)\n",
    "print(f\"{time.time() - start_time:.3f}\")\n",
    "start_time = time.time()\n",
    "encode_bytes(texts, True, True)\n",
    "print(f\"{time.time() - start_time:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901afdc9-09ac-4136-a662-7d6edc5487ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b0317-2b5c-4038-a418-bec5b048f65d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b22c0cb-88bf-4875-994c-709ce14bff8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48ae4f-9014-484d-bf6f-7e68c5e7a60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
