{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd98f9-1013-456d-a94e-89845d424e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display\n",
    "\n",
    "from src.datasets import *\n",
    "from src.util.image import *\n",
    "from src.util import *\n",
    "from src.algo import *\n",
    "from src.models.decoder import *\n",
    "\n",
    "def resize(img, scale: float, mode: VF.InterpolationMode = VF.InterpolationMode.NEAREST):\n",
    "    return VF.resize(img, [max(1, int(s * scale)) for s in img.shape[-2:]], mode, antialias=False)\n",
    "\n",
    "def plot_samples(\n",
    "        iterable, \n",
    "        total: int = 32, \n",
    "        nrow: int = 8, \n",
    "        return_image: bool = False, \n",
    "        show_compression_ratio: bool = False,\n",
    "        label: Optional[Callable] = None,\n",
    "):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    f = ImageFilter()\n",
    "    try:\n",
    "        for idx, entry in enumerate(tqdm(iterable, total=total)):\n",
    "            image = entry\n",
    "            if isinstance(entry, (list, tuple)):\n",
    "                image = entry[0]\n",
    "            if image.ndim == 4:\n",
    "                image = image.squeeze(0)\n",
    "            samples.append(image)\n",
    "            if show_compression_ratio:\n",
    "                labels.append(round(f.calc_compression_ratio(image), 3))\n",
    "            elif label is not None:\n",
    "                labels.append(label(entry) if callable(label) else idx)\n",
    "                \n",
    "            if len(samples) >= total:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    if labels:\n",
    "        image = VF.to_pil_image(make_grid_labeled(samples, nrow=nrow, labels=labels))\n",
    "    else:\n",
    "        image = VF.to_pil_image(make_grid(samples, nrow=nrow))\n",
    "    if return_image:\n",
    "        return image\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5e75a-37a4-4e2e-b592-eb55e6119a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TotalCALayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            birth: Union[None, torch.Tensor, Iterable[int]] = None,\n",
    "            survive: Union[None, torch.Tensor, Iterable[int]] = None,\n",
    "            iterations: int = 1,\n",
    "            learn_kernel: bool = False,\n",
    "            learn_rules: bool = False,\n",
    "            wrap: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Totalitarian Cellular Automaton as torch layer.\n",
    "        \n",
    "        :param birth: optional birth rule\n",
    "        :param survive: optional survival rule \n",
    "        :param iterations: number of iterations\n",
    "        :param learn_kernel: do train the neighbourhood kernel \n",
    "        :param learn_rules: do train the rules\n",
    "        :param wrap: if True, edges wrap around\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        for name, value in ((\"birth\", birth), (\"survive\", survive)):\n",
    "            if value is None:\n",
    "                value = torch.rand(9).bernoulli()\n",
    "            elif not isinstance(value, torch.Tensor):\n",
    "                value = torch.Tensor(value)\n",
    "\n",
    "            if value.shape != torch.Size((9, )):\n",
    "                raise ValueError(f\"Expected `{name}` to have shape (9), got {value.shape}\")\n",
    "\n",
    "            setattr(self, name, nn.Parameter(value, requires_grad=learn_rules))\n",
    "\n",
    "        self.iterations = iterations\n",
    "        self.wrap = wrap\n",
    "        self.kernel = nn.Parameter(torch.Tensor([[[[1, 1, 1], [1, 0, 1], [1, 1, 1]]]]), requires_grad=learn_kernel)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ndim = x.ndim\n",
    "        if ndim not in (3, 4):\n",
    "            raise ValueError(f\"Expected x.ndim == 3 or 4, got {x.shape}\")\n",
    "        if ndim == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        y = x\n",
    "        ch = x.shape[-3]\n",
    "        if ch != 1:\n",
    "            y = y.view(-1, 1, *x.shape[-2:])  # (BxC)xHxW\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            y = self._ca_step(y)\n",
    "\n",
    "        if ch != 1:\n",
    "            y = y.view(x.shape)\n",
    "\n",
    "        return y if ndim == 4 else y.squeeze(0)\n",
    "\n",
    "    def _ca_step(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.wrap:\n",
    "            xp = torch.concat([x[..., -1, None], x, x[..., 0, None]], dim=-1)\n",
    "            xp = torch.concat([xp[..., -1, None, :], xp, xp[..., 0, None, :]], dim=-2)\n",
    "            neighbour_count = F.conv2d(xp, self.kernel)\n",
    "        else:\n",
    "            neighbour_count = F.conv2d(x, self.kernel, padding=1)\n",
    "\n",
    "        neighbour_count = neighbour_count.long().clamp(0, 8)\n",
    "\n",
    "        birth = torch.index_select(self.birth, 0, neighbour_count.flatten(0)).view(x.shape)\n",
    "        survive = torch.index_select(self.survive, 0, neighbour_count.flatten(0)).view(x.shape)\n",
    "\n",
    "        return birth * (x < 1.) + survive * (x >= 1.)\n",
    "\n",
    "\n",
    "inp = torch.zeros(1, 3, 10, 10)\n",
    "inp[..., :, 3, 0] = 1\n",
    "inp[..., 0, 0, 4] = 1\n",
    "inp[..., 0, 5, 5] = 1\n",
    "inp[..., 0, 5, 6] = 1\n",
    "inp[..., 0, 6, 6] = 1\n",
    "inp[..., 0, 0, 9] = 1\n",
    "print(inp)\n",
    "TotalCALayer()(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91114d4-c39b-410b-892e-59fab445f898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ca = TotalCALayer(\n",
    "        birth=  (0, 0, 0, 1, 0, 0, 0, 0, 0),\n",
    "        survive=(0, 0, 1, 1, 0, 0, 0, 0, 0),\n",
    "        iterations=5,\n",
    "    )\n",
    "    state = torch.rand(8, 3, 32, 32)\n",
    "    states = []\n",
    "    for i in range(20):\n",
    "        for s in state:\n",
    "            states.append(s)\n",
    "        \n",
    "        state = ca(state)\n",
    "        \n",
    "VF.to_pil_image(resize(make_grid(states), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea0b64-c19c-4783-b8c2-d6f60aded496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
