{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4f146-9723-4c4d-bcf2-ad32c654a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f32ee-a03b-4814-8bda-3d8bd21ecc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = VF.to_tensor(PIL.Image.open(\n",
    "    \"/home/bergi/Pictures/Unternehmenskleidung.jpg\"\n",
    ").convert(\"RGB\"))\n",
    "image = VF.crop(image, 110, 140, 64, 64)\n",
    "print(image.shape)\n",
    "VF.to_pil_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f186037-7e3f-4ab0-bf08-dc30d211272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 3, 3)\n",
    "y = conv(image)\n",
    "print(y.shape)\n",
    "display(VF.to_pil_image(y.clamp(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62246d2-26b4-4ea1-9d76-247b0357a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 3, 8, padding=3, stride=16)\n",
    "y = conv(image)\n",
    "print(y.shape)\n",
    "display(VF.to_pil_image(y.clamp(0, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa926f-2fb1-4f54-802c-f39d04e0b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchAE(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            shape: Tuple[int, int, int],\n",
    "            patch_size: int,\n",
    "            code_size: int,\n",
    "            kernel_size: Optional[int] = None,\n",
    "            channels: Optional[int] = None,\n",
    "            num_residuals: int = 0,\n",
    "            batch_norm: bool = False,\n",
    "            activation: Union[None, str, Callable] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if channels is None:\n",
    "            channels = shape[0] * patch_size ** 2\n",
    "        if kernel_size is None:\n",
    "            kernel_size = patch_size\n",
    "        padding = int(math.floor(kernel_size / 2))\n",
    "\n",
    "        self.encoder = nn.Sequential()\n",
    "        self.encoder.append(\n",
    "            nn.Conv2d(shape[0], channels, kernel_size, padding=padding, stride=patch_size)\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img = torch.zeros(1, *shape)\n",
    "            encoded_shape = self.encoder(img).shape[1:]\n",
    "        \n",
    "        if batch_norm: \n",
    "            self.encoder.append(nn.BatchNorm2d(encoded_shape[0]))\n",
    "        \n",
    "        if activation is not None:\n",
    "            self.encoder.append(activation_to_module(activation))\n",
    "\n",
    "        for i in range(num_residuals):\n",
    "            self.encoder.append(ResidualAdd(nn.Conv2d(encoded_shape[0], encoded_shape[0], 3, padding=1)))\n",
    "            if activation is not None:\n",
    "                self.encoder.append(activation_to_module(activation))        \n",
    "\n",
    "        self.encoder.append(nn.Flatten(-3))\n",
    "        self.encoder.append(nn.Linear(math.prod(encoded_shape), code_size))\n",
    "\n",
    "        self.decoder = nn.Sequential()\n",
    "        self.decoder.append(nn.Linear(code_size, math.prod(encoded_shape), code_size))\n",
    "        if activation is not None:\n",
    "            self.decoder.append(activation_to_module(activation))        \n",
    "        self.decoder.append(Reshape(encoded_shape))\n",
    "\n",
    "        for i in range(num_residuals):\n",
    "            self.decoder.append(ResidualAdd(nn.Conv2d(encoded_shape[0], encoded_shape[0], 3, padding=1)))\n",
    "            if activation is not None:\n",
    "                self.decoder.append(activation_to_module(activation))        \n",
    "        \n",
    "        self.decoder.append(\n",
    "            nn.ConvTranspose2d(channels, shape[0], kernel_size, padding=padding, stride=patch_size)\n",
    "        )\n",
    "        self.decoder.append(nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "ae = PatchAE(\n",
    "    shape=image.shape,\n",
    "    patch_size=16,\n",
    "    code_size=128,\n",
    "    kernel_size=16,\n",
    "    activation=\"gelu\",\n",
    "    num_residuals=2,\n",
    ")\n",
    "#display(ae)\n",
    "print(f\"params: {num_module_parameters(ae):,}\")\n",
    "\n",
    "c = ae.encoder(image.unsqueeze(0))\n",
    "y = ae.decoder(c).squeeze(0)\n",
    "print(f\"{image.shape} -> {c.shape} -> {y.shape}, RATIO: {math.prod(image.shape) / math.prod(c.shape)}\")\n",
    "\n",
    "display(VF.to_pil_image(y[:3].clamp(0, 1)))\n",
    "\n",
    "display(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c26b04-a8c6-4a3c-8dcc-4c47d86867ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f856c31-5d2b-4207-8a16-291c2a356ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54181aa-bed4-41a7-9b6f-13c2df1e82ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d268ab4-93d5-4413-bd75-237600d2bf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0598a-abb1-4b05-b878-28a76cdce3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConv(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_in: int,\n",
    "            num_out: int,\n",
    "            kernel_size: int = 3,\n",
    "            activation: Union[None, str, Callable] = None,\n",
    "            conv_class: Type[nn.Module] = nn.Conv2d,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        padding = int(math.floor(kernel_size / 2))\n",
    "        self.conv = conv_class(num_in, num_out, kernel_size, padding=padding)\n",
    "        self.residual = None\n",
    "        if num_in != num_out:\n",
    "            self.residual = conv_class(num_in, num_out, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        r = x\n",
    "        if self.residual is not None:\n",
    "            r = self.residual(r)\n",
    "        y = self.conv(x)\n",
    "        return y + r\n",
    "\n",
    "m = ResConv(10, 11)\n",
    "print(f\"params: {num_module_parameters(m):,}\")\n",
    "print(m(torch.ones(1, 10, 16, 16)).shape)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b90caff-1a27-4106-936a-5489a7a29d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d(3, 8, 1).weight.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
