{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e720f9-1f84-4c8e-91ea-1383ae4d2798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b185e-1bea-4db1-8f68-298369aaec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagonalEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels_in: int,\n",
    "            channels_out: int,\n",
    "            diagonal: bool = True,\n",
    "            symmetric: bool = True,\n",
    "            fft: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Wrapper around torch.nn.Embedding\n",
    "\n",
    "        :param channels_in: int, vocabulary size\n",
    "        :param channels_out: int, internal representation size\n",
    "        :param diagonal: bool, if True, the embedding weights are initialized with\n",
    "            a diagonal matrix, e.g. if channels_in==channels_out, the representation\n",
    "            matches the input\n",
    "        :param symmetric: bool, if True, the embedding weights and readout weights are shared.\n",
    "            If False, the readout has it's own set of weights.\n",
    "        :param fft: bool, If True, the representation is the concatenation of the\n",
    "            real and imaginary FFT transform, which doubles the `channels_out`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._diagonal = diagonal\n",
    "        self._symmetric = symmetric\n",
    "        self._fft = fft\n",
    "\n",
    "        self.input = nn.Embedding(channels_in, channels_out)\n",
    "        with torch.no_grad():\n",
    "            if diagonal:\n",
    "                self.input.weight[:] = create_diagonal_matrix(self.input.weight.shape)\n",
    "            if fft:\n",
    "                self.input.weight[:] = F.softmax(self.input.weight, dim=-1)\n",
    "\n",
    "        if not symmetric:\n",
    "            self.output = nn.Linear(channels_out, channels_in)\n",
    "        #else:\n",
    "        #    self.output = nn.Linear(channels_out, channels_in, bias=False)\n",
    "        #    self.output.weight = self.input.weight\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"diagonal={self._diagonal}, symmetric={self._symmetric}, fft={self._fft}\"\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x: torch.Tensor,\n",
    "            reverse: bool = False,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Converts token indices to representation or representation to token class logits\n",
    "\n",
    "        :param x: torch.Tensor,\n",
    "            if reverse==False, the token indices of shape [B, L] (where L is sequence length),\n",
    "            if reverse==True and fft==False, the representation of shape [B, C, L]\n",
    "            if reverse==True and fft==True, the representation of shape [B, C*2, L]\n",
    "        :param reverse: bool, if True, reverses the embedding\n",
    "        :return: torch.Tensor,\n",
    "            if reverse==False and fft==False, the representation of shape [B, C, L]\n",
    "            if reverse==False and fft==True, the representation of shape [B, C*2, L]\n",
    "            if reverse==True, the token class logits of shape [B, L, V] (where V is vocab_size)\n",
    "        \"\"\"\n",
    "        if not reverse:\n",
    "\n",
    "            outp = self.input(x).permute(0, 2, 1)\n",
    "            if self._fft:\n",
    "                outp = torch.fft.fft(outp, dim=-2)\n",
    "                outp = torch.concat([outp.real, outp.imag], dim=-2)\n",
    "            return outp\n",
    "            \n",
    "        else:\n",
    "            if self._fft:\n",
    "                x = torch.complex(*torch.split(x, x.shape[-2] // 2, dim=-2))\n",
    "                x = torch.fft.ifft(x, dim=-2).real\n",
    "                \n",
    "            if self._symmetric:\n",
    "                return (self.input.weight @ x).permute(0, 2, 1).contiguous()\n",
    "            else:\n",
    "                return self.output(x.permute(0, 2, 1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb = DiagonalEmbedding(256, 512, fft=True, diagonal=True, symmetric=False)\n",
    "    #inp = torch.randint(0, 255, (1, 10))\n",
    "    inp = torch.LongTensor([[0, 1, 2, 3, 2, 1, 201]])\n",
    "    outp = emb(inp)\n",
    "    inp2 = emb(outp, reverse=True)\n",
    "    print(outp.shape, outp.min(), outp.max())\n",
    "    display((inp, inp2.argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b8e73-856c-4616-909b-498e7323106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inp = torch.LongTensor([[0, 1, 2, 4, 16, 201]])\n",
    "    x = emb(inp)\n",
    "    x.shape\n",
    "    \n",
    "    x2 = torch.fft.fft(x, dim=-2)\n",
    "    xc = torch.cat([x2.real, x2.imag], dim=-2)\n",
    "\n",
    "    display(px.imshow(xc[0].T, height=400, aspect=False))\n",
    "    \n",
    "    #x2 = torch.cat([x2.real, x2.imag], dim=-2)\n",
    "    #print(x2.shape, x2.min(), x2.max())\n",
    "    \n",
    "    x2 = torch.complex(*torch.split(xc, xc.shape[-2] // 2, dim=-2))\n",
    "    x3 = torch.fft.ifft(x2, dim=-2)\n",
    "    display(px.imshow(x3.real[0].T, height=250, aspect=False))\n",
    "    display(px.imshow(x3.imag[0].T, height=250, aspect=False))\n",
    "    outp = emb(x3.real, reverse=True).argmax(-1)\n",
    "    display(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577841de-5bf7-416a-b847-ff5b42399055",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf = torch.fft.rfft(x, dim=-2).imag\n",
    "print(xf.shape)\n",
    "#xc = torch.cat([x2.real, x2.imag], dim=-2)\n",
    "\n",
    "display(px.imshow(xf[0].T, height=400, aspect=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae1b347-0e96-4f32-a78d-200de674dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg11\n",
    "vgg11()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
