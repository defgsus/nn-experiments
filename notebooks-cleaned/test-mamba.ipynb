{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d24ef-8df1-46c4-ac19-e39fbe54b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953d786-7dc5-45b1-a466-ddd276e39746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.mamba.mamba import Mamba, ModelArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba779f85-41e3-4979-b4ed-19d5128469f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mamba(ModelArgs(d_model=100, n_layer=4, vocab_size=256))\n",
    "print(f\"param: {num_module_parameters(m):,}\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31bd21d-80db-4289-9a64-351089bc695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m(torch.ones(1, 100, dtype=torch.int64)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc5b1c-c918-4b34-93f6-5c55197d4f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62d369-fed1-43c6-9da0-85647b0d0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_mask(texts: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :param text: tensor of shape [B, L]\n",
    "    :return: masked tensor\n",
    "    \"\"\"\n",
    "    B, L = texts.shape\n",
    "    size = max(1, int(L*.3)) #int(self._mask_ratio * L))\n",
    "    indices = torch.randint(0, L - size, (B, 1)).to(texts.device)\n",
    "    coords = torch.arange(0, L).unsqueeze(0).repeat(B, 1)\n",
    "    mask = (coords < indices) | (coords >= indices + size) \n",
    "    return texts * mask\n",
    "    \n",
    "texts = torch.randint(0, 10, (3, 10))\n",
    "print(texts)\n",
    "masked = _apply_mask(texts)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f4a018-069d-42f6-b45c-7d817c2569fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encoded_to_logits(texts: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :param texts: tensor of [B, L]\n",
    "    :return: tensor of [B, L, 256]\n",
    "    \"\"\"\n",
    "    B, L = texts.shape\n",
    "    logits = torch.zeros((B, L, 10)).to(texts)\n",
    "    logits.scatter_(-1, texts.unsqueeze(-1).to(torch.int64), 1)\n",
    "    return logits\n",
    "\n",
    "print(texts)\n",
    "_encoded_to_logits(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3adcb-f7e3-45c4-a6d8-1aa81fd2266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSegmentIterableDataset(BaseIterableDataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            *text: str,\n",
    "            size: int,\n",
    "            stride: Union[None, int, str] = None,  # int or \"random\"\n",
    "            encode: Optional[str] = None,\n",
    "    ):\n",
    "        self._texts = text\n",
    "        self._size = size\n",
    "        self._stride = stride\n",
    "        self._encode = encode\n",
    "        \n",
    "    def __iter__(self):\n",
    "        stride = self._stride\n",
    "        if stride is None:\n",
    "            stride = self._size\n",
    "            \n",
    "        for text in self._texts:\n",
    "            pos = 0\n",
    "            while pos < len(text):\n",
    "                segment = text[pos: pos + self._size]\n",
    "\n",
    "                if stride == \"random\":\n",
    "                    pos += random.randrange(self._size)\n",
    "                elif isinstance(stride, int):\n",
    "                    pos += stride\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"Invalid stride '{self._stride}'\")\n",
    "                \n",
    "                if self._encode is None:\n",
    "                    yield segment\n",
    "                elif self._encode == \"bytes\":\n",
    "                    yield torch.tensor(list(segment.encode()), dtype=torch.uint8)\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"Invalid encode '{self._encode}'\")\n",
    "\n",
    "ds = TextSegmentIterableDataset(\n",
    "    Path(\"/home/bergi/text/der_bandwurm.txt\").read_text(),\n",
    "    size=10, stride=1,\n",
    ").shuffle(1000)\n",
    "print(len(list(ds)))\n",
    "for i, seg in enumerate(ds):\n",
    "    print(f\"{i:3}:\", repr(seg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a59db2-0888-4c0d-9cd9-1f4a981f266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(DataLoader(ds, batch_size=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7130bf2e-4e27-4a67-bacc-3a107ce7aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import glob\n",
    "\n",
    "class FilenameDataset(BaseDataset):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            root: Union[str, Path],\n",
    "            include: Union[None, str, Iterable[str]] = None,\n",
    "            exclude: Union[None, str, Iterable[str]] = None,\n",
    "            recursive: bool = False,\n",
    "            max_files: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.root = Path(root).expanduser()\n",
    "        if include is None:\n",
    "            self.include = None\n",
    "        elif isinstance(include, str):\n",
    "            self.include = [include]\n",
    "        else:\n",
    "            self.include = list(include)\n",
    "        if exclude is None:\n",
    "            self.exclude = None\n",
    "        elif isinstance(exclude, str):\n",
    "            self.exclude = [exclude]\n",
    "        else:\n",
    "            self.exclude = list(exclude)\n",
    "            \n",
    "        self.recursive = recursive\n",
    "        self.max_files = max_files\n",
    "        self._filenames = None\n",
    "\n",
    "    def __len__(self):\n",
    "        self._get_filenames()\n",
    "        return len(self._filenames)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self._get_filenames()\n",
    "        return self._filenames[i]\n",
    "\n",
    "    def _is_valid(self, filename: str) -> bool:\n",
    "        if self.include:\n",
    "            for pattern in self.include:\n",
    "                if not fnmatch.fnmatch(filename, pattern):\n",
    "                    return False\n",
    "            \n",
    "        if self.exclude:\n",
    "            for pattern in self.exclude:\n",
    "                if fnmatch.fnmatch(filename, pattern):\n",
    "                    return False\n",
    "        return True\n",
    "        \n",
    "    def _get_filenames(self):\n",
    "        if self._filenames is None:\n",
    "\n",
    "            if self.root.is_file():\n",
    "                self._filenames = [str(self.root)]\n",
    "\n",
    "            else:\n",
    "                glob_path = self.root\n",
    "                if self.recursive:\n",
    "                    glob_path /= \"**/*\"\n",
    "                else:\n",
    "                    glob_path /= \"*\"\n",
    "\n",
    "                self._filenames = []\n",
    "                for filename in glob.glob(str(glob_path), recursive=self.recursive):\n",
    "                    if self._is_valid(filename):\n",
    "                        self._filenames.append(filename)\n",
    "                        if self.max_files and len(self._filenames) >= self.max_files:\n",
    "                            break\n",
    "\n",
    "                self._filenames.sort()\n",
    "\n",
    "dsf = FilenameDataset(\n",
    "    \"../../billion-bubbles/\",\n",
    "    include=\"*.py\",\n",
    "    exclude=\"*/env/*\",\n",
    "    recursive=True,\n",
    ")\n",
    "for f in dsf:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71da43-aded-4208-aafb-ae52d72f4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileTextSegmentIterableDataset(BaseIterableDataset):\n",
    "    \"\"\"\n",
    "    Base dataset must provide filenames\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: Union[Dataset, IterableDataset],\n",
    "            size: int,\n",
    "            stride: Union[None, int, str] = None,  # int or \"random\"\n",
    "            encode: Optional[str] = None,\n",
    "    ):\n",
    "        self._dataset = dataset\n",
    "        self._size = size\n",
    "        self._stride = stride\n",
    "        self._encode = encode\n",
    "        \n",
    "    def __iter__(self):\n",
    "        stride = self._stride\n",
    "        if stride is None:\n",
    "            stride = self._size\n",
    "\n",
    "        for file in self._dataset:\n",
    "            try:\n",
    "                text = Path(file).read_text()\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "\n",
    "            pos = 0\n",
    "            while pos < len(text):\n",
    "                segment = text[pos: pos + self._size]\n",
    "\n",
    "                if stride == \"random\":\n",
    "                    pos += random.randrange(self._size)\n",
    "                elif isinstance(stride, int):\n",
    "                    pos += stride\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"Invalid stride '{self._stride}'\")\n",
    "                \n",
    "                if self._encode is None:\n",
    "                    yield segment\n",
    "                elif self._encode == \"bytes\":\n",
    "                    yield torch.tensor(list(segment.encode()), dtype=torch.uint8)\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"Invalid encode '{self._encode}'\")\n",
    "\n",
    "ds = FileTextSegmentIterableDataset(\n",
    "    FilenameDataset(\n",
    "        #\"~/prog/python/github\",\n",
    "        \"/home/bergi/prog/python/botgard/BotGard3/\",\n",
    "        include=\"*.py\",\n",
    "        exclude=[\"*/env/*\", \"*/node_modules/*\", \"*/site-packages/*\"],\n",
    "        recursive=True,\n",
    "    ),\n",
    "    size=50, #stride=1,\n",
    ")#.shuffle(1000)\n",
    "\n",
    "print(len(list(ds)))\n",
    "for i, seg in zip(range(100), ds):\n",
    "    print(f\"{i:3}:\", repr(seg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb110b8-21e1-4f84-ba48-01d82c2ad921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextMathFormula(IterableDataset):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            size: int,\n",
    "            num_operands: int = 1,\n",
    "            max_number: int = 10,\n",
    "            operators: Iterable[str] = (\"+\",),\n",
    "            sep: str = \" \",\n",
    "            seed: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._size = size\n",
    "        self._num_operands = num_operands\n",
    "        self._max_number = max_number\n",
    "        self._operators = list(operators)\n",
    "        self._sep = sep\n",
    "        self._seed = seed\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return self._size\n",
    "\n",
    "    def __iter__(self) -> Generator[str, None, None]:\n",
    "        if self._seed is None:\n",
    "            rng = random\n",
    "        else:\n",
    "            rng = random.Random(self._seed)\n",
    "        \n",
    "        for i in range(self._size):\n",
    "            seq = [str(rng.randint(0, self._max_number))]\n",
    "            for j in range(self._num_operands):\n",
    "                seq.append(\n",
    "                    rng.choice(self._operators)\n",
    "                )\n",
    "                seq.append(\n",
    "                    str(rng.randint(0, self._max_number))\n",
    "                )\n",
    "            \n",
    "            expression = self._sep.join(seq)\n",
    "            result = str(eval(expression))\n",
    "            yield self._sep.join([expression, \"=\", result])\n",
    "\n",
    "ds = TextMathFormula(20, sep=\" \")\n",
    "for i, seg in zip(range(100), ds):\n",
    "    print(f\"{i:3}:\", repr(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe27bb7-bb15-4918-b733-2ebed501cc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93648e-97f7-48f5-84c6-42f215af17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from src.util.gharchive import GHArchive\n",
    "#gha = GHArchive(verbose=True)\n",
    "#for commit in gha.iter_commits(datetime.date(2024, 12, 13), hours=16):\n",
    "#    print(commit[\"message\"])\n",
    "\n",
    "class TextGithubEventIterableDataset(BaseIterableDataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dt=datetime.datetime(2024, 12, 13, 16),\n",
    "            type: Union[str, Iterable[str]] = (\"commit\", \"comment\"),\n",
    "            min_text_length: Optional[int] = None,\n",
    "            fixed_width: Optional[int] = None,\n",
    "            stride: Union[None, int, str] = None,\n",
    "            verbose: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._dt = dt\n",
    "        self._gha = GHArchive(verbose=verbose)\n",
    "        self._type = [type] if isinstance(type, str) else set(type)\n",
    "        self._min_text_length = min_text_length\n",
    "        self._fixed_width = fixed_width\n",
    "        self._stride = stride\n",
    "\n",
    "    def __iter__(self) -> Generator[str, None, None]:\n",
    "        for text in self._iter_texts():\n",
    "            if self._min_text_length and len(text) < self._min_text_length:\n",
    "                continue\n",
    "\n",
    "            if not self._fixed_width:\n",
    "                yield text\n",
    "            else:\n",
    "                while text:\n",
    "                    if self._min_text_length and len(text) < self._min_text_length:\n",
    "                        break\n",
    "\n",
    "                    yielded_text = text\n",
    "                    if self._fixed_width:\n",
    "                        yielded_text = yielded_text.ljust(self._fixed_width,)\n",
    "\n",
    "                    yield yielded_text[:self._fixed_width]\n",
    "\n",
    "                    stride = self._stride\n",
    "                    if stride is None:\n",
    "                        stride = self._fixed_width\n",
    "                    elif stride == \"random\":\n",
    "                        stride = random.randrange(1, self._fixed_width)\n",
    "\n",
    "                    text = text[stride:]\n",
    "\n",
    "    def _iter_texts(self):\n",
    "        #shown = set()\n",
    "        for event in self._gha.iter_events(\n",
    "                day=self._dt.date(),\n",
    "                hours=self._dt.hour,\n",
    "        ):\n",
    "            #if event[\"type\"] not in shown:\n",
    "            #    json.dumps(event, indent=2)\n",
    "            #    shown.add(event[\"type\"])\n",
    "\n",
    "            if event[\"type\"] == \"PushEvent\":\n",
    "                if \"commit\" in self._type:\n",
    "                    if event.get(\"payload\") and event[\"payload\"].get(\"commits\"):\n",
    "                        for commit in event[\"payload\"][\"commits\"]:\n",
    "                            if commit.get(\"message\"):\n",
    "                                pass#yield commit[\"message\"]\n",
    "\n",
    "            elif event[\"type\"] == \"IssueCommentEvent\":\n",
    "                if \"comment\" in self._type:\n",
    "                    if event.get(\"payload\") and event[\"payload\"].get(\"comment\") and event[\"payload\"][\"comment\"].get(\"body\"):\n",
    "                        yield event[\"payload\"][\"comment\"][\"body\"]\n",
    "                #print(json.dumps(event,indent=2))\n",
    "            \n",
    "ds = TextGithubEventIterableDataset(\n",
    "    fixed_width=20,\n",
    "    stride=\"random\",\n",
    ")\n",
    "#print(len(list(tqdm(ds))))\n",
    "for i, seg in zip(range(100), ds):\n",
    "    print(f\"{i:3}:\", repr(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36d6dd-a74f-47a4-b189-075493b65f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b56999-99dc-458b-a412-1ccad3498a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81381668-fad0-43be-b844-e09a7895c7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9ddd7-55e3-4ffe-8902-eae3886c54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Union, Tuple\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as VF\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "\n",
    "\n",
    "class FontSquares:\n",
    "    def __init__(\n",
    "            self,\n",
    "            file: Union[str, Path] = Path(\"~/.local/share/fonts/unscii-8.ttf\").expanduser(),\n",
    "            shape: Tuple[int, int, int] = (1, 8, 8),\n",
    "            center: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generator for monospaced images from text\n",
    "\n",
    "        :param file: file to use as font\n",
    "        :param shape: tuple of (C, H, W), square channels & size, C must be 1 or 3\n",
    "        :param center: bool, center all fonts into their squares\n",
    "        \"\"\"\n",
    "        assert len(shape) == 3, f\"Expected [C, H, W] shape, got {shape}\"\n",
    "        assert shape[0] in (1, 3), f\"Expected 1 or 3 channels, got {shape}\"\n",
    "\n",
    "        self.shape = shape\n",
    "        self.center = center\n",
    "        self.font = PIL.ImageFont.truetype(\n",
    "            str(file),\n",
    "            size=min(self.shape[-2:]),\n",
    "        )\n",
    "        self._font_map = {}\n",
    "\n",
    "    def __call__(self, ch: Union[str, int], dim: int = 2) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert text to image\n",
    "\n",
    "        :param ch: int (ordinal) or str (single character or text)\n",
    "        :param dim: int, dimension for concatenation/stacking\n",
    "        :return: Tensor of shape\n",
    "            [C, H, W] if single character\n",
    "            [C, H, W * N] if dim == 2\n",
    "            [C, H * N, N] if dim == 1\n",
    "            [C * N, H, W] if dim == 0\n",
    "            [N, C, H, W] if dim == -1\n",
    "        \"\"\"\n",
    "        if isinstance(ch, str):\n",
    "            if len(ch) == 0:\n",
    "                ch = 32\n",
    "            elif len(ch) == 1:\n",
    "                ch = ord(ch)\n",
    "            else:\n",
    "                squares = [self(c) for c in ch]\n",
    "                if dim == -1:\n",
    "                    return torch.stack(squares)\n",
    "                else:\n",
    "                    return torch.cat(squares, dim)\n",
    "\n",
    "        ch = max(ch, 32) if ch != 0 else 0\n",
    "\n",
    "        if ch not in self._font_map:\n",
    "            if ch == 0:\n",
    "                self._font_map[ch] = torch.ones(self.shape)\n",
    "            else:\n",
    "                image = PIL.Image.new(\n",
    "                    \"RGB\" if self.shape[0] == 3 else \"L\",\n",
    "                    (self.shape[-1], self.shape[-2]),\n",
    "                )\n",
    "                draw = PIL.ImageDraw.ImageDraw(image)\n",
    "    \n",
    "                if self.center:\n",
    "                    L, T, R, B = draw.textbbox((0, 0), chr(ch), font=self.font)\n",
    "                    xy = (\n",
    "                        (self.shape[-1] - (R - L)) // 2,\n",
    "                        -T + (self.shape[-2] - (B - T)) // 2,\n",
    "                    )\n",
    "                else:\n",
    "                    xy = (0, 0)\n",
    "    \n",
    "                draw.text(\n",
    "                    xy,\n",
    "                    chr(ch),\n",
    "                    font=self.font,\n",
    "                    fill=(255,) * self.shape[0],\n",
    "                )\n",
    "                self._font_map[ch] = VF.to_tensor(image)\n",
    "\n",
    "        return self._font_map[ch]\n",
    "\n",
    "    def reverse(self, image: torch.Tensor, dim: int = 2) -> str:\n",
    "        \"\"\"\n",
    "        Convert image back to text by best-match.\n",
    "\n",
    "        :param image: Tensor of shape\n",
    "            [C, H, W * N] if dim == 2\n",
    "            [C, H * N, N] if dim == 1\n",
    "            [C * N, H, W] if dim == 0\n",
    "            [N, C, H, W] if dim == -1\n",
    "        :param dim: int, dimension where image is concatenated/stacked\n",
    "        :return: str\n",
    "        \"\"\"\n",
    "        if dim == -1:\n",
    "            assert image.ndim == 4, f\"Expected 4 dimensions, got {image.shape}\"\n",
    "            assert image.shape[1:] == self.shape, f\"Expected square shape of {self.shape}, got {image.shape}\"\n",
    "            squares = image\n",
    "        elif dim == 0:\n",
    "            assert image.ndim == 3, f\"Expected 3 dimensions, got {image.shape}\"\n",
    "            assert image.shape[0] % self.shape[0] == 0, f\"Expected channels divisible by {self.shape[0]}, got {image.shape}\"\n",
    "            assert image.shape[1] == self.shape[1], f\"Expected height of {self.shape[1]}, got {image.shape}\"\n",
    "            assert image.shape[2] == self.shape[2], f\"Expected width of {self.shape[2]}, got {image.shape}\"\n",
    "        elif dim == 1:\n",
    "            assert image.ndim == 3, f\"Expected 3 dimensions, got {image.shape}\"\n",
    "            assert image.shape[0] == self.shape[0], f\"Expected {self.shape[0]} channels, got {image.shape}\"\n",
    "            assert image.shape[1] % self.shape[1] == 0, f\"Expected height divisible by {self.shape[1]}, got {image.shape}\"\n",
    "            assert image.shape[2] == self.shape[2], f\"Expected width of {self.shape[2]}, got {image.shape}\"\n",
    "        elif dim == 2:\n",
    "            assert image.ndim == 3, f\"Expected 3 dimensions, got {image.shape}\"\n",
    "            assert image.shape[0] == self.shape[0], f\"Expected {self.shape[0]} channels, got {image.shape}\"\n",
    "            assert image.shape[1] == self.shape[1], f\"Expected height of {self.shape[1]}, got {image.shape}\"\n",
    "            assert image.shape[2] % self.shape[2] == 0, f\"Expected width divisible by {self.shape[2]}, got {image.shape}\"\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Expected dim in -1, 0, 1 or 2, got {dim}\")\n",
    "        \n",
    "        if dim >= 0:\n",
    "            squares = image.split(self.shape[dim], dim)\n",
    "            \n",
    "        all_ords = list(self._font_map)\n",
    "        all_fonts = torch.cat([self(o).unsqueeze(0) for o in all_ords])\n",
    "        output = []\n",
    "        for square in squares:\n",
    "            diffs = (all_fonts - square).abs().flatten(1).mean(1)\n",
    "            best = all_ords[diffs.argmin()]\n",
    "            # print(chr(best), best)\n",
    "            output.append(chr(best))\n",
    "        return \"\".join(output)\n",
    "\n",
    "f = FontSquares(\n",
    "    #\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\",\n",
    "    #\"/usr/share/fonts/truetype/freefont/FreeSansBold.ttf\",\n",
    "    #center=True,\n",
    ")\n",
    "display(VF.to_pil_image(resize(make_grid([\n",
    "    f(i) for i in range(32, 256)\n",
    "], nrow=32, pad_value=.3), 3)))\n",
    "display(VF.to_pil_image(resize(f(\"hello world\\0\"), 3)))\n",
    "#print(f.reverse(f(\"hello world\")))\n",
    "#f(\"hello\", dim=0).shape\n",
    "print(f.reverse(f(\"hello world\", dim=0), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc632b-4079-45ac-8cb7-fa48a260d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.rand(3, 4, 4)\n",
    "torch.stack([v, v]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b99034-4843-40da-b93b-d6f44e953562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedbf64b-0b04-4dba-91b1-ff9bc0924331",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv1d(2, 3, 5, padding=8, dilation=4)(\n",
    "    torch.ones(1, 2, 100)\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831b2b6-1f86-4bcc-bb99-a30fec7d0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 52\n",
    "for ks in [3, 5, 7, 9]:\n",
    "    for pad in range(1, 12):\n",
    "        for dil in range(1, 12):\n",
    "            shape = nn.Conv1d(2, 3, ks, padding=pad, dilation=dil)(\n",
    "                torch.ones(1, 2, size)\n",
    "            ).shape\n",
    "            if shape[-1] == size:\n",
    "                print(f\"ks={ks:2}, pad={pad:2}, dil={dil:2}, shape={shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81863fc8-cf1f-4dc2-96f1-b894606d20a2",
   "metadata": {},
   "source": [
    "# display convolution receptive field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c7460-4a83-424a-b8c8-5cab314fd15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_conv(size: int, kernel_size: int, dilation: Union[int, Iterable[int]], layers: int = 6, zoom: int = 5):\n",
    "    \n",
    "    inp = torch.zeros(1, 3, size)\n",
    "    inp[..., size//2] = 1\n",
    "    \n",
    "    grid = []\n",
    "    def add_pic(state):\n",
    "        img = state.permute(1, 0, 2)  # take the one batch dimension as height\n",
    "        #img = (img.abs() / img.max()).pow(.3)\n",
    "        grid.append(resize(img.clamp(0, 1), zoom))\n",
    "        \n",
    "    add_pic(inp)\n",
    "    for i, dil in enumerate(param_make_list(dilation, layers, \"dilation\")):\n",
    "        padding = int(math.floor(kernel_size / 2)) * dil\n",
    "        conv = nn.Conv1d(3, 3, kernel_size, padding=padding, dilation=dil)\n",
    "        conv.weight[:] = .5 * torch.rand(conv.weight.shape, generator=torch.Generator().manual_seed(23))\n",
    "        conv.bias[:] = 0.\n",
    "        inp = conv(inp)\n",
    "        #inp = F.gelu(inp)\n",
    "        add_pic(inp)\n",
    "        \n",
    "    display(VF.to_pil_image(make_grid(grid, nrow=1, pad_value=.3)))\n",
    "\n",
    "plot_conv(\n",
    "    100, 9, \n",
    "    #dilation=2, \n",
    "    #dilation=[2, 3, 4, 5, 6, 1],\n",
    "    #dilation=[2, 3, 2, 3, 2, 3],\n",
    "    dilation=[6, 6, 6, 1, 1, 1],\n",
    "    layers=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a223c-235b-467f-ac32-71bfd9c0f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "400*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5f40a-8610-40d2-b5e9-43a3b854ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.generative.text_gen import TextQABaseIterableDataset\n",
    "\n",
    "class TextQAProgramIterableDataset(TextQABaseIterableDataset):\n",
    "    \"\"\"\n",
    "    Yields things like\n",
    "\n",
    "        ABCD, 0>1 = BACD\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            count: int,\n",
    "            num_items: Union[int, Tuple[int, int]] = 4,\n",
    "            num_operations: Union[int, Tuple[int, int]] = 3,\n",
    "            seed: Optional[int] = None,\n",
    "            exclude: Optional[Iterable[str]] = None,\n",
    "            with_masked: bool = False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            count=count, seed=seed, exclude=exclude, with_masked=with_masked,\n",
    "            fixed_answer_width=max(num_items) if isinstance(num_items, (tuple, list)) else num_items,\n",
    "        )\n",
    "        self._count = count\n",
    "        self._num_items = num_items\n",
    "        self._num_operations = num_operations\n",
    "        self._seed = seed\n",
    "        self._exclude = None if exclude is None else set(exclude)\n",
    "        self._with_masked = with_masked\n",
    "\n",
    "    def iter_question_answer(self, rng: random.Random) -> Generator[Tuple[str, str], None, None]:\n",
    "        while True:\n",
    "\n",
    "            num_items = self._num_items\n",
    "            if isinstance(num_items, (tuple, list)):\n",
    "                num_items = rng.randint(*num_items)\n",
    "\n",
    "            num_ops = self._num_operations\n",
    "            if isinstance(num_ops, (tuple, list)):\n",
    "                num_ops = rng.randint(*num_ops)\n",
    "\n",
    "            cells = [chr(ord('A') + i) for i in range(num_items)]\n",
    "            rng.shuffle(cells)\n",
    "            program_input = cells.copy()\n",
    "\n",
    "            stack = []\n",
    "            ops = []\n",
    "            while cells and len(ops) < num_ops:\n",
    "                op = rng.choices(\n",
    "                    [\">\", \"-\", \"+\"],\n",
    "                    weights=[1, 1/3, 1/3],\n",
    "                )[0]\n",
    "                if op == \"-\":\n",
    "                    idx = rng.randrange(len(cells))\n",
    "                    stack.append(cells.pop(idx))\n",
    "                    ops.append(f\"{op}{idx+1}\")\n",
    "                elif op == \"+\" and len(stack):\n",
    "                    idx = rng.randrange(len(cells))\n",
    "                    cells.insert(idx, stack.pop())\n",
    "                    ops.append(f\"{op}{idx+1}\")\n",
    "                elif op == \">\" and len(cells) >= 2:\n",
    "                    indices = list(range(len(cells)))\n",
    "                    rng.shuffle(indices)\n",
    "                    idx1, idx2 = indices[:2]\n",
    "                    cells[idx1], cells[idx2] = cells[idx2], cells[idx1]\n",
    "                    ops.append(f\"{idx1+1}{op}{idx2+1}\")\n",
    "\n",
    "            question = (\n",
    "                    \"\".join(program_input) + \": \"\n",
    "                    + \", \".join(ops)\n",
    "            )\n",
    "            answer = \"\".join(cells)\n",
    "            yield question, answer\n",
    "\n",
    "ds = TextQAProgramIterableDataset(\n",
    "    1000,\n",
    "    num_items=(2, 5),\n",
    "    num_operations=(1, 5),\n",
    ")\n",
    "\n",
    "for i, seg in zip(range(100), ds):\n",
    "    print(f\"{i:3}:\", repr(seg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
