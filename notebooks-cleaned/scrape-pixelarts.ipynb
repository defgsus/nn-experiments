{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab41df-0320-44bf-a154-38c5811047b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9b239-823d-4782-b35e-f11b9b8b8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"~/prog/data/pixilart\").expanduser()\n",
    "os.makedirs(PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadbc081-28b2-4b43-90b8-bf9fde2046da",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/113.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b956319-1d2f-40ee-b934-295d347c608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(index: int):\n",
    "    url = f\"https://www.pixilart.com/api/w/gallery/{index}/0/highlighted?user=true&liked=true\"\n",
    "    response = session.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(response.text)\n",
    "\n",
    "    for art in response.json()[\"art\"]:\n",
    "        filename = PATH / f'{art[\"unqid\"]}.json'\n",
    "        filename.write_text(json.dumps(art, indent=2))\n",
    "        \n",
    "        image_url = art[\"full_image_url\"]\n",
    "        filename = PATH / image_url.rsplit(\"/\", 1)[-1]\n",
    "        if not filename.exists():        \n",
    "            print(image_url)\n",
    "            response = session.get(image_url)\n",
    "            filename.write_bytes(response.content)\n",
    "            time.sleep(1)\n",
    "        \n",
    "# yeah, well, it does not work, thanks to cloudflare i guess         \n",
    "#scrape_page(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c98ae5-fe62-4b6d-a000-30cef1c56136",
   "metadata": {},
   "source": [
    "# instead record a har file in the browser and extract images from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafeae80-bf29-47cb-b5cb-222990dcfacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_images():\n",
    "    entries = []\n",
    "    for filename in (\n",
    "            PATH / \"pixilart-com-2024-02-25.har\",\n",
    "            PATH / \"pixilart-com-2025-01-25.har\",\n",
    "            PATH / \"pixilart-com-2025-01-25-02.har\",\n",
    "            PATH / \"pixilart-com-2025-01-25-03.har\",\n",
    "            PATH / \"pixilart-com-2025-01-25-04.har\",\n",
    "    ):\n",
    "        with filename.open() as f:\n",
    "            har_data = json.load(f)\n",
    "            entries.extend(har_data[\"log\"][\"entries\"])\n",
    "\n",
    "    filename_set = set()\n",
    "    num_duplicates = 0\n",
    "\n",
    "    with tqdm(entries, desc=filename.name) as progress:\n",
    "        for e in progress:\n",
    "            if e.get(\"request\") and e[\"request\"][\"url\"].endswith(\".png\"):\n",
    "                if e.get(\"response\") and e[\"response\"].get(\"content\"):\n",
    "                    content = e[\"response\"][\"content\"]\n",
    "                    #print(content[\"mimeType\"])\n",
    "                    if content[\"mimeType\"] in (\"image/png\", \"image/webp\"):\n",
    "                        if content.get(\"encoding\") == \"base64\":\n",
    "                            data = base64.b64decode(content[\"text\"].encode(\"ascii\"))\n",
    "                            fn = e[\"request\"][\"url\"].rsplit(\"/\", 1)[-1]\n",
    "                            if fn in filename_set:\n",
    "                                num_duplicates += 1\n",
    "                                progress.set_postfix({\"duplicates\": num_duplicates})\n",
    "                                continue\n",
    "                            filename_set.add(fn)\n",
    "                            \n",
    "                            try:\n",
    "                                image = PIL.Image.open(io.BytesIO(data))\n",
    "                            except Exception as ex:\n",
    "                                print(\"FAILED\", e[\"request\"][\"url\"], ex)\n",
    "                                continue\n",
    "                            \n",
    "                            yield image, fn\n",
    "                        \n",
    "\n",
    "for i, (image, filename) in zip(range(10), iter_images()):\n",
    "    print(filename)\n",
    "    display(image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e58eae-18fe-47ae-9dc4-e3d00d61d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for _ in iter_images():\n",
    "    count += 1\n",
    "print(\"COUNT\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8714531-3a79-481e-817b-0abf883d0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a24fc-adb9-4b5f-8db8-6d60caa2023c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## resize images to smallest scale\n",
    "\n",
    "wow, this seems to be a harder problem... it's not really working good, so i keep the 400px previews as they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87aa90-f473-428c-b008-4c0c848ce49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e65a8ee-8340-4340-9daa-1adf33e93772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as VF\n",
    "import torch\n",
    "import math\n",
    "\n",
    "def resize(img, scale: float, mode: VF.InterpolationMode = VF.InterpolationMode.NEAREST):\n",
    "    if isinstance(img, PIL.Image.Image):\n",
    "        shape = (img.height, img.width)\n",
    "    else:\n",
    "        shape = img.shape[-2:]\n",
    "    return VF.resize(img, [max(1, int(s * scale)) for s in shape], mode, antialias=False)\n",
    "\n",
    "def iter_small_images():\n",
    "    for image, filename in iter_images():\n",
    "        image = VF.to_tensor(image.convert(\"RGB\"))\n",
    "        # display(VF.to_pil_image(resize(image, 1)))\n",
    "    \n",
    "        smallest_image = image\n",
    "        smallest_error = None\n",
    "        \n",
    "        for ofs in range(2, 9):\n",
    "            small = VF.resize(image, [s // ofs for s in image.shape[-2:]], VF.InterpolationMode.NEAREST, antialias=False)\n",
    "            upscaled = VF.resize(small, image.shape[-2:], VF.InterpolationMode.BILINEAR, antialias=False)\n",
    "            error = (image != upscaled).float().mean()\n",
    "            \n",
    "            # print(\"X\", ofs, error)\n",
    "            if error < 0.5:\n",
    "                if smallest_error is None or error <= smallest_error or error < .4:\n",
    "                    smallest_error = error\n",
    "                    smallest_image = small\n",
    "                    # print(\"smallest\", ofs, smallest_error)\n",
    "        #print(smallest_error)\n",
    "        #display(VF.to_pil_image(smallest_image))\n",
    "        yield smallest_image, filename, smallest_error\n",
    "\n",
    "\n",
    "for i, (image, filename, e) in zip(range(10), iter_small_images()):\n",
    "    display(VF.to_pil_image(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708373cf-2591-46c4-9222-9941a657cce4",
   "metadata": {},
   "source": [
    "# store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae36ee4-f289-4cd7-9490-5c5801b4c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(PATH / \"raw\" / \"train\", exist_ok=True)\n",
    "os.makedirs(PATH / \"raw\" / \"test\", exist_ok=True)\n",
    "\n",
    "for i, (image, filename) in enumerate(iter_images()):\n",
    "    sub_path = \"test\" if i % 10 == 0 else \"train\"\n",
    "    filename = PATH / \"raw\" / sub_path / filename\n",
    "    if not filename.exists():\n",
    "        try:\n",
    "            image.convert(\"RGB\").save(filename)    \n",
    "        except Exception as e:\n",
    "            print(\"EXC\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa82ab-b24a-4899-ac41-b84c073dedb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2576337b-3811-425e-a80d-8fa3c751574b",
   "metadata": {},
   "source": [
    "## patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e520c14a-4855-428d-a86c-a575f1da9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util.image import ImageFilter\n",
    "from src.datasets import ImageFilterIterableDataset\n",
    "\n",
    "class PixilartPatchDataset(BaseIterableDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        shape: Tuple[int, int, int] = (3, 64, 64),\n",
    "        interpolation: VT.InterpolationMode = VT.InterpolationMode.BILINEAR,\n",
    "        interleave_images: Optional[int] = 20,\n",
    "        shuffle_images: bool = True,\n",
    "        train: bool = True,\n",
    "    ):\n",
    "        self._ds_image = ImageFolderIterableDataset(\n",
    "            Path(\"~/prog/data/pixilart/raw\").expanduser() / (\"train\" if train else \"test\"),\n",
    "            shuffle=shuffle_images,\n",
    "        )\n",
    "        \n",
    "        self._ds = InterleaveIterableDataset(( \n",
    "            RandomImagePatchIterableDataset(\n",
    "                self._ds_image.scale(min(shape[2:])/400, interpolation=interpolation), shape,\n",
    "                patches_per_image_factor=1.,\n",
    "                interleave_images=interleave_images,\n",
    "            ),\n",
    "            RandomImagePatchIterableDataset(\n",
    "                self._ds_image.scale(.25, interpolation=interpolation), shape,\n",
    "                patches_per_image_factor=2.,\n",
    "                interleave_images=interleave_images,\n",
    "            ),\n",
    "            RandomImagePatchIterableDataset(\n",
    "                self._ds_image.scale(.5, interpolation=interpolation), shape,\n",
    "                patches_per_image_factor=3.,\n",
    "                interleave_images=interleave_images,\n",
    "            ),\n",
    "            RandomImagePatchIterableDataset(\n",
    "                self._ds_image, shape,\n",
    "                interleave_images=interleave_images,\n",
    "            ),\n",
    "        ))\n",
    "        self._ds = ImageFilterIterableDataset(\n",
    "            self._ds,\n",
    "            ImageFilter(\n",
    "                min_std=0.1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from self._ds\n",
    "\n",
    "ds = PixilartPatchDataset(shape=(3, 64, 64), interleave_images=20, train=True)#.shuffle(10_000)\n",
    "\n",
    "VF.to_pil_image(make_grid(ds.sample(14*14), nrow=14))\n",
    "#VF.to_pil_image(resize(make_grid(ds.sample(64), nrow=4), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca8a19-5fb9-4609-8cf4-23e43b0dcf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(ds):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5490f-9a6b-4bf2-8cde-c3332b409d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = (3, 70, 70)\n",
    "FILENAME = f\"../datasets/pixilart-uint-{target_shape[-2]}x{target_shape[-1]}-train.pt\"\n",
    "\n",
    "def store_dataset(\n",
    "        images: Iterable,\n",
    "        dtype=torch.float32,\n",
    "        #image_folder=\"~/Pictures/__diverse/\",\n",
    "        output_filename=FILENAME,\n",
    "        max_megabyte=4_096,\n",
    "):\n",
    "    tensor_batch = []\n",
    "    tensor_size = 0\n",
    "    last_print_size = 0\n",
    "    try:\n",
    "        for image in tqdm(images):\n",
    "            if len(image.shape) < 4:\n",
    "                image = image.unsqueeze(0)\n",
    "            tensor_batch.append((image.clamp(0, 1) * 255).to(torch.uint8))\n",
    "            tensor_size += math.prod(image.shape)\n",
    "\n",
    "            if tensor_size - last_print_size > 1024 * 1024 * 200:\n",
    "                last_print_size = tensor_size\n",
    "\n",
    "                print(f\"size: {tensor_size:,}\")\n",
    "\n",
    "            if tensor_size >= max_megabyte * 1024 * 1024:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    tensor_batch = torch.cat(tensor_batch)\n",
    "    torch.save(tensor_batch, output_filename)\n",
    "\n",
    "store_dataset(\n",
    "    PixilartPatchDataset(shape=target_shape, interleave_images=20, train=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a5f9d-7de6-4365-970f-736dfbcec07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dataset(\n",
    "    PixilartPatchDataset(shape=target_shape, interleave_images=20, train=False),\n",
    "    output_filename=FILENAME.replace(\"-train\", \"-test\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8c8a3-0f38-483c-a3a0-8f4089009e02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
