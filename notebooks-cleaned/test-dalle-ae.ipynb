{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b67930-6b3e-4ff2-9f8f-e6e4e7cfe55e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.datasets import *\n",
    "from src.util import *\n",
    "from src.util.image import * \n",
    "from src.algo import Space2d, IFS\n",
    "from src.datasets.generative import *\n",
    "from src.models.cnn import *\n",
    "from src.util.embedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf96c7-a8d7-48eb-a601-746c5b294e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_samples(\n",
    "        iterable, \n",
    "        total: int = 32, \n",
    "        nrow: int = 8, \n",
    "        return_image: bool = False, \n",
    "        show_compression_ratio: bool = False,\n",
    "        label: Optional[Callable] = None,\n",
    "):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    f = ImageFilter()\n",
    "    try:\n",
    "        for idx, entry in enumerate(tqdm(iterable, total=total)):\n",
    "            image = entry\n",
    "            if isinstance(entry, (list, tuple)):\n",
    "                image = entry[0]\n",
    "            if image.ndim == 4:\n",
    "                image = image.squeeze(0)\n",
    "            samples.append(image)\n",
    "            if show_compression_ratio:\n",
    "                labels.append(round(f.calc_compression_ratio(image), 3))\n",
    "            elif label is not None:\n",
    "                labels.append(label(entry) if callable(label) else idx)\n",
    "                \n",
    "            if len(samples) >= total:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    if labels:\n",
    "        image = VF.to_pil_image(make_grid_labeled(samples, nrow=nrow, labels=labels))\n",
    "    else:\n",
    "        image = VF.to_pil_image(make_grid(samples, nrow=nrow))\n",
    "    if return_image:\n",
    "        return image\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c9e53-bd7e-4c2b-9037-a6901db7604f",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da8d7e-30de-4e7c-bf96-1c5d138e571d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.train_autoencoder import DalleAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34d328-fa28-4ea2-ab3d-01c102cf7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (1, 64, 64)\n",
    "CODE_SIZE = 128\n",
    "model = DalleAutoencoder(SHAPE, vocab_size=CODE_SIZE, n_hid=64, group_count=1, n_blk_per_group=1, act_fn=nn.GELU)\n",
    "model.load_state_dict(torch.load(\"../checkpoints/ae-d3/best.pt\")[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b265a06-aedc-461a-896c-2a5c047c24d5",
   "metadata": {},
   "source": [
    "## plot random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35089fc9-bc34-4447-9890-b7f2ee1e1259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VF.to_pil_image(make_grid(model.decoder(\n",
    "    torch.randn(8*8, CODE_SIZE) * 1.5 \n",
    ").clamp(0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d5cc9f-0c91-4c7d-a1fe-13171d02c21f",
   "metadata": {},
   "source": [
    "## transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3e6f0-ae0e-402d-8ab5-db1b9de0431f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = torch.zeros(8 * 8, CODE_SIZE)\n",
    "for i in range(8):\n",
    "    f1, f2 = torch.randn(2, CODE_SIZE) * 1.5\n",
    "\n",
    "    for j in range(8):\n",
    "        t = j / 7.\n",
    "        features[i * 8 + j] = f1 * (1. - t) + t * f2\n",
    "        \n",
    "VF.to_pil_image(make_grid(model.decoder(features).clamp(0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc23db-38cf-4708-a6a3-72b41bf6540f",
   "metadata": {},
   "source": [
    "# load some image patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf59b693-66ec-4b03-97fb-64a40a5f1d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = torch.load(\"../datasets/kali-uint8-64x64.pt\")[:5000]\n",
    "#samples = torch.load(\"../datasets/fonts-regular-32x32.pt\")[:1000]; samples = VF.resize(samples, (64, 64), antialias=True)\n",
    "#samples = torch.load(\"../datasets/diverse-64x64-aug4.pt\")[:1000]\n",
    "\n",
    "samples = (samples.to(torch.float32) / 255.).mean(1, keepdim=True)\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d41ce-7bce-43f9-8f68-2f67128dea09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_samples(samples, label=True, total=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66345f-0868-4111-9b12-469422e8f96f",
   "metadata": {},
   "source": [
    "# get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35c8ab-2391-4f4e-a048-436b7a933ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    all_features = batch_call(model.encoder, samples, verbose=True)\n",
    "    all_features_norm = normalize_embedding(all_features)\n",
    "    \n",
    "features_mean = all_features.mean()\n",
    "features_std = all_features.std()\n",
    "features_mean0 = all_features.mean(0)\n",
    "features_std0 = all_features.std(0)\n",
    "print(f\"embeddings mean {features_mean} std {features_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da213ab1-29f2-42ad-b1bc-76046d6c9c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(px.line(all_features[:10].detach().T, title=\"sample embeddings\"))\n",
    "display(px.line(pd.DataFrame({\n",
    "    \"mean\": features_mean0,\n",
    "    \"std\": features_std0,\n",
    "})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35f4f22-fd24-44c5-9740-db9141d462f8",
   "metadata": {},
   "source": [
    "# random samples again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120de91-a7bf-4c4a-b5c5-570771ce2362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VF.to_pil_image(make_grid(model.decoder(\n",
    "    torch.randn(8*8, CODE_SIZE) * features_std0 + features_mean0\n",
    ").clamp(0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d18861-f4f1-4e7d-b326-342e5bae985a",
   "metadata": {},
   "source": [
    "# morph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586315df-b826-494c-8146-07f77e2fdf5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def morph_images(idx1, idx2, noise: float = 0.):\n",
    "    images = samples[[idx1, idx2]]\n",
    "    f1, f2 = model.encoder(images)\n",
    "    \n",
    "    features = torch.zeros(8, 128)\n",
    "    for j in range(features.shape[0]):\n",
    "        t = j / (features.shape[0] - 1)\n",
    "        f = f1 * (1.-t) + t * f2\n",
    "        f = f + torch.randn_like(f) * noise\n",
    "        features[j] = f\n",
    "        \n",
    "    display(VF.to_pil_image(make_grid(model.decoder(features).clamp(0, 1))))\n",
    "    \n",
    "morph_images(0, 59, noise=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae561e1-f2ab-4bf7-a47b-1a786ea75038",
   "metadata": {},
   "source": [
    "# randomize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a3c91-399c-4004-be02-d81aa27bd169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def randomize_image(idx, count=8*8):\n",
    "    image = samples[idx]\n",
    "    features = model.encoder(image.unsqueeze(0)).repeat(count, 1)\n",
    "    \n",
    "    for i in range(1, count):\n",
    "        features[i] = features[i - 1]\n",
    "        for j in range(3):\n",
    "            features[i][random.randrange(features.shape[-1])] = random.gauss(features_mean, features_std)\n",
    "        \n",
    "    display(VF.to_pil_image(make_grid(model.decoder(features).clamp(0, 1))))\n",
    "    \n",
    "randomize_image(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c9a12-cb67-4a92-97a4-31c4d6e6461d",
   "metadata": {},
   "source": [
    "# similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a77830f-d1b3-4bbd-84c7-77dda3db7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sim = all_features_norm @ all_features_norm.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab453411-b575-4fcf-9b81-b1b0b9062460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.imshow(sim[:200, :200], height=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301cc48-2424-4c3d-a233-853eab491e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_ids = sim[:64].argsort(descending=True)[..., :32].flatten(0)\n",
    "VF.to_pil_image(make_grid([\n",
    "    samples[i] for i in best_ids\n",
    "], nrow=32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a11d6-2836-49f8-91fd-90752fc2fade",
   "metadata": {},
   "source": [
    "# PCA of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74be1e-325d-4acc-87f4-8e4ed0f511c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(8*8)\n",
    "pca.fit(all_features)\n",
    "pca_components = torch.Tensor(pca.components_)\n",
    "pca_variance = torch.Tensor(pca.explained_variance_)\n",
    "px.line(pca_components[:10].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082e8c9-2909-41a7-9071-bb2968624a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VF.to_pil_image(make_grid(model.decoder(\n",
    "    pca_components * 15 #pca_variance.unsqueeze(1)\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af105bf-1f48-4420-b818-3c719001d0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def morph_images_pca(images, band: int = 0, count: int = 10):\n",
    "    features = model.encoder(images)\n",
    "    \n",
    "    image_grid = []\n",
    "    for i in range(count):\n",
    "        t = i / max(1, count - 1) * 2. - 1.\n",
    "        fmod = features + pca_components[band] * t * 20#* pca_variance.unsqueeze(1)\n",
    "        images = model.decoder(fmod).clamp(0, 1)\n",
    "        image_grid.append(images)\n",
    "    \n",
    "    image_grid = torch.concat(image_grid)\n",
    "    \n",
    "    display(VF.to_pil_image(make_grid(image_grid, nrow=features.shape[0])))\n",
    "    \n",
    "morph_images_pca(samples[:20], band=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b516f36b-1a22-418c-882b-f57dcc7b18f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4bbfe-3291-40cf-8795-4b2901186a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2fb4d5-7c45-4291-ab1d-50cb0d76ea15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af283f8f-646e-47ba-9a05-2e0bb6a14ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4366130-85dc-45cc-9107-e258912aee3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68739159-5025-436b-97e1-65c6982b17e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f45782-76d7-4b56-841f-a4a48391f0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af34d1b1-693b-4bf0-8f34-c19a7644bf29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "1_000_000 // (36*36*36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee70122-de9c-4de5-b33d-9ce144695751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "\n",
    "values = [0] * 10\n",
    "output = ipywidgets.Output()\n",
    "display(output)\n",
    "\n",
    "def doit(index, x):\n",
    "    values[index] = x\n",
    "    output.clear_output(False)\n",
    "    with output:\n",
    "        display(values)#output.append_display_data(values)\n",
    "    #display(values, output)\n",
    "\n",
    "    \n",
    "widgets = [\n",
    "    ipywidgets.interactive(\n",
    "        doit, \n",
    "        x=ipywidgets.FloatSlider(value=i, min=-10, max=10, step=.1, continuous_update=False), \n",
    "        index=ipywidgets.fixed(i),\n",
    "    ) \n",
    "    for i in range(len(values))\n",
    "]\n",
    "\n",
    "for w in widgets:\n",
    "    display(w)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa90fe1-f30e-4ba9-ba51-d0805f31ca1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = ipywidgets.Button(description=\"hello\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2fa459-4841-4d33-b844-786804f38bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def create_param_widgets(params: dict, callback):\n",
    "    \n",
    "    param_widgets = []\n",
    "    \n",
    "    def _on_change(param_name, event):\n",
    "        if event[\"type\"] == \"change\":\n",
    "            callback({param_name: event[\"new\"][\"value\"]})\n",
    "    \n",
    "    for param_name, param in params.items(): \n",
    "        if issubclass(param[\"type\"], int):\n",
    "            input_widget = ipywidgets.IntSlider()\n",
    "        elif issubclass(param[\"type\"], float):\n",
    "            input_widget = ipywidgets.FloatSlider()\n",
    "        elif issubclass(param[\"type\"], str):\n",
    "            input_widget = ipywidgets.Text()\n",
    "        \n",
    "        input_widget.observe(partial(_on_change, param_name))\n",
    "        \n",
    "        param_widgets.append(\n",
    "            ipywidgets.HBox([ipywidgets.HTML(param_name), input_widget])\n",
    "        )\n",
    "    \n",
    "    return ipywidgets.VBox(param_widgets)\n",
    "\n",
    "\n",
    "def create_widgets():\n",
    "    params = {\n",
    "        \"text\": {\"type\": str, \"value\": \"strange beings\"}, \n",
    "        \"number1\": {\"type\": int, \"value\": 10}, \n",
    "        \"number2\": {\"type\": float, \"value\": 23.5},\n",
    "    }\n",
    "    output_widget = ipywidgets.Output()\n",
    "    \n",
    "    def _on_change(pars):\n",
    "        for key, value in pars.items():\n",
    "            params[key][\"value\"] = value\n",
    "            \n",
    "        output_widget.clear_output()\n",
    "        with output_widget:\n",
    "            display(params)\n",
    "    \n",
    "    param_widgets = create_param_widgets(\n",
    "        params,\n",
    "        _on_change,\n",
    "    )\n",
    "    return ipywidgets.HBox([\n",
    "        param_widgets,\n",
    "        output_widget,\n",
    "    ])\n",
    "    \n",
    "\n",
    "create_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385af85-d523-484d-b259-d447027fe6c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipywidgets.Text?\n",
    "#b.on_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b428e5-aa30-4bcc-bbe6-e853a889a4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipywidgets.Button?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
