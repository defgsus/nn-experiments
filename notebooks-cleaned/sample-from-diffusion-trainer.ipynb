{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294b2c6-5915-4277-a418-546e0f27921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f62b27-bbc8-479d-baa8-e99aab284b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = load_experiment_trainer(\"../experiments/diffusion/baseline.yml\", device=\"cuda\")\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf8d7a-cbf4-42f6-8cf4-41e38e4384ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.checkpoint_path)\n",
    "trainer.load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a249ff2-4fab-4e5b-9550-c0ac5aee8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 4\n",
    "with torch.no_grad():\n",
    "    images = trainer.generate_images(size*size, (1, 128, 128), steps=2)\n",
    "VF.to_pil_image(make_grid(images, nrow=size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766291a-0f3e-4415-9c9c-7467ad233cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86df257-5ba2-4c6c-bed0-52b2a3fd969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionSampler:\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            model: nn.Module,\n",
    "            channels: int,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.channels = channels\n",
    "        self._device = None\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        if self._device is None:\n",
    "            for p in self.model.parameters():\n",
    "                self._device = p.device\n",
    "                break\n",
    "        return self._device\n",
    "\n",
    "    def predict_noise(\n",
    "            self,\n",
    "            images: torch.Tensor,\n",
    "            noise_amounts: Optional[torch.Tensor] = None,\n",
    "    ):\n",
    "        assert images.ndim == 4, f\"Got {images.shape}\"\n",
    "        assert images.shape[1] == self.channels, f\"Got {images.shape}\"\n",
    "        \n",
    "        if noise_amounts is None:\n",
    "            noise_amounts = self.create_noise_amount(images.shape[0], 1, 1)\n",
    "\n",
    "        assert noise_amounts.ndim == 2, f\"Got {noise_amounts.shape}\"\n",
    "        assert noise_amounts.shape[0] == images.shape[0], f\"Got: {noise_amounts.shape}\"\n",
    "        \n",
    "        #embedding = noise_amounts[:, None, None, :].repeat(*images.shape) \n",
    "        \n",
    "        return self.model(\n",
    "            images.clamp(-1, 1),\n",
    "            noise_amounts,\n",
    "        )\n",
    "        \n",
    "    def _to_generator(self, seed: Union[None, int, torch.Generator]) -> Optional[torch.Generator]:\n",
    "        if seed is None:\n",
    "            return None #torch.Generator()\n",
    "        elif isinstance(seed, torch.Generator):\n",
    "            return seed\n",
    "        else:\n",
    "            return torch.Generator().manual_seed(seed)\n",
    "\n",
    "    def create_noise_amount(\n",
    "            self, \n",
    "            batch_size: int, \n",
    "            minimum: float = 0.001,\n",
    "            maximum: float = 1.,\n",
    "            seed: Union[None, int, torch.Generator] = None,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        gen = self._to_generator(seed)\n",
    "        \n",
    "        amounts = torch.rand((batch_size, 1), generator=gen).to(self.device)\n",
    "        if minimum == maximum:\n",
    "            return amounts * maximum\n",
    "        return amounts * ((maximum - minimum) + minimum)\n",
    "            \n",
    "    def create_noise(\n",
    "            self, \n",
    "            batch_size: int, \n",
    "            shape: Tuple[int, int], \n",
    "            seed: Union[None, int, torch.Generator] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        gen = self._to_generator(seed)\n",
    "        \n",
    "        return torch.randn((batch_size, self.channels, *shape), generator=gen).to(self.device) \n",
    "        #* noise_amounts[:, None, None, :]\n",
    "\n",
    "    def denoise_image(\n",
    "            self,\n",
    "            images: torch.Tensor,\n",
    "            noise_amounts: Optional[torch.Tensor] = None,\n",
    "            strength: float = 1.,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        assert images.ndim == 4, f\"Got {images.shape}\"\n",
    "        \n",
    "        if noise_amounts is None:\n",
    "            noise_amounts = self.create_noise_amount(images.shape[0], 1, 1)\n",
    "\n",
    "        estimated_noise = self.predict_noise(images, noise_amounts)\n",
    "\n",
    "        images = images - estimated_noise * strength\n",
    "        noise_amounts = noise_amounts - noise_amounts * strength\n",
    "\n",
    "        return images, noise_amounts\n",
    "        \n",
    "    def generate_images(\n",
    "            self,\n",
    "            batch_size,\n",
    "            shape: Tuple[int, int],\n",
    "            steps: int = 10,\n",
    "            seed: Optional[int] = None,\n",
    "            method: int = 1,\n",
    "    ):\n",
    "        gen = self._to_generator(seed)\n",
    "\n",
    "        noise = self.create_noise(batch_size, shape, seed=gen)\n",
    "        noise_amounts = self.create_noise_amount(batch_size, 1., 1.)\n",
    "        \n",
    "        noisy_images = noise\n",
    "\n",
    "        for step in range(steps):\n",
    "            estimated_noise = self.predict_noise(noisy_images, noise_amounts)\n",
    "            outputs = noisy_images - estimated_noise\n",
    "\n",
    "            if step < steps - 1:\n",
    "                noise = self.create_noise(batch_size, shape, seed=gen)\n",
    "                noisy_images = outputs + noise * (1. - (step + 1) / steps)\n",
    "                noise_amounts = noise_amounts - noise_amounts / steps\n",
    "\n",
    "        return outputs\n",
    "\n",
    "sampler = DiffusionSampler(\n",
    "    model=trainer.model,\n",
    "    channels=1,\n",
    ")\n",
    "VF.to_pil_image(make_grid(\n",
    "    sampler.generate_images(4, (32, 32)) * .5 + .5\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08401d-99a0-4450-a635-b09709a5263b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd00390-2a07-46e5-bc22-7f578d067d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce2740-76f5-461b-91a9-9b6dd3faf7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46022bfb-3d91-4e23-abc1-89784a527b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b195a9c-7c61-4bb0-a28a-25f30ed4e60e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
