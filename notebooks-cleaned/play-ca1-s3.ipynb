{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67573b-3acf-472f-8769-a53ba1089397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from typing import Optional, Callable, List, Tuple, Iterable, Generator, Union\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "plotly.io.templates.default = \"plotly_dark\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, IterableDataset, RandomSampler\n",
    "import torchvision.transforms as VT\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import display\n",
    "\n",
    "from src.util.image import *\n",
    "from src.util import *\n",
    "from src.algo import ca1\n",
    "\n",
    "def resize(img, scale: float, mode: VF.InterpolationMode = VF.InterpolationMode.NEAREST):\n",
    "    return VF.resize(img, [max(1, int(s * scale)) for s in img.shape[-2:]], mode, antialias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e67ef-5ffb-4117-ab8a-30c8e245017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rules = ca1.Ca1ReplaceRules(num_states=3, num_neighbours=1)\n",
    "f\"{len(all_rules):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa960b-5cbe-405a-a22b-94bc6ac40675",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in tqdm(range(len(all_rules))):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d69c14-236a-44e1-9547-101893dd4fe7",
   "metadata": {},
   "source": [
    "Aua! This is huge, maybe comming back another time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c7eb1-18fd-400e-a617-19ad343627ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd1f5a-1ee0-48b8-b6e0-3403b7712f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b225bb5-8149-4e9c-bf3e-440997e9df64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cf28715-8538-4173-b0b2-e2c6f5724d36",
   "metadata": {},
   "source": [
    "# reservoir computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f007c-00d5-4048-80fc-6a045d5f6565",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907c4a6-619c-416c-9568-de23732d5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float_rep(f: float):\n",
    "    b = np.array([f]).astype(np.float32).data.tobytes()\n",
    "    return [\n",
    "        (b[i // 8] >> (i % 8)) & 1\n",
    "        for i in range(8 * 4)\n",
    "    ]\n",
    "\n",
    "to_float_rep(23.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8298f7-4132-4580-ae38-3274494d14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BITS = 9\n",
    "NUM_TEST_SAMPLES = 100\n",
    "\n",
    "data = torch.zeros((2**NUM_BITS, NUM_BITS), dtype=torch.uint8)\n",
    "for i in range(data.shape[0]):\n",
    "    for k in range(data.shape[1]):\n",
    "        data[i, k] = (i >> k) & 1\n",
    "\n",
    "if 0:  # copy\n",
    "    targets = data    \n",
    "elif 0:  # xor\n",
    "    assert NUM_BITS % 2 == 0\n",
    "    targets = data[:, :5] ^ data[:, 5:]\n",
    "elif 0:  # square\n",
    "    targets = torch.Tensor([\n",
    "        [((i * i % 251) >> j) & 1 for j in range(8)]\n",
    "        for i in range(data.shape[0])\n",
    "    ]).to(data)\n",
    "elif 0:  # sqrt\n",
    "    targets = torch.Tensor([\n",
    "        [(int(math.sqrt(i)) >> j) & 1 for j in range((NUM_BITS + 1) // 2)]\n",
    "        for i in range(data.shape[0])\n",
    "    ]).to(data)\n",
    "\n",
    "else:  # float-rep\n",
    "    targets = torch.Tensor([\n",
    "        to_float_rep(float(i))\n",
    "        for i in range(data.shape[0])\n",
    "    ]).to(data)\n",
    "\n",
    "test_indices = torch.randperm(data.shape[0], generator=torch.Generator().manual_seed(23))[:NUM_TEST_SAMPLES]\n",
    "train_indices = torch.Tensor(sorted(set(range(data.shape[0])) - set(test_indices.tolist()))).to(torch.int64)\n",
    "\n",
    "data_train, data_test = data[train_indices], data[test_indices] \n",
    "targets_train, targets_test = targets[train_indices], targets[test_indices]\n",
    "print(\"input: \", data_train.shape, data_test.shape)\n",
    "print(\"target:\", targets_train.shape, targets_test.shape)\n",
    "print(\"sample:\")\n",
    "for i in (0, 1, 2, 3, -3, -2, -1):\n",
    "    print(f\"{i:2}: {data[i].tolist()} -> {targets[i].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95fae1c-b2a9-4f5b-9d97-34e48ade5acd",
   "metadata": {},
   "source": [
    "### render states for each input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51306c9c-148d-4d44-9608-864704191ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_WIDTH = 200\n",
    "MIN_INPUT_DIST = 3\n",
    "\n",
    "seed = 50\n",
    "while True:\n",
    "    mapping_indices = torch.randperm(STATE_WIDTH, generator=torch.Generator().manual_seed(seed))[:NUM_BITS].sort().values\n",
    "    diffs = mapping_indices[1:] - mapping_indices[:-1]\n",
    "    if diffs.min() >= MIN_INPUT_DIST:\n",
    "        break\n",
    "    seed += 1\n",
    "        \n",
    "print(f\"seed: {seed}\\nindices: {mapping_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8897d7-66bf-4255-a924-290c4103dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ca_states(\n",
    "    rule: int,\n",
    "    num_states: int = 2,\n",
    "    num_neighbours: int = 1,\n",
    "    iterations: int = 2000,\n",
    "    output_steps: int = 100,\n",
    "    wrap: bool = False,\n",
    "    seq_input: str = \"none\", \n",
    "    seq_input_stride: int = 7,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    states = []\n",
    "    for batch in tqdm(iter_batches(data, batch_size=256), disable=not verbose):\n",
    "        input = torch.zeros(batch.shape[0], STATE_WIDTH, dtype=torch.uint8)\n",
    "\n",
    "        if 1:  # direct input\n",
    "            input[:, mapping_indices] = batch\n",
    "            seq_input = None\n",
    "        \n",
    "        if seq_input == \"sequential\":  # seq input\n",
    "            seq_input = torch.zeros(batch.shape[0], batch.shape[-1], STATE_WIDTH, dtype=torch.uint8)\n",
    "            for idx in range(batch.shape[-1]):\n",
    "                seq_input[:, idx, mapping_indices[idx]] = batch[:, idx]\n",
    "            # display(VF.to_pil_image(resize(seq_input[1:2], 4) * 255))\n",
    "\n",
    "        if seq_input == \"repeat\":  # seq input\n",
    "            seq_input = torch.zeros(batch.shape[0], 20, STATE_WIDTH, dtype=torch.uint8)\n",
    "            seq_input[:, :, mapping_indices] = batch.unsqueeze(1).repeat(1, 20, 1)\n",
    "\n",
    "        state = ca1.ca1_replace_step(\n",
    "            input=input,\n",
    "            lookup=ca1.Ca1ReplaceRules(num_states=num_states, num_neighbours=num_neighbours).lookup(rule),\n",
    "            num_states=num_states,\n",
    "            num_neighbours=num_neighbours,\n",
    "            iterations=iterations,\n",
    "            wrap=wrap,\n",
    "            seq_input=seq_input,\n",
    "            seq_input_stride=seq_input_stride,\n",
    "            seq_input_mode=\"add\",\n",
    "        )\n",
    "        states.append(state[:, -output_steps:, :].flatten(1))\n",
    "    states = torch.concat(states)\n",
    "\n",
    "    if verbose:\n",
    "        img = make_grid([\n",
    "            states[i].view(1, -1, STATE_WIDTH)\n",
    "            for i in (1, 23, 42, -1)\n",
    "        ]).float() / states.max()\n",
    "        display(VF.to_pil_image(resize(img, 5)))\n",
    "    \n",
    "    return states\n",
    "\n",
    "# 30, 225, 18, 60, 181\n",
    "states = calc_ca_states(22)\n",
    "#states = calc_ca_states(193426, num_states=2, num_neighbours=2)\n",
    "states_train, states_test = states[train_indices], states[test_indices]\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd738d56-7ad3-4876-8da6-86707f73fe60",
   "metadata": {},
   "source": [
    "### linear readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c03d7-3646-4bc5-8c4e-e45cae40a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "ridge.fit(states_train, targets_train)\n",
    "for kind, states_, target_ in (\n",
    "        (\"train\", states_train, targets_train), \n",
    "        (\"test\", states_test, targets_test),\n",
    "):\n",
    "    output_real = ridge.predict(states_)\n",
    "    output = (output_real >= .5).astype(np.float32)\n",
    "    num_correct = np.sum(np.sum(output == np.array(target_), axis=-1) == target_.shape[-1])\n",
    "    mae = (torch.Tensor(output_real) - target_).abs().mean()\n",
    "    print(f\"correct {kind:5}: {num_correct:4} / {target_.shape[0]:4}  (MAE {mae:.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78750266-7508-4312-aada-f0a80d419849",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = make_grid(torch.Tensor(ridge.coef_).view(targets.shape[-1], 1, -1, STATE_WIDTH), normalize=False, nrow=3)\n",
    "img = signed_to_image(img) * 10\n",
    "VF.to_pil_image(resize(img.clamp(0, 1), 5))\n",
    "#VF.to_pil_image(resize(signed_to_image(make_grid(torch.Tensor(ridge.coef_).view(targets.shape[-1], 1, -1, STATE_WIDTH), normalize=False, nrow=3))*10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b3220-278d-4752-accb-7afe7e67b2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43d3589f-d798-49dc-886d-8e248f29fd3a",
   "metadata": {},
   "source": [
    "# run all rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551773a4-6295-4193-b5bd-674071f4a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_rules():\n",
    "    rows = []\n",
    "    try:\n",
    "        for params in iter_parameter_permutations({\n",
    "            \"iter_steps\": [\n",
    "                #(200, 50),\n",
    "                (200, 100),\n",
    "                #(500, 50),\n",
    "                #(500, 50),\n",
    "                #(500, 100),\n",
    "                #(500, 200),\n",
    "                #(500, 300),\n",
    "                #(500, 400),\n",
    "                #(2000, 50),\n",
    "                #(2000, 100),\n",
    "                #(2000, 200),\n",
    "                #(2000, 500),\n",
    "            ],\n",
    "            \"wrap\": [True, False],\n",
    "            \"seq_input\": [\"none\", \"repeat\", \"sequential\"],\n",
    "            \"seq_input_stride\": [0, 1, 3, 7],\n",
    "        }):\n",
    "            iterations, output_steps = params[\"iter_steps\"]\n",
    "            wrap = params[\"wrap\"]\n",
    "            seq_input = params[\"seq_input\"]\n",
    "            seq_input_stride = params[\"seq_input_stride\"]\n",
    "            if seq_input == \"none\": \n",
    "                if seq_input_stride:\n",
    "                    continue\n",
    "            else:\n",
    "                if not seq_input_stride:\n",
    "                    continue\n",
    "                \n",
    "            for rule in tqdm(\n",
    "                #range(len(ca1.Ca1ReplaceRules())),\n",
    "                ca1.Ca1ReplaceRules().strong_rules,\n",
    "                #[22],\n",
    "                #[150, 105],\n",
    "                desc=str(params),\n",
    "                #desc=f\"it={iterations}, out={output_steps}, wrap={wrap}\", \n",
    "            ):        \n",
    "                states = calc_ca_states(\n",
    "                    rule=rule, iterations=iterations, output_steps=output_steps, wrap=wrap, seq_input=seq_input, \n",
    "                    verbose=False,\n",
    "                )\n",
    "                \n",
    "                states_train, states_test = states[train_indices], states[test_indices]\n",
    "        \n",
    "                ridge = Ridge()\n",
    "                ridge.fit(states_train, targets_train)\n",
    "    \n",
    "                row = {\n",
    "                    \"rule\": rule, \"iterations\": iterations, \"output_steps\": output_steps, \"wrap\": wrap,\n",
    "                    \"seq_input\": seq_input, \"seq_input_stride\": seq_input_stride,\n",
    "                    \"readout_var\": np.std(ridge.coef_),\n",
    "                }\n",
    "                for kind, states_, target_ in (\n",
    "                        (\"train\", states_train, targets_train), \n",
    "                        (\"test\", states_test, targets_test),\n",
    "                ):\n",
    "                    output_real = ridge.predict(states_)\n",
    "                    output = (output_real >= .5).astype(np.float32)\n",
    "                    num_correct = np.sum(np.sum(output == np.array(target_), axis=-1) == target_.shape[-1])\n",
    "                    mae = (torch.Tensor(output_real) - target_).abs().mean()\n",
    "                    \n",
    "                    row.update({\n",
    "                        f\"correct_{kind}\": num_correct,\n",
    "                        f\"mae_{kind}\": float(mae),\n",
    "                    })\n",
    "                    #print(f\"correct {kind:5}: {num_correct:4} / {target_.shape[0]:4}  (MAE {mae:.5f})\")\n",
    "                rows.append(row)\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    return pd.DataFrame(rows).set_index([\"rule\", \"iterations\", \"output_steps\", \"wrap\", \"seq_input\", \"seq_input_stride\"])\n",
    "\n",
    "df = run_all_rules().sort_values(\"correct_test\", ascending=False).sort_values(\"correct_train\", ascending=False, kind=\"stable\")\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a264a5f-d63d-4ed0-9362-1aa5a815ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"correct_test\", ascending=False).sort_values(\"correct_train\", ascending=False, kind=\"stable\").head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e79b2-e886-4793-8285-ebcdab6d8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"mae_train\").sort_values(\"correct_train\", ascending=False, kind=\"stable\").head(50)#.to_csv(\"../experiments/logs/data/ca1-repl-copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e3c27-f958-469f-a34e-fb15927622f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xor.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a098ff5-8aaa-405c-9d56-166e937dc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df_xor[\"correct_train\"] == 924).sum())\n",
    "print((df_xor[\"correct_test\"] == 100).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08f89be-ecd7-4f9d-a9bf-444f14f54070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"correct_test\", ascending=False).sort_values(\"correct_train\", ascending=False, kind=\"stable\")\n",
    "#df = df_square.copy()\n",
    "#df[\"correct_train\"] = df[\"correct_train\"].astype(np.str_)\n",
    "print(df.head(50).droplevel([\"iterations\", \"state_size\"]).to_markdown(floatfmt=\"f\", intfmt=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb2222-0d07-4001-a8c6-6d255b7ead2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = sorted((df_xor[df_xor[\"correct_train\"] == 924]).index.get_level_values(0))\n",
    "i2 = sorted((df_square[df_square[\"correct_train\"] == 462]).index.get_level_values(0))\n",
    "print(i1)\n",
    "print(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4edbe0b-c996-45f0-9f8b-0e37b8f6cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in i1:\n",
    "    print(f\"{r:3}: {ca1.Ca1ReplaceRules().lookup(r).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef198f3-ddb4-41af-be12-809dc688e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rules(rules, mark=[]):\n",
    "    images = []\n",
    "    for rule in rules:\n",
    "        input = torch.zeros(101)\n",
    "        input[input.shape[-1] // 2] = 1\n",
    "        state = ca1.ca1_replace_step(\n",
    "            input=input,\n",
    "            lookup=ca1.Ca1ReplaceRules().lookup(rule),\n",
    "            iterations=100,\n",
    "            num_neighbours=1,\n",
    "            wrap=True,\n",
    "        )\n",
    "        images.append(state.unsqueeze(0))\n",
    "    labels = [str(r) + (\" *\" if r in mark else \"\") for r in rules]\n",
    "    display(VF.to_pil_image(make_grid_labeled(images, labels=labels, nrow=5)))\n",
    "\n",
    "plot_rules(i1, mark=[60, 102, 105, 150, 153, 195])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a84ff-7fe9-4424-89f1-e0707037b8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
