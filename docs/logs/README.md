I started logging some experiments when i realized
that i always start from scratch when determining some 
meta parameters. 

This index is supposed to make it easy to find an old setup
and look at its parameters and results.


## Index
- [2024-12-15-selcopy2.md](2024-12-15-selcopy2.md)
  - [:arrow_forward:](2024-12-15-selcopy2.md#solving-the-very-selective-copying-problem-with-a-very-small-language-model) Solving the "Very Selective Copying" problem with a Very Small Language Model
      - [:arrow_forward:](2024-12-15-selcopy2.md#preliminary-tests) Preliminary tests
      - [:arrow_forward:](2024-12-15-selcopy2.md#number-of-operations-versus-number-of-layers) Number of operations versus number of layers
      - [:arrow_forward:](2024-12-15-selcopy2.md#quick-comparison-with-mamba-and-lstm) Quick comparison with Mamba and LSTM
      - [:arrow_forward:](2024-12-15-selcopy2.md#attention-please) Attention, please!
      - [:arrow_forward:](2024-12-15-selcopy2.md#compare-attention-activation-function) Compare attention activation function
      - [:arrow_forward:](2024-12-15-selcopy2.md#compare-position-of-self-attention-in-3-layers-network) Compare position of self-attention in 3-layers network
      - [:arrow_forward:](2024-12-15-selcopy2.md#compare-position-of-self-attention-in-5-layers-network) Compare position of self-attention in 5-layers network
      - [:arrow_forward:](2024-12-15-selcopy2.md#6-layers) 6-layers
- [2024-12-14-selcopy.md](2024-12-14-selcopy.md)
  - [:arrow_forward:](2024-12-14-selcopy.md#efficiently-solving-the-selective-copying-problem-with-a-very-small-language-model) Efficiently solving the Selective Copying Problem with a Very Small Language Model
      - [:arrow_forward:](2024-12-14-selcopy.md#comparing-number-of-layers) Comparing number of layers
      - [:arrow_forward:](2024-12-14-selcopy.md#increasing-kernel-size) Increasing kernel size
      - [:arrow_forward:](2024-12-14-selcopy.md#increasing-dilation) Increasing dilation
      - [:arrow_forward:](2024-12-14-selcopy.md#mixing-different-dilation-values) Mixing different dilation values
- [2024-12-03-shiny-tubes.md](2024-12-03-shiny-tubes.md)
  - [:arrow_forward:](2024-12-03-shiny-tubes.md#shiny-tubes-increasing-render-quality-with-a-unet) "Shiny Tubes": increasing render quality with a UNet
- [2024-11-28-colorize.md](2024-11-28-colorize.md)
  - [:arrow_forward:](2024-11-28-colorize.md#comparing-different-color-spaces-in-a-grayscale-to-color-residual-cnn) Comparing different color-spaces in a grayscale-to-color residual CNN
- [2024-10-23-deep-compression-ae.md](2024-10-23-deep-compression-ae.md)
  - [:arrow_forward:](2024-10-23-deep-compression-ae.md#deep-compression-auto-encoder) Deep-Compression Auto-Encoder
- [2024-02-24-residual-convolution.md](2024-02-24-residual-convolution.md)
  - [:arrow_forward:](2024-02-24-residual-convolution.md#parameter-tuning-for-a-residual-deep-image-to-image-cnn) Parameter tuning for a Residual Deep Image-to-Image CNN
    - [:arrow_forward:](2024-02-24-residual-convolution.md#compare-number-of-layers) Compare number of layers
    - [:arrow_forward:](2024-02-24-residual-convolution.md#compare-residual-weight-factor) Compare residual weight factor
    - [:arrow_forward:](2024-02-24-residual-convolution.md#compare-position-of-batch-normalization) Compare position of batch normalization?
    - [:arrow_forward:](2024-02-24-residual-convolution.md#compare-activation-function) Compare activation function
    - [:arrow_forward:](2024-02-24-residual-convolution.md#compare-channel-size) Compare channel size
    - [:arrow_forward:](2024-02-24-residual-convolution.md#compare-kernel-size) Compare kernel size
- [2024-02-12-lm-gen.md](2024-02-12-lm-gen.md)
  - [:arrow_forward:](2024-02-12-lm-gen.md#text-generation-with-microsoftphi-2) text generation with microsoft/phi-2
    - [:arrow_forward:](2024-02-12-lm-gen.md#text-completion) text completion
    - [:arrow_forward:](2024-02-12-lm-gen.md#code-completion) code completion
  - [:arrow_forward:](2024-02-12-lm-gen.md#microsoftphi-15) microsoft/phi-1.5
- [2024-01-21-ae-stacked.md](2024-01-21-ae-stacked.md)
  - [:arrow_forward:](2024-01-21-ae-stacked.md#stacked-symmetric-autoencoder-adding-one-layer-at-a-time) stacked symmetric autoencoder, adding one-layer-at-a-time
- [2023-12-29-reservoir-hyper-computing.md](2023-12-29-reservoir-hyper-computing.md)
  - [:arrow_forward:](2023-12-29-reservoir-hyper-computing.md#reproducing-connectionist-symbolic-machine-intelligence-using-cellular-automata-based-reservoir-hyperdimensional-computing) Reproducing "Connectionist-Symbolic Machine Intelligence using Cellular Automata based Reservoir-Hyperdimensional Computing"
      - [:arrow_forward:](2023-12-29-reservoir-hyper-computing.md#5-bit-xor) 5-bit xor
      - [:arrow_forward:](2023-12-29-reservoir-hyper-computing.md#8-bit-square) 8-bit square
      - [:arrow_forward:](2023-12-29-reservoir-hyper-computing.md#more-tests) more tests
- [2023-12-08-ae-histogram-loss.md](2023-12-08-ae-histogram-loss.md)
  - [:arrow_forward:](2023-12-08-ae-histogram-loss.md#autoencoder-with-histogram-loss) autoencoder with histogram loss
- [2023-12-03-reservoir-computing.md](2023-12-03-reservoir-computing.md)
  - [:arrow_forward:](2023-12-03-reservoir-computing.md#reservoir-computing) Reservoir computing
    - [:arrow_forward:](2023-12-03-reservoir-computing.md#reproducing-handwritten-digit-recognition-by-spin-waves-in-a-skyrmion-reservoir) Reproducing "Handwritten Digit Recognition by Spin Waves in a Skyrmion Reservoir"
      - [:arrow_forward:](2023-12-03-reservoir-computing.md#baseline-without-reservoir) Baseline without reservoir
      - [:arrow_forward:](2023-12-03-reservoir-computing.md#reservoirnum_inputs16-num_cells100) Reservoir(num_inputs=16, num_cells=100)
      - [:arrow_forward:](2023-12-03-reservoir-computing.md#reservoirnum_inputs16-num_cells1000) Reservoir(num_inputs=16, num_cells=1000)
- [2023-11-27-transformers.md](2023-11-27-transformers.md)
  - [:arrow_forward:](2023-11-27-transformers.md#experiments-with-vision-transformers) Experiments with vision transformers
    - [:arrow_forward:](2023-11-27-transformers.md#classifying-fmnist) Classifying FMNIST
- [2023-11-16-autoencoder-experiments.md](2023-11-16-autoencoder-experiments.md)
  - [:arrow_forward:](2023-11-16-autoencoder-experiments.md#variational-auto-encoder-on-rpg-tile-dataset) variational auto-encoder on RPG Tile dataset
  - [:arrow_forward:](2023-11-16-autoencoder-experiments.md#comparing-different-datasets) comparing different datasets
      - [:arrow_forward:](2023-11-16-autoencoder-experiments.md#take-care-of-the-choice-of-interpolation) Take care of the choice of interpolation!
- [2023-11-12-mnist.md](2023-11-12-mnist.md)
  - [:arrow_forward:](2023-11-12-mnist.md#autoencoder-training-on-mnist-dataset) Autoencoder training on MNIST dataset
    - [:arrow_forward:](2023-11-12-mnist.md#varying-kernel-size) varying kernel size
    - [:arrow_forward:](2023-11-12-mnist.md#varying-activation-function) varying activation function
    - [:arrow_forward:](2023-11-12-mnist.md#varying-image-to-code-ratio) varying image to code ratio
    - [:arrow_forward:](2023-11-12-mnist.md#varying-kernel-size-and-number-of-channels) varying kernel size and number of channels
- [2023-11-09-manifold.md](2023-11-09-manifold.md)
  - [:arrow_forward:](2023-11-09-manifold.md#implicit-neural-representation) "implicit neural representation"
      - [:arrow_forward:](2023-11-09-manifold.md#upgrade-decoder) upgrade decoder
      - [:arrow_forward:](2023-11-09-manifold.md#back-to-real-dataset) back to "real" dataset
      - [:arrow_forward:](2023-11-09-manifold.md#2023-11-10-back-to-small-dataset) 2023-11-10: back to small dataset
  - [:arrow_forward:](2023-11-09-manifold.md#2023-11-12-transformer-on-mnist) 2023-11-12: transformer on mnist
  - [:arrow_forward:](2023-11-09-manifold.md#resnet21-for-embedding---imagemanifoldmodel) resnet21 for embedding -> ImageManifoldModel
    - [:arrow_forward:](2023-11-09-manifold.md#back-to-simple-cnn-encoder) back to simple CNN encoder