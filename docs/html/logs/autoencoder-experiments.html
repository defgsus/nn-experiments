<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>variational auto-encoder on RPG Tile dataset</title>
    <meta name="description" content="" />
    <link rel="stylesheet" href="../../html/style/style-ab80046a.css">
    <script type="text/javascript" src="../../html/js/main-04542d2b.js"></script>
    
</head>
<body>


<main class="article">
    <div class="article-left">
        <h3><a href="../../index.html">&lt;&lt; nn-experiments</a></h3>
        <ul>
            
            
            <li class="indent-1"><a href="#variational-auto-encoder-on-rpg-tile-dataset" title="variational auto-encoder on RPG Tile dataset">variational auto-encoder on RPG Tile dataset</a></li>
            
            
            
            <li class="indent-1"><a href="#comparing-different-datasets" title="comparing different datasets">comparing different datasets</a></li>
            
            
            
            <li class="indent-3"><a href="#take-care-of-the-choice-of-interpolation" title="Take care of the choice of interpolation!">Take care of the choice of interpolation!</a></li>
            
            
            
            <li class="indent-1"><a href="#2023-12-08-autoencoder-with-histogram-loss" title="2023-12-08 autoencoder with histogram loss">2023-12-08 autoencoder with histogram loss</a></li>
            
            
            
            <li class="indent-1"><a href="#2024-01-21-stacked-symmetric-one-layer-at-a-time" title="2024-01-21 stacked symmetric one-layer-at-a-time">2024-01-21 stacked symmetric one-layer-at-a-time</a></li>
            
            
            
            <li class="indent-1"><a href="#2024-10-23-deep-compression-auto-encoder" title="2024-10-23 Deep-Compression Auto-Encoder">2024-10-23 Deep-Compression Auto-Encoder</a></li>
            
            
            
            
            
            
            
            
            
            
            
            
        </ul>
    </div>

    <div class="article-mid">

        <div class="show-when-small">
            <a href="../../index.html">&lt;&lt; nn-experiments</a></h3>
        </div>

        <h1 id="variational-auto-encoder-on-rpg-tile-dataset">variational auto-encoder on RPG Tile dataset <a href="#variational-auto-encoder-on-rpg-tile-dataset" class="heading-linker">←</a></h1>
<p>There is a <em>deep</em> love/hate relationships with neural networks.
Why the heck do i need to train a small network like this</p>
<div style="overflow: scroll;"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">VariationalAutoencoderConv</span><span class="p">(</span>
    <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">channels</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">latent_dims</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">default_parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">.0001</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">)</span>
</pre></div>
</div><p>for 10 hours and it still does not reach the optimum?</p>
<p><div style="overflow: scroll;"><img src="../../logs/img/vae-rpg-conv16-24-32-40M.png" alt="loss plots" /></div></p>
<p>And how could one tell after 30 minutes where this is going
to go? The plot shows the l1 validation loss (right) over
<strong>1700 epochs!</strong> Why does this network need to look at
things 1700 times???</p>
<p>Well, it's a complicated dataset, for sure.</p>
<p><div style="overflow: scroll;"><img src="../../logs/img/vae-rpg-conv16-24-32-40M-repros.png" alt="reproductions" /></div></p>
<p>But i feel there is something wrong in the method.
This <em>backpropagation gradient descent</em>, although
mathematically grounded, feels like a brute-force approach.</p>
<h1 id="comparing-different-datasets">comparing different datasets <a href="#comparing-different-datasets" class="heading-linker">←</a></h1>
<p>The rpg tile dataset is now fixed to 47579 training and 2505
validation grayscale images at 32x32 pixels.
Running the following experiment to compare
with the <em>&quot;classic&quot;</em> datasets:</p>
<div style="overflow: scroll;"><div class="highlight"><pre><span></span><span class="nt">trainer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">src.train.TrainAutoencoder</span>

<span class="nt">matrix</span><span class="p">:</span>
<span class="w">  </span><span class="nt">ds</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;mnist&quot;</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;fmnist&quot;</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;rpg&quot;</span>

<span class="nt">experiment_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">vae/base28_${matrix_slug}</span>

<span class="nt">train_set</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span><span class="w"> </span>
<span class="w">  </span><span class="no">{</span>
<span class="w">      </span><span class="no">&quot;mnist&quot;: mnist_dataset(train=True, shape=SHAPE),</span>
<span class="w">      </span><span class="no">&quot;fmnist&quot;: fmnist_dataset(train=True, shape=SHAPE),</span>
<span class="w">      </span><span class="no">&quot;rpg&quot;: rpg_tile_dataset_3x32x32(validation=False, shape=SHAPE),</span>
<span class="w">  </span><span class="no">}[&quot;${ds}&quot;]</span>

<span class="nt">validation_set</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">  </span><span class="no">{</span>
<span class="w">      </span><span class="no">&quot;mnist&quot;: mnist_dataset(train=False, shape=SHAPE),</span>
<span class="w">      </span><span class="no">&quot;fmnist&quot;: fmnist_dataset(train=False, shape=SHAPE),</span>
<span class="w">      </span><span class="no">&quot;rpg&quot;: rpg_tile_dataset_3x32x32(validation=True, shape=SHAPE)</span>
<span class="w">  </span><span class="no">}[&quot;${ds}&quot;]</span>

<span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">64</span>
<span class="nt">learnrate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0003</span>
<span class="nt">optimizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Adam</span>
<span class="nt">scheduler</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CosineAnnealingLR</span>
<span class="nt">max_inputs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1_000_000</span>

<span class="nt">globals</span><span class="p">:</span>
<span class="w">  </span><span class="nt">SHAPE</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">(1, 28, 28)</span>
<span class="w">  </span><span class="nt">CODE_SIZE</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>

<span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">  </span><span class="no">encoder = EncoderConv2d(SHAPE, code_size=CODE_SIZE, channels=(16, 24, 32), kernel_size=3)</span>
<span class="w">  </span><span class="no">decoder = DecoderConv2d(SHAPE, code_size=CODE_SIZE, channels=(32, 24, 16), kernel_size=3)</span>
<span class="w">  </span>
<span class="w">  </span><span class="no">VariationalAutoencoder(</span>
<span class="w">      </span><span class="no">encoder = VariationalEncoder(</span>
<span class="w">          </span><span class="no">encoder, CODE_SIZE, CODE_SIZE</span>
<span class="w">      </span><span class="no">),</span>
<span class="w">      </span><span class="no">decoder = decoder,</span>
<span class="w">      </span><span class="no">reconstruction_loss = &quot;l1&quot;,</span>
<span class="w">      </span><span class="no">reconstruction_loss_weight = 1.,</span>
<span class="w">      </span><span class="no">kl_loss_weight = 1.,</span>
<span class="w">  </span><span class="no">)</span>
</pre></div>
</div><p>Note that the MNIST and <a href="https://arxiv.org/abs/1708.07747" target="_blank">FMNIST</a> images are 28x28 pixels and
the RPG dataset is resized (via BILINEAR filter) to the same
resolution.</p>
<p><div style="overflow: scroll;"><img src="../../logs/img/vae-base-28.png" alt="training results" /></div></p>
<p>So, the RPG datasets seems to be equally easy/complicated
like MNIST and FMNIST is pretty hard in comparison.
Doing the same for 32x32 pixels (where the other two datasets
are resized):</p>
<p><div style="overflow: scroll;"><img src="../../logs/img/vae-base-32.png" alt="training results" /></div></p>
<p>Huh? Very different results.
MNIST easiest, FMNIST middle, RPG hardest. </p>
<h3 id="take-care-of-the-choice-of-interpolation">Take care of the choice of interpolation! <a href="#take-care-of-the-choice-of-interpolation" class="heading-linker">←</a></h3>
<p>After some testing it seems that the interpolation mode
during resizing has a strong influence. So i ran the above
experiment on different resolutions (<strong>res</strong>) and with
interpolation mode <code>BILINEAR</code> (<strong>aa</strong> = True) and
<code>NEAREST</code> (<strong>aa</strong> = False) and two different
learning rates (<strong>lr</strong>):</p>
<p>(using file <code>experiments/vae/compare-datasets.yml</code>)</p>
<div style="overflow: scroll;"><table>
<thead>
<tr>
<th align="left">dataset</th>
<th align="left">aa</th>
<th align="right">res</th>
<th align="right">lr</th>
<th align="right">validation loss (1,000,000 steps)</th>
<th align="left">meter</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">mnist</td>
<td align="left">False</td>
<td align="right">20</td>
<td align="right">0.0003</td>
<td align="right">0.0274497</td>
<td align="left">*******</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left">False</td>
<td align="right">20</td>
<td align="right">0.0003</td>
<td align="right">0.0482327</td>
<td align="left">******************</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left">False</td>
<td align="right">20</td>
<td align="right">0.0003</td>
<td align="right">0.052915</td>
<td align="left">********************</td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left"></td>
<td align="right">28</td>
<td align="right">0.0003</td>
<td align="right">0.0351929</td>
<td align="left">***********</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left"></td>
<td align="right">28</td>
<td align="right">0.0003</td>
<td align="right">0.0534702</td>
<td align="left">*********************</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left">False</td>
<td align="right">28</td>
<td align="right">0.0003</td>
<td align="right">0.0514313</td>
<td align="left">*******************</td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left">False</td>
<td align="right">32</td>
<td align="right">0.0003</td>
<td align="right">0.0333494</td>
<td align="left">**********</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left">False</td>
<td align="right">32</td>
<td align="right">0.0003</td>
<td align="right">0.0495315</td>
<td align="left">******************</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left"></td>
<td align="right">32</td>
<td align="right">0.0003</td>
<td align="right">0.0532157</td>
<td align="left">********************</td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left">True</td>
<td align="right">20</td>
<td align="right">0.0003</td>
<td align="right">0.0193185</td>
<td align="left">**</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left">True</td>
<td align="right">20</td>
<td align="right">0.0003</td>
<td align="right">0.0337913</td>
<td align="left">**********</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left">True</td>
<td align="right">20</td>
<td align="right">0.0003</td>
<td align="right">0.0337807</td>
<td align="left">**********</td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left"></td>
<td align="right">28</td>
<td align="right">0.0003</td>
<td align="right">0.0357742</td>
<td align="left">***********</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left"></td>
<td align="right">28</td>
<td align="right">0.0003</td>
<td align="right">0.0528828</td>
<td align="left">********************</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left">True</td>
<td align="right">28</td>
<td align="right">0.0003</td>
<td align="right">0.0369611</td>
<td align="left">************</td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left">True</td>
<td align="right">32</td>
<td align="right">0.0003</td>
<td align="right">0.0246818</td>
<td align="left">*****</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left">True</td>
<td align="right">32</td>
<td align="right">0.0003</td>
<td align="right">0.0380947</td>
<td align="left">************</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left"></td>
<td align="right">32</td>
<td align="right">0.0003</td>
<td align="right">0.0533928</td>
<td align="left">********************</td>
</tr>
<tr>
<td align="left">------</td>
<td align="left"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left">False</td>
<td align="right">20</td>
<td align="right">0.001</td>
<td align="right">0.0221466</td>
<td align="left">****</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left">False</td>
<td align="right">20</td>
<td align="right">0.001</td>
<td align="right">0.0421959</td>
<td align="left">***************</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left">False</td>
<td align="right">20</td>
<td align="right">0.001</td>
<td align="right">0.0454093</td>
<td align="left">****************</td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left"></td>
<td align="right">28</td>
<td align="right">0.001</td>
<td align="right">0.0326754</td>
<td align="left">*********</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left"></td>
<td align="right">28</td>
<td align="right">0.001</td>
<td align="right">0.0491466</td>
<td align="left">******************</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left">False</td>
<td align="right">28</td>
<td align="right">0.001</td>
<td align="right">0.0472919</td>
<td align="left">*****************</td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left">False</td>
<td align="right">32</td>
<td align="right">0.001</td>
<td align="right">0.0300777</td>
<td align="left">********</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left">False</td>
<td align="right">32</td>
<td align="right">0.001</td>
<td align="right">0.0459637</td>
<td align="left">*****************</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left"></td>
<td align="right">32</td>
<td align="right">0.001</td>
<td align="right">0.0485321</td>
<td align="left">******************</td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left">True</td>
<td align="right">20</td>
<td align="right">0.001</td>
<td align="right">0.0157305</td>
<td align="left">*</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left">True</td>
<td align="right">20</td>
<td align="right">0.001</td>
<td align="right">0.0278209</td>
<td align="left">*******</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left">True</td>
<td align="right">20</td>
<td align="right">0.001</td>
<td align="right">0.0281536</td>
<td align="left">*******</td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left"></td>
<td align="right">28</td>
<td align="right">0.001</td>
<td align="right">0.0321101</td>
<td align="left">*********</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left"></td>
<td align="right">28</td>
<td align="right">0.001</td>
<td align="right">0.0492271</td>
<td align="left">******************</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left">True</td>
<td align="right">28</td>
<td align="right">0.001</td>
<td align="right">0.0349186</td>
<td align="left">***********</td>
</tr>
<tr>
<td align="left">mnist</td>
<td align="left">True</td>
<td align="right">32</td>
<td align="right">0.001</td>
<td align="right">0.0221171</td>
<td align="left">****</td>
</tr>
<tr>
<td align="left">fmnist</td>
<td align="left">True</td>
<td align="right">32</td>
<td align="right">0.001</td>
<td align="right">0.0357977</td>
<td align="left">***********</td>
</tr>
<tr>
<td align="left">rpg</td>
<td align="left"></td>
<td align="right">32</td>
<td align="right">0.001</td>
<td align="right">0.0489479</td>
<td align="left">******************</td>
</tr>
</tbody></table></div><p>(No entry in <strong>aa</strong> means that there was no resizing necessary)</p>
<p>It confirms the strong correlation of the dataset difficulty
and the interpolation method. It gave me some headache in
the beginning but looking at resized examples makes it
understandable:</p>
<div style="overflow: scroll;"><table>
<thead>
<tr>
<th>Original MNIST image (28x28)</th>
<th>resized to 32x32 <em>without</em></th>
<th>and <em>with</em> bilinear filtering</th>
</tr>
</thead>
<tbody>
<tr>
<td><div style="overflow: scroll;"><img src="../../logs/img/resize-mnist-28-orig.png" alt="original" /></div></td>
<td><div style="overflow: scroll;"><img src="../../logs/img/resize-mnist-32.png" alt="original" /></div></td>
<td><div style="overflow: scroll;"><img src="../../logs/img/resize-mnist-32-aa.png" alt="original" /></div></td>
</tr>
</tbody></table></div><div style="overflow: scroll;"><table>
<thead>
<tr>
<th>Original FMNIST image (28x28)</th>
<th>resized to 32x32 <em>without</em></th>
<th>and <em>with</em> bilinear filtering</th>
</tr>
</thead>
<tbody>
<tr>
<td><div style="overflow: scroll;"><img src="../../logs/img/resize-fmnist-28-orig.png" alt="original" /></div></td>
<td><div style="overflow: scroll;"><img src="../../logs/img/resize-fmnist-32.png" alt="original" /></div></td>
<td><div style="overflow: scroll;"><img src="../../logs/img/resize-fmnist-32-aa.png" alt="original" /></div></td>
</tr>
</tbody></table></div><div style="overflow: scroll;"><table>
<thead>
<tr>
<th>Original RPG image (32x32)</th>
<th>resized to 28x28 <em>without</em></th>
<th>and <em>with</em> bilinear filtering</th>
</tr>
</thead>
<tbody>
<tr>
<td><div style="overflow: scroll;"><img src="../../logs/img/resize-rpg-32-orig.png" alt="original" /></div></td>
<td><div style="overflow: scroll;"><img src="../../logs/img/resize-rpg-28.png" alt="original" /></div></td>
<td><div style="overflow: scroll;"><img src="../../logs/img/resize-rpg-28-aa.png" alt="original" /></div></td>
</tr>
</tbody></table></div><p>The bilinear filter blurs out a lot of the single pixel
details and makes the images <em>&quot;easier&quot;</em> to auto-encode.
Ignoring the <code>aa = True</code> runs in the table above we can see
that the RPG dataset is, in comparison, equally <em>&quot;hard</em>&quot;
when down-scaled to the FMNIST size and a little harder
when FMNIST is up-scaled (because some pixels are just
repeated).</p>
<p>Side note: Many of the images in RPG are originally 16x16
but there is a good percentage of images that were 32x32
or larger. All of them have been resized to 32x32 <strong>without</strong>
interpolation.</p>
<p>For comparison, below is a run on a dataset of 60,000
noise images (mean=0.5, std=0.5, clamped to range [0, 1]),
+10,000 for validation (green). </p>
<p><div style="overflow: scroll;"><img src="../../logs/img/vae-32-noise.png" alt="loss plots" /></div></p>
<h1 id="2023-12-08-autoencoder-with-histogram-loss">2023-12-08 autoencoder with histogram loss <a href="#2023-12-08-autoencoder-with-histogram-loss" class="heading-linker">←</a></h1>
<p>Stupid experiment, just to get a feeling for the parameters.</p>
<p>Basically a simple autoencoder but the loss only considers the histogram
using the <em>soft histogram</em> mentioned by Tony-Y in the
<a href="https://discuss.pytorch.org/t/differentiable-torch-histc/25865/4" target="_blank">pytorch forum</a>.</p>
<div style="overflow: scroll;"><div class="highlight"><pre><span></span><span class="nt">matrix</span><span class="p">:</span>
<span class="w">  </span><span class="nt">bins</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">100</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">200</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">50</span><span class="p p-Indicator">]</span>
<span class="w">  </span><span class="nt">sigma</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">100</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">200</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">50</span><span class="p p-Indicator">]</span>
<span class="w">  </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">False</span><span class="p p-Indicator">]</span>
<span class="w">  </span><span class="nt">loss</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">&quot;&#39;l1&#39;&quot;</span><span class="p p-Indicator">]</span>

<span class="nt">experiment_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ae/hist/hl-${matrix_slug}</span>

<span class="nt">trainer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">experiments.ae.trainer.TrainAutoencoderSpecial</span>

<span class="nt">train_set</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">  </span><span class="no">rpg_tile_dataset_3x32x32(SHAPE, validation=False)</span>

<span class="nt">validation_set</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">  </span><span class="no">rpg_tile_dataset_3x32x32(SHAPE, validation=True)</span>

<span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">64</span>
<span class="nt">learnrate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0003</span>
<span class="nt">optimizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">AdamW</span>
<span class="nt">scheduler</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CosineAnnealingLR</span>
<span class="nt">loss_function</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">  </span><span class="no">HistogramLoss(${bins}, 0., 1., sigma=${sigma}, loss=${loss}, normalize=${norm})</span>
<span class="nt">max_inputs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">500_000</span>

<span class="nt">globals</span><span class="p">:</span>
<span class="w">  </span><span class="nt">SHAPE</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">(3, 32, 32)</span>
<span class="w">  </span><span class="nt">CODE_SIZE</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>

<span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">  </span><span class="no">encoder = EncoderConv2d(SHAPE, code_size=CODE_SIZE, channels=(24, 32, 48), kernel_size=5)</span>

<span class="w">  </span><span class="no">encoded_shape = encoder.convolution.get_output_shape(SHAPE)</span>
<span class="w">  </span><span class="no">decoder = nn.Sequential(</span>
<span class="w">      </span><span class="no">nn.Linear(CODE_SIZE, math.prod(encoded_shape)),</span>
<span class="w">      </span><span class="no">Reshape(encoded_shape),</span>
<span class="w">      </span><span class="no">encoder.convolution.create_transposed(act_last_layer=False),</span>
<span class="w">  </span><span class="no">)</span>

<span class="w">  </span><span class="no">EncoderDecoder(encoder, decoder)</span>
</pre></div>
</div><p><div style="overflow: scroll;"><img src="../../logs/img/ae-histogramloss.png" alt="loss plots" /></div></p>
<p>Normalizing the histograms before calculating the difference did not
converge well. And reproduction look terrible as could be expected: </p>
<div style="overflow: scroll;"><table>
<thead>
<tr>
<th>green</th>
<th>yellow</th>
</tr>
</thead>
<tbody>
<tr>
<td><div style="overflow: scroll;"><img src="../../logs/img/ae-histogramloss-repro-green.png" alt="repro" /></div></td>
<td><div style="overflow: scroll;"><img src="../../logs/img/ae-histogramloss-repro-yellow.png" alt="repro" /></div></td>
</tr>
</tbody></table></div><div style="overflow: scroll;"><table>
<thead>
<tr>
<th>purple</th>
<th>gray</th>
</tr>
</thead>
<tbody>
<tr>
<td><div style="overflow: scroll;"><img src="../../logs/img/ae-histogramloss-repro-purple.png" alt="repro" /></div></td>
<td><div style="overflow: scroll;"><img src="../../logs/img/ae-histogramloss-repro-gray.png" alt="repro" /></div></td>
</tr>
</tbody></table></div><h1 id="2024-01-21-stacked-symmetric-one-layer-at-a-time">2024-01-21 stacked symmetric one-layer-at-a-time <a href="#2024-01-21-stacked-symmetric-one-layer-at-a-time" class="heading-linker">←</a></h1>
<p>Trained autoencoder on 3x64x64 images. Encoder and decoder are each 25 layers
of 3x3 cnn kernels and a final fully connected layer. code_size=128</p>
<p>In training, every N input steps the number of used layers is increased. First,
the autoencoder only uses first encoder and last decoder layer. That way,
it's possible to train the whole 25 layers after a time. It's just not good:</p>
<p><div style="overflow: scroll;"><img src="../../logs/img/ae-stacked-64.png" alt="loss plots" /></div></p>
<ul>
<li><strong>white</strong>: reference baseline cnn (using space-to-depth)</li>
<li><strong>cyan</strong>: 32-chan 25 layer cnn, next layer activated every 47,000 steps (1 epoch)</li>
<li><strong>yellow</strong>: 32-chan 25 layer cnn, next layer activated every 8,000 steps</li>
<li><strong>purple</strong>: 128-chan 25 layer cnn, next layer activated every 8,000 steps</li>
</ul>
<p>Also compared symmetric vs. non-symmetric. Symmetric means the convolutions
and fully connected layer use <strong>the same</strong> weights for encoding and decoding.
symmetric is half the number of parameters for the autoencoder and performs only
slightly below non-symmetric. The biases are not shared between encoder and decoder.</p>
<h1 id="2024-10-23-deep-compression-auto-encoder">2024-10-23 Deep-Compression Auto-Encoder <a href="#2024-10-23-deep-compression-auto-encoder" class="heading-linker">←</a></h1>
<p>Experiments with a small version of DC-AE from the paper
<em>DEEP COMPRESSION AUTOENCODER FOR EFFICIENT HIGH-RESOLUTION DIFFUSION MODELS</em> <a href="https://arxiv.org/abs/2205.14756" target="_blank">arxiv.org/abs/2205.14756</a></p>
<p>Code can be found here <a href="https://github.com/mit-han-lab/efficientvit" target="_blank">https://github.com/mit-han-lab/efficientvit</a>, and i copied the DC-AE parts and ported
the type-hints back to python &lt;3.10 <a href="https://github.com/defgsus/nn-experiments/blob/master/src/models/efficientvit" target="_blank">here</a>.</p>
<p>Using the good ol' 47,579 RPG dataset, for one million 3x32x32 images.</p>
<p><div style="overflow: scroll;"><img src="../../logs/img/dc-ae-rpg47k-1M.png" alt="loss plots" /></div></p>
<p>(Not all runs are finished because they seemed to converge at the same validation error)</p>
<p>The <strong>baseline (gray)</strong> is the usual stacked symmetric CNN AE with 24, 32, 48 channels, kernel-size 5 and a linear
layer for latent code size of 128, which results in a <strong>compression ratio of 24</strong>.</p>
<p>The DC-AE model configurations i tried are:</p>
<h4 id="dcae-03-yellow-params-81m-ratio-96">dcae-03 (yellow) params: 81M, ratio 96 <a href="#dcae-03-yellow-params-81m-ratio-96" class="heading-linker">←</a></h4>
<div style="overflow: scroll;"><pre>&quot;latent_channels=32 &quot;
&quot;encoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] &quot;
&quot;encoder.width_list=[64,128,256,256,512,512] encoder.depth_list=[0,4,8,2,2,2] &quot;
&quot;decoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] &quot;
&quot;decoder.width_list=[64,128,256,256,512,512] decoder.depth_list=[0,5,10,2,2,2] &quot;
&quot;decoder.norm=[bn2d,bn2d,bn2d,trms2d,trms2d,trms2d] decoder.act=[relu,relu,relu,silu,silu,silu]&quot;
</pre></div><h4 id="dcae-04-purple-params-81m-ratio-48">dcae-04 (purple) params: 81M, ratio 48 <a href="#dcae-04-purple-params-81m-ratio-48" class="heading-linker">←</a></h4>
<p>lowered compression ratio (via <code>latent_channels</code>)</p>
<div style="overflow: scroll;"><pre>&quot;latent_channels=64 &quot;
&quot;encoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] &quot;
&quot;encoder.width_list=[64,128,256,256,512,512] encoder.depth_list=[0,4,8,2,2,2] &quot;
&quot;decoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] &quot;
&quot;decoder.width_list=[64,128,256,256,512,512] decoder.depth_list=[0,5,10,2,2,2] &quot;
&quot;decoder.norm=[bn2d,bn2d,bn2d,trms2d,trms2d,trms2d] decoder.act=[relu,relu,relu,silu,silu,silu]&quot;
</pre></div><h4 id="dcae-05-green-params-110m-ratio-48">dcae-05 (green) params: 110M, ratio: 48 <a href="#dcae-05-green-params-110m-ratio-48" class="heading-linker">←</a></h4>
<p>increased width</p>
<div style="overflow: scroll;"><pre>&quot;latent_channels=64 &quot;
&quot;encoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] &quot;
&quot;encoder.width_list=[128,256,256,512,512,512] encoder.depth_list=[0,4,8,2,2,2] &quot;
&quot;decoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] &quot;
&quot;decoder.width_list=[128,256,256,512,512,512] decoder.depth_list=[0,5,10,2,2,2] &quot;
&quot;decoder.norm=[bn2d,bn2d,bn2d,trms2d,trms2d,trms2d] decoder.act=[relu,relu,relu,silu,silu,silu]&quot;
</pre></div><h4 id="dcae-06-orange-params-142m-ratio-48">dcae-06 (orange): params: 142M, ratio: 48 <a href="#dcae-06-orange-params-142m-ratio-48" class="heading-linker">←</a></h4>
<p>increased width</p>
<div style="overflow: scroll;"><pre>&quot;latent_channels=64 &quot;
&quot;encoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] &quot;
&quot;encoder.width_list=[64,128,256,256,512,1024] encoder.depth_list=[0,4,8,2,2,2] &quot;
&quot;decoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] &quot;
&quot;decoder.width_list=[64,128,256,256,512,1024] decoder.depth_list=[0,5,10,2,2,2] &quot;
&quot;decoder.norm=[bn2d,bn2d,bn2d,trms2d,trms2d,trms2d] decoder.act=[relu,relu,relu,silu,silu,silu]&quot;
</pre></div><h4 id="dcae-07-pink-params-106m-ratio-48">dcae-07 (pink): params: 106M, ratio: 48 <a href="#dcae-07-pink-params-106m-ratio-48" class="heading-linker">←</a></h4>
<p>Sames as dcae-04 but increased depth.</p>
<div style="overflow: scroll;"><pre>&quot;latent_channels=64 &quot;
&quot;encoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] &quot;
&quot;encoder.width_list=[64,128,256,256,512,512] encoder.depth_list=[0,4,8,2,3,4] &quot;
&quot;decoder.block_type=[ResBlock,ResBlock,ResBlock,EViT_GLU,EViT_GLU,EViT_GLU] &quot;
&quot;decoder.width_list=[64,128,256,256,512,512] decoder.depth_list=[0,5,10,2,3,4] &quot;  
&quot;decoder.norm=[bn2d,bn2d,bn2d,trms2d,trms2d,trms2d] decoder.act=[relu,relu,relu,silu,silu,silu]&quot;
</pre></div><p>The original model in the repo has 323M parameters which i could not train on my GPU,
so i lowered the width of the layers to make it fit. Also increased the learning rate from
originally <code>9.375e-7</code> to <code>9.375e-5</code>. Batch size was 64.</p>
<p>The latent shape for 32x32 images is actually <code>[&lt;latent_channels&gt;, 1, 1]</code>. The first try with
compression ratio 96 was a bit too much. With ratio 48 the results are better than the baseline (with 24)
so this is promising. However, none of the changes (dcae-05 to dcae-07) did enhance the performance.</p>
<p>Here's the reconstruction of the validation set for <strong>baseline</strong> and <strong>dcae-05</strong>:</p>
<p><div style="overflow: scroll;"><img src="../../logs/img/dc-ae-rpg47k-1M-recon-baseline.png" alt="reconstruction plot" /></div> <div style="overflow: scroll;"><img src="../../logs/img/dc-ae-rpg47k-1M-recon-05.png" alt="reconstruction plot" /></div></p>

        <!-- article footer -->
        <div class="flex article-footer">
            <div>
                 <a target="_blank" href="https://github.com/defgsus/nn-experiments/issues">Leave a comment</a>
            </div>

            <div class="flex-grow"></div>

            <div>
                Edit on <a target="_blank" href="https://github.com/defgsus/nn-experiments/blob/master/docs/logs/2023-11-16-autoencoder-experiments.md">github</a>
            </div>
        </div>

        <div class="flex article-footer">
            <div>
                
                    <a href="../../html/logs/mnist.html">
                        &lt;&lt; Autoencoder training on MNIST dataset
                    </a>
                
            </div>

            <div class="flex-grow"></div>

            <div>
                
                <a href="../../html/logs/transformers.html">
                    Experiments with vision transformers &gt;&gt;
                </a>
                
            </div>
        </div>
    </div>

</main>


</body>